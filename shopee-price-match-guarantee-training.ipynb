{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":24286,"databundleVersionId":1878097,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Сиды","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport os\nimport random\n    \n\nseed=42\n\nos.environ['PYTHONHASHSEED']=str(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:14:48.895920Z","iopub.execute_input":"2025-09-18T08:14:48.896173Z","iopub.status.idle":"2025-09-18T08:14:53.123834Z","shell.execute_reply.started":"2025-09-18T08:14:48.896154Z","shell.execute_reply":"2025-09-18T08:14:53.122998Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:14:53.125042Z","iopub.execute_input":"2025-09-18T08:14:53.125474Z","iopub.status.idle":"2025-09-18T08:14:53.183709Z","shell.execute_reply.started":"2025-09-18T08:14:53.125454Z","shell.execute_reply":"2025-09-18T08:14:53.182895Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Импорты","metadata":{}},{"cell_type":"code","source":"from torch import nn\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import v2\nimport tqdm \nfrom tqdm import tqdm\nfrom PIL import Image\nimport math\nfrom transformers import AutoTokenizer, AutoModel\nimport joblib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:14:53.184618Z","iopub.execute_input":"2025-09-18T08:14:53.184824Z","iopub.status.idle":"2025-09-18T08:15:03.853911Z","shell.execute_reply.started":"2025-09-18T08:14:53.184808Z","shell.execute_reply":"2025-09-18T08:15:03.853328Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# TEST MODE","metadata":{}},{"cell_type":"code","source":"TEST_MODE=True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:03.855482Z","iopub.execute_input":"2025-09-18T08:15:03.855880Z","iopub.status.idle":"2025-09-18T08:15:03.859202Z","shell.execute_reply.started":"2025-09-18T08:15:03.855861Z","shell.execute_reply":"2025-09-18T08:15:03.858546Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')\ntest=pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')\nsample=pd.read_csv('/kaggle/input/shopee-product-matching/sample_submission.csv')\n\ntrain_img_dir='/kaggle/input/shopee-product-matching/train_images'\ntest_img_dir='/kaggle/input/shopee-product-matching/test_images'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:03.860000Z","iopub.execute_input":"2025-09-18T08:15:03.860213Z","iopub.status.idle":"2025-09-18T08:15:04.025186Z","shell.execute_reply.started":"2025-09-18T08:15:03.860197Z","shell.execute_reply":"2025-09-18T08:15:04.024346Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.026052Z","iopub.execute_input":"2025-09-18T08:15:04.026255Z","iopub.status.idle":"2025-09-18T08:15:04.066446Z","shell.execute_reply.started":"2025-09-18T08:15:04.026239Z","shell.execute_reply":"2025-09-18T08:15:04.065623Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"posting_id     34250\nimage          32412\nimage_phash    28735\ntitle          33117\nlabel_group    11014\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"if TEST_MODE:\n    #train=train.sample(n=100, random_state=seed).reset_index(drop=True)\n    train=train[:32000]\nelse:\n    train=train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.067315Z","iopub.execute_input":"2025-09-18T08:15:04.067682Z","iopub.status.idle":"2025-09-18T08:15:04.071766Z","shell.execute_reply.started":"2025-09-18T08:15:04.067662Z","shell.execute_reply":"2025-09-18T08:15:04.071043Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Маппинг","metadata":{}},{"cell_type":"code","source":"label2id = {lg: i for i, lg in enumerate(sorted(train['label_group'].unique()))}\nid2label = {i: lg for lg, i in label2id.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.072517Z","iopub.execute_input":"2025-09-18T08:15:04.072764Z","iopub.status.idle":"2025-09-18T08:15:04.095734Z","shell.execute_reply.started":"2025-09-18T08:15:04.072747Z","shell.execute_reply":"2025-09-18T08:15:04.094976Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train['class_id']=train['label_group'].map(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.096533Z","iopub.execute_input":"2025-09-18T08:15:04.096806Z","iopub.status.idle":"2025-09-18T08:15:04.128687Z","shell.execute_reply.started":"2025-09-18T08:15:04.096783Z","shell.execute_reply":"2025-09-18T08:15:04.128044Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## train_test_split","metadata":{}},{"cell_type":"code","source":"train_data, eval_data=train_test_split(train, test_size=0.2)\n#stratify=train['class_id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.131697Z","iopub.execute_input":"2025-09-18T08:15:04.131922Z","iopub.status.idle":"2025-09-18T08:15:04.143725Z","shell.execute_reply.started":"2025-09-18T08:15:04.131906Z","shell.execute_reply":"2025-09-18T08:15:04.143067Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Датасет","metadata":{}},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    def __init__(self, df, img_root, transform, train):\n        self.df=df\n        self.img_root=img_root\n        self.transform=transform\n        self.train=train\n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        image_path=row['image']\n        image_path_all=os.path.join(self.img_root, f'{image_path}')\n        image=Image.open(image_path_all).convert('RGB')\n\n        if self.transform is not None:\n            image=self.transform(image)\n        else:\n            image=image\n        \n        if self.train:\n            return({\n                'image': image,\n                'label': torch.tensor(row['class_id'], dtype=torch.long),\n                'posting_id': row['posting_id']\n            })\n        else:\n            return({\n                'image': image,\n                'posting_id': row['posting_id']\n            })\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.144657Z","iopub.execute_input":"2025-09-18T08:15:04.144870Z","iopub.status.idle":"2025-09-18T08:15:04.150639Z","shell.execute_reply.started":"2025-09-18T08:15:04.144845Z","shell.execute_reply":"2025-09-18T08:15:04.149922Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Аугментации ","metadata":{}},{"cell_type":"code","source":"transforms_train=v2.Compose([\n    v2.Resize((224, 224)), \n    v2.RandomHorizontalFlip(),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntransforms_eval=v2.Compose([\n    v2.Resize((224,224)),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransforms_test=v2.Compose([\n    v2.Resize((224,224)),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.151407Z","iopub.execute_input":"2025-09-18T08:15:04.151630Z","iopub.status.idle":"2025-09-18T08:15:04.170133Z","shell.execute_reply.started":"2025-09-18T08:15:04.151615Z","shell.execute_reply":"2025-09-18T08:15:04.169457Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## Создание датасетов","metadata":{}},{"cell_type":"code","source":"train_dataset=ShopeeDataset(train_data, train_img_dir, transform=transforms_train, train=True)\neval_dataset=ShopeeDataset(eval_data,train_img_dir, transform=transforms_eval, train=True)\ntest_dataset=ShopeeDataset(test, test_img_dir, transform=transforms_test, train=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.170835Z","iopub.execute_input":"2025-09-18T08:15:04.171072Z","iopub.status.idle":"2025-09-18T08:15:04.184152Z","shell.execute_reply.started":"2025-09-18T08:15:04.171051Z","shell.execute_reply":"2025-09-18T08:15:04.183595Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Даталоадеры","metadata":{}},{"cell_type":"code","source":"train_dataloader=DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\neval_dataloader=DataLoader(eval_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_dataloader=DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.184914Z","iopub.execute_input":"2025-09-18T08:15:04.185126Z","iopub.status.idle":"2025-09-18T08:15:04.198981Z","shell.execute_reply.started":"2025-09-18T08:15:04.185110Z","shell.execute_reply":"2025-09-18T08:15:04.198335Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Кол-во эпох","metadata":{}},{"cell_type":"code","source":"EPOCHS=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.199653Z","iopub.execute_input":"2025-09-18T08:15:04.199905Z","iopub.status.idle":"2025-09-18T08:15:04.213218Z","shell.execute_reply.started":"2025-09-18T08:15:04.199883Z","shell.execute_reply":"2025-09-18T08:15:04.212466Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Model for image","metadata":{}},{"cell_type":"code","source":"model=timm.create_model('eca_nfnet_l1', pretrained=True,  num_classes=0).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:04.213988Z","iopub.execute_input":"2025-09-18T08:15:04.214168Z","iopub.status.idle":"2025-09-18T08:15:05.908040Z","shell.execute_reply.started":"2025-09-18T08:15:04.214146Z","shell.execute_reply":"2025-09-18T08:15:05.907445Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9368578cc6f745e9bbd06721d6903451"}},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Model for text","metadata":{}},{"cell_type":"code","source":"# === TEXT encoder (XLM-RoBERTa) ===\nTEXT_MODEL_NAME = 'xlm-roberta-base'  # мультиязычный, оффлайн часто есть в кеше Kaggle\ntext_tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME, use_fast=True)\ntext_model = AutoModel.from_pretrained(TEXT_MODEL_NAME).to(device).eval()\n\n# mean pooling по маске\ndef mean_pooling(last_hidden_state, attention_mask):\n    mask = attention_mask.unsqueeze(-1).float()          # (B, L, 1)\n    summed = (last_hidden_state * mask).sum(dim=1)       # (B, H)\n    denom = mask.sum(dim=1).clamp(min=1e-6)              # (B, 1)\n    return summed / denom\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:05.908875Z","iopub.execute_input":"2025-09-18T08:15:05.909231Z","iopub.status.idle":"2025-09-18T08:15:26.931998Z","shell.execute_reply.started":"2025-09-18T08:15:05.909193Z","shell.execute_reply":"2025-09-18T08:15:26.931137Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebad64393fd1425b9a349cab9a36c03d"}},"metadata":{}},{"name":"stderr","text":"2025-09-18 08:15:10.111981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758183310.313217      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758183310.370357      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02b1a803f65f48d393fd2419a798c1f4"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"@torch.no_grad()\ndef build_text_embeddings_for_df(df, batch_size=256, max_len=64):\n    \"\"\"\n    Возвращает L2-нормированные эмбеддинги заголовков (N, 768) в float16.\n    Порядок совпадает с df.\n    \"\"\"\n    titles = df['title'].fillna('').astype(str).tolist()\n    embs = []\n    for start in tqdm(range(0, len(titles), batch_size), desc=\"Embed/text\"):\n        batch = titles[start:start+batch_size]\n        tok = text_tokenizer(batch, padding=True, truncation=True,\n                             max_length=max_len, return_tensors='pt')\n        tok = {k: v.to(device, non_blocking=True) for k, v in tok.items()}\n        out = text_model(**tok)\n        sent = mean_pooling(out.last_hidden_state, tok['attention_mask'])  # (B, 768)\n        sent = nn.functional.normalize(sent, dim=1)\n        embs.append(sent.cpu())\n    embs = torch.cat(embs, dim=0).numpy().astype('float32')  # (N,768)\n    # safety L2 + экономия RAM\n    norms = np.linalg.norm(embs, axis=1, keepdims=True) + 1e-8\n    return (embs / norms).astype('float16')\n\ndef topk_chunked_cos(embs_f16: np.ndarray, K: int, qbs: int = 128):\n    \"\"\"\n    OOM-safe top-K по косинусу с помощью torch (без FAISS).\n    embs_f16: (N, D) float16, L2-нормированные\n    Возвращает sims, idxs: по (N, K) в float32 / int32\n    \"\"\"\n    N, D = embs_f16.shape\n    device_t = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    db = torch.from_numpy(embs_f16.astype('float32', copy=False)).to(device_t, non_blocking=True)\n\n    K = min(K, N)\n    idxs_list, sims_list = [], []\n    for start in tqdm(range(0, N, qbs), desc=\"TopK (torch-chunk)\"):\n        q = db[start:start+qbs]                 # (qbs, D)\n        S = torch.matmul(q, db.T)               # (qbs, N) — косинус\n        vals, ids = torch.topk(S, k=K, dim=1, largest=True, sorted=True)\n        idxs_list.append(ids.cpu().numpy().astype('int32'))\n        sims_list.append(vals.cpu().numpy().astype('float32'))\n        del S, vals, ids\n        if device_t.type == 'cuda':\n            torch.cuda.empty_cache()\n    idxs = np.vstack(idxs_list)   # (N, K)\n    sims = np.vstack(sims_list)   # (N, K)\n    del db\n    return sims, idxs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feat_dim = model.num_features \n\nembedding_head = nn.Sequential(\n    nn.Linear(feat_dim, 512, bias=False),\n    nn.BatchNorm1d(512)\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:26.932894Z","iopub.execute_input":"2025-09-18T08:15:26.933502Z","iopub.status.idle":"2025-09-18T08:15:26.954413Z","shell.execute_reply.started":"2025-09-18T08:15:26.933482Z","shell.execute_reply":"2025-09-18T08:15:26.953622Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# ArcFace голова","metadata":{}},{"cell_type":"code","source":"class ArcFace(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.5, easy_margin=False):\n        super().__init__()\n        \n        self.in_features=in_features\n        self.out_features=out_features\n        self.m=m\n        self.s=s\n        self.easy_margin=easy_margin\n\n        self.weight=nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.cos_m=math.cos(self.m)\n        self.sin_m=math.sin(self.m)\n\n        self.th=math.cos(math.pi-m)\n        self.mm=math.sin(math.pi-m)*m\n        \n        \n\n    def forward(self, embeddings, labels):\n        weights=nn.functional.normalize(self.weight)\n        cosine=nn.functional.linear(embeddings, weights)\n        sine=torch.sqrt(torch.clamp(1.0-cosine**2, min=1e-6))\n\n        phi=cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, labels.view(-1,1), 1.0)\n\n        \n        logits = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        logits = logits * self.s\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:26.955211Z","iopub.execute_input":"2025-09-18T08:15:26.956196Z","iopub.status.idle":"2025-09-18T08:15:26.963464Z","shell.execute_reply.started":"2025-09-18T08:15:26.956170Z","shell.execute_reply":"2025-09-18T08:15:26.962732Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"NUM_CLASSES = train['class_id'].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:26.964201Z","iopub.execute_input":"2025-09-18T08:15:26.964433Z","iopub.status.idle":"2025-09-18T08:15:26.981361Z","shell.execute_reply.started":"2025-09-18T08:15:26.964408Z","shell.execute_reply":"2025-09-18T08:15:26.980661Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"arcface_head=ArcFace(512, NUM_CLASSES, s=30.0, m=0.5).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:26.982066Z","iopub.execute_input":"2025-09-18T08:15:26.982344Z","iopub.status.idle":"2025-09-18T08:15:27.050409Z","shell.execute_reply.started":"2025-09-18T08:15:26.982320Z","shell.execute_reply":"2025-09-18T08:15:27.049619Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Criterion ","metadata":{}},{"cell_type":"code","source":"criterion=torch.nn.CrossEntropyLoss(label_smoothing=0.05)\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:27.051229Z","iopub.execute_input":"2025-09-18T08:15:27.051521Z","iopub.status.idle":"2025-09-18T08:15:27.055162Z","shell.execute_reply.started":"2025-09-18T08:15:27.051498Z","shell.execute_reply":"2025-09-18T08:15:27.054639Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Optimizer","metadata":{}},{"cell_type":"code","source":"optimizer=torch.optim.AdamW(list(model.parameters()) +\n    list(embedding_head.parameters()) +\n    list(arcface_head.parameters()), lr=3e-4, weight_decay=0.05)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:27.055889Z","iopub.execute_input":"2025-09-18T08:15:27.056093Z","iopub.status.idle":"2025-09-18T08:15:27.070632Z","shell.execute_reply.started":"2025-09-18T08:15:27.056078Z","shell.execute_reply":"2025-09-18T08:15:27.069892Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Scheduler","metadata":{}},{"cell_type":"code","source":"scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:27.071300Z","iopub.execute_input":"2025-09-18T08:15:27.071528Z","iopub.status.idle":"2025-09-18T08:15:27.084487Z","shell.execute_reply.started":"2025-09-18T08:15:27.071508Z","shell.execute_reply":"2025-09-18T08:15:27.083687Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"#  Training loop","metadata":{}},{"cell_type":"code","source":"for epoch in range(1, EPOCHS+1):\n    model.train()\n    embedding_head.train()\n    arcface_head.train()\n    running_loss, num_correct, n=0.0,0,0\n    pbar=tqdm(train_dataloader, desc='train', leave=False)\n    for step, batch in enumerate(pbar):\n        optimizer.zero_grad()\n        X=batch['image'].to(device)\n        y=batch['label'].to(device)\n    \n        feats=model(X)\n        embeddings = embedding_head(feats)\n        embeddings=nn.functional.normalize(embeddings, dim=1)\n        logits=arcface_head(embeddings, y)\n        loss=criterion(logits, y)\n        loss.backward()\n        \n        \n        optimizer.step()\n        running_loss+=loss.item()*X.size(0)\n        pbar.set_postfix(loss=running_loss/((step+1)*X.size(0)))\n\n    scheduler.step()\n# ===== Validation: build embeddings -> cosine-kNN -> global tau -> F1 =====\nimport numpy as np\n\nmodel.eval(); embedding_head.eval(); arcface_head.eval()\n\n@torch.no_grad()\ndef build_val_embeddings(loader):\n    embs, ids, labels = [], [], []\n    for b in tqdm(loader, desc=\"Embed/val\"):\n        x = b['image'].to(device, non_blocking=True)\n        e = model(x)                         # (B, feat_dim)\n        e = embedding_head(e)                # (B, 512)\n        e = nn.functional.normalize(e, dim=1)\n        embs.append(e.cpu())\n        ids.extend(b['posting_id'])\n        # важно: eval_dataset должен возвращать label (class_id)\n        labels.extend(b['label'].cpu().numpy().tolist())\n    embs = torch.cat(embs, dim=0).numpy()    # (N, 512)\n    labels = np.array(labels)\n    return embs, ids, labels\n\ndef build_preds(embs, ids, K=50, tau=0.50, mutual=True, cap=50):\n    \"\"\"\n    embs: (N, D) L2-нормированные векторы\n    ids:  список posting_id в том же порядке\n    Возвращает dict: posting_id -> set(predicted_ids) (включая self), с ограничением cap.\n    \"\"\"\n    # Косинусная матрица: для L2-нормированных это просто e @ e^T\n    S = embs @ embs.T        # (N, N)\n    N = S.shape[0]\n\n    # Предвычислим top-K индексы для каждого i (быстро и экономно)\n    topk_idx = np.argsort(-S, axis=1)[:, :K]  # индексы соседей по убыванию сходства\n\n    preds = {}\n    for i in range(N):\n        cand = []\n        for j in topk_idx[i]:\n            if S[i, j] >= tau:\n                if not mutual or i in topk_idx[j]:   # взаимность (mutual-kNN) уменьшает false-merge\n                    cand.append(ids[j])\n        # обязательно self-match\n        if ids[i] not in cand:\n            cand = [ids[i]] + cand\n        # кап по условию соревна\n        preds[ids[i]] = set(cand[:cap])\n    return preds\n\ndef f1_matches(ids, labels, preds):\n    \"\"\"\n    Средний F1 по каждому посту:\n      - истина: все posting_id той же class_id\n      - предсказание: preds[posting_id]\n    \"\"\"\n    # сгруппируем истину: class_id -> set(posting_id)\n    truth = {}\n    for pid, g in zip(ids, labels):\n        truth.setdefault(g, set()).add(pid)\n\n    f1s = []\n    for pid, g in zip(ids, labels):\n        T = truth[g]\n        P = preds[pid]\n        inter = len(T & P)\n        denom = len(T) + len(P)\n        f1s.append( 2*inter/denom if denom > 0 else 0.0 )\n    return float(np.mean(f1s))\n\n# 1) эмбеддинги на валидации\nval_embs, val_ids, val_labels = build_val_embeddings(eval_dataloader)\n# === TEXT embeddings на валидации (в порядке eval_dataset.df) ===\nval_text_embs = build_text_embeddings_for_df(eval_dataset.df, batch_size=256, max_len=64)  # (Nv,768) float16\n\n# === top-K для image и text (шире cap, потом обрежем) ===\nKQ = 100  # ширина кандидатов перед обрезкой до 50\nsims_img, idxs_img = topk_chunked_cos(val_embs.astype('float16'), K=KQ, qbs=128)     # (Nv,KQ)\nsims_txt, idxs_txt = topk_chunked_cos(val_text_embs,              K=KQ, qbs=256)     # (Nv,KQ)\n\ndef build_preds_fused_union(ids, idxs_img, sims_img, idxs_txt, sims_txt,\n                            tau, alpha=0.7, K_cap=50, mutual=True):\n    \"\"\"\n    Смешиваем косинусы: score = alpha*img + (1-alpha)*txt.\n    (оба в [-1,1]) → приводим к [0,1] для стабильности.\n    Кандидаты = объединение topK от image и text.\n    \"\"\"\n    N = len(ids)\n    preds = []\n    for i in range(N):\n        cand_idx = set(idxs_img[i]).union(set(idxs_txt[i]))\n        # карты скорингов текущей строки\n        map_img = {int(j): float(s) for j, s in zip(idxs_img[i], sims_img[i])}\n        map_txt = {int(j): float(s) for j, s in zip(idxs_txt[i], sims_txt[i])}\n\n        fused = []\n        for j in cand_idx:\n            si = (map_img.get(int(j), 0.0) + 1.0) / 2.0   # → [0,1]\n            st = (map_txt.get(int(j), 0.0) + 1.0) / 2.0   # → [0,1]\n            s  = alpha * si + (1.0 - alpha) * st\n            fused.append((j, s))\n\n        fused.sort(key=lambda x: -x[1])  # по убыванию\n        # mutual — проверяем только по image (дёшево и достаточно)\n        keep = []\n        for j, s in fused:\n            if s < tau: \n                continue\n            if (not mutual) or (np.any(idxs_img[j] == i)):\n                keep.append(ids[j])\n\n        if ids[i] not in keep:\n            keep = [ids[i]] + keep\n        preds.append(set(keep[:K_cap]))\n    # в формате, который ждёт f1_matches (dict)\n    return {ids[i]: preds[i] for i in range(N)}\n\n# Поиск (alpha, tau) по сетке\nalphas = np.linspace(0.4, 0.9, 6)     # 0.40..0.90\ntaus   = np.linspace(0.20, 0.80, 31)  # 0.20..0.80\nbest_f1, best_tau, best_alpha = -1.0, None, None\nfor a in alphas:\n    for t in taus:\n        preds = build_preds_fused_union(val_ids, idxs_img, sims_img, idxs_txt, sims_txt,\n                                        tau=float(t), alpha=float(a), K_cap=50, mutual=True)\n        f1 = f1_matches(val_ids, val_labels, preds)\n        if f1 > best_f1:\n            best_f1, best_tau, best_alpha = f1, float(t), float(a)\n\nprint(f\"[VAL FUSION] Best F1={best_f1:.4f} at tau={best_tau:.2f}, alpha={best_alpha:.2f}\")\n\n# (на всякий случай) L2-норм ещё раз, если вызывалась неявно\nval_embs = val_embs / np.linalg.norm(val_embs, axis=1, keepdims=True)\n\n# 2) поищем глобальный порог tau на сетке (стабильнее одного «подогнанного» фолда)\ngrid = np.linspace(0.20, 0.80, 31)  # шаг 0.02\nbest_f1, best_tau = -1.0, None\nfor tau in grid:\n    preds = build_preds(val_embs, val_ids, K=50, tau=float(tau), mutual=True, cap=50)\n    f1 = f1_matches(val_ids, val_labels, preds)\n    if f1 > best_f1:\n        best_f1, best_tau = f1, float(tau)\n\nprint(f\"[VAL] Best F1={best_f1:.4f} at tau={best_tau:.2f}\")\n\n# (необязательно) Быстрый sanity-check: средний размер предсказанных групп\npreds_best = build_preds(val_embs, val_ids, K=50, tau=best_tau, mutual=True, cap=50)\navg_group_size = np.mean([len(v) for v in preds_best.values()])\nprint(f\"[VAL] Avg predicted group size: {avg_group_size:.2f}\")\n# === Save checkpoint(s) ===\nSAVE_DIR = '/kaggle/working'\nos.makedirs(SAVE_DIR, exist_ok=True)\n\nckpt = {\n    'backbone_name': 'resnet50',\n    'feat_dim': model.num_features,       # для resnet50 = 2048\n    'emb_dim': 512,\n    'num_classes': NUM_CLASSES,\n    'arcface_cfg': {'s': 30.0, 'm': 0.5, 'easy_margin': False},\n    'state_dict': {\n        'backbone': model.state_dict(),\n        'embedding_head': embedding_head.state_dict(),\n        'arcface_head': arcface_head.state_dict(),\n    },\n    'label2id': label2id,                 # важно для повторного обучения/отчётов\n    'best_tau': float(best_tau),          # пригодится для инференса\n    'val_f1': float(best_f1),\n    'epoch': EPOCHS,\n}\n\ntorch.save(ckpt, os.path.join(SAVE_DIR, 'arcface_resnet50_shopee_ckpt.pth'))\nprint('[SAVE] Full checkpoint ->', os.path.join(SAVE_DIR, 'arcface_resnet50_shopee_ckpt.pth'))\n\n# Лёгкий пакет для инференса (без arcface головы и без оптимизатора)\nembed_pkg = {\n    'backbone_name': 'resnet50',\n    'feat_dim': model.num_features,\n    'emb_dim': 512,\n    'state_dict': {\n        'backbone': model.state_dict(),\n        'embedding_head': embedding_head.state_dict(),\n    },\n    'best_tau': float(best_tau),\n}\ntorch.save(embed_pkg, os.path.join(SAVE_DIR, 'embedding_extractor.pth'))\nprint('[SAVE] Embedding extractor ->', os.path.join(SAVE_DIR, 'embedding_extractor.pth'))\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:15:27.085231Z","iopub.execute_input":"2025-09-18T08:15:27.085546Z","iopub.status.idle":"2025-09-18T08:26:23.127173Z","shell.execute_reply.started":"2025-09-18T08:15:27.085529Z","shell.execute_reply":"2025-09-18T08:26:23.126335Z"}},"outputs":[{"name":"stderr","text":"Embed/val: 100%|██████████| 200/200 [00:44<00:00,  4.49it/s]       \n","output_type":"stream"},{"name":"stdout","text":"[VAL] Best F1=0.8970 at tau=0.72\n[VAL] Avg predicted group size: 1.65\n[SAVE] Full checkpoint -> /kaggle/working/arcface_resnet50_shopee_ckpt.pth\n[SAVE] Embedding extractor -> /kaggle/working/embedding_extractor.pth\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"#need inference notebook","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:26:23.128252Z","iopub.execute_input":"2025-09-18T08:26:23.129001Z","iopub.status.idle":"2025-09-18T08:26:23.132389Z","shell.execute_reply.started":"2025-09-18T08:26:23.128959Z","shell.execute_reply":"2025-09-18T08:26:23.131580Z"}},"outputs":[],"execution_count":26}]}