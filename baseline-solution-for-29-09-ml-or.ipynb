{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ð¡Ð¸Ð´Ñ‹","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\nimport os \n\nseed=42\n\nos.environ['PYTHONHASHSEED']=str(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, train_test_split\nimport pandas as pd\n# Ð’ÐÐ˜ÐœÐÐÐ˜Ð• Ð’ÐÐ˜ÐœÐÐÐ˜Ð• ÐŸÐ Ð•Ð”Ð˜ÐšÐ¢ ÐÐ ÐœÐ•Ð¢Ð Ð˜ÐšÐ£: f1_score \nfrom sklearn.metrics import f1_score\nfrom catboost import Pool, CatBoostClassifier, CatBoostRegressor\nimport matplotlib.pyplot as plt \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TEST MODE","metadata":{}},{"cell_type":"code","source":"TEST_MODE=True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('')\ntest=pd.read_csv('')\nsample=pd.read_csv('')\n\n#smth else?\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id_test=test['id']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# cat and num feats ","metadata":{}},{"cell_type":"code","source":"drop_nonsence=['']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train=train.drop(columns=drop_nonsence)\ntest=test.drop(columns=drop_nonsence)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_feats=train.select_dtypes(include='object').columns.tolist()\nnum_feats=train.drop(columns='target').select_dtypes(include='number').columns.tolist()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# If TEST MODE","metadata":{}},{"cell_type":"code","source":"if TEST_MODE:\n    train=train[:100]\nelse:\n    train=train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in num_feats:\n    plt.figure()\n    plt.hist(train[col])\n    \n    plt.xlabel(col)\n    plt.ylabel('Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð°')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in num_feats:\n    plt.figure()\n    plt.hist(test[col])\n    \n    plt.xlabel(col)\n    plt.ylabel('Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð°')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#for col in num_feats:\ncorrelation=train[num_feats].corrwith(train['target'])\nplt.figure()\ncorrelation.plot(kind='bar')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in cat_feats:\n    counts=train[col].value_counts()\n    plt.figure()\n    counts.plot(kind='bar')\n    plt.xlabel(col)\n    plt.ylabel('Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð°')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in cat_feats:\n    cat_crt=pd.crosstab(train['col'], train['target'], normalize='columns')*100\n    ax=cat_crt.plot(kind='bar')\n    ax.set_xlabel(col)\n    ax.set_ylabel('%')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cleaning???","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef _iqr_bounds(s: pd.Series, whisker: float = 1.5):\n    s = s.dropna()\n    if s.empty:\n        return np.nan, np.nan\n    q1 = s.quantile(0.25, interpolation=\"linear\")\n    q3 = s.quantile(0.75, interpolation=\"linear\")\n    iqr = q3 - q1\n    low = q1 - whisker * iqr\n    high = q3 + whisker * iqr\n    return low, high\n\ndef boxplot_clean(\n    df: pd.DataFrame,\n    num_feats,\n    by=None,                       # str or list[str] for group-wise bounds, or None for global\n    mode: str = \"remove\",          # \"remove\" = drop outlier rows, \"cap\" = winsorize to bounds\n    whisker: float = 1.5,\n    max_remove_frac: float = 0.10, # if > this would be removed, auto-cap instead\n    min_group_size: int = 20       # for small groups, fallback to global bounds\n):\n    out = df.copy()\n    records = []\n\n    if by is None:\n        # Global IQR per feature\n        for col in num_feats:\n            low, high = _iqr_bounds(out[col], whisker)\n            mask = (out[col] < low) | (out[col] > high)\n            n_out = int(mask.sum())\n            frac = n_out / max(len(out), 1)\n\n            if mode == \"remove\" and frac <= max_remove_frac:\n                out = out.loc[~mask].copy()\n                action = \"removed\"\n            elif mode == \"remove\" and frac > max_remove_frac:\n                out.loc[mask, col] = out.loc[mask, col].clip(lower=low, upper=high)\n                action = \"capped_due_to_fraction\"\n            else:  # mode == \"cap\"\n                out[col] = out[col].clip(lower=low, upper=high)\n                action = \"capped\"\n\n            records.append({\n                \"feature\": col, \"by\": None,\n                \"low\": low, \"high\": high,\n                \"n_outliers\": n_out, \"frac_outliers\": frac,\n                \"action\": action\n            })\n    else:\n        # Group-wise IQR per feature (by one or more categoricals)\n        keys = [by] if isinstance(by, str) else list(by)\n        # Handle NaNs in groups to ensure join works\n        for k in keys:\n            if out[k].isna().any():\n                out[k] = out[k].astype(object).fillna(\"__MISSING__\")\n\n        for col in num_feats:\n            g = out.groupby(keys, dropna=False)\n            qs = g[col].quantile([0.25, 0.75]).unstack(-1)\n            qs.columns = [\"q1\", \"q3\"]\n            sizes = g.size().rename(\"n\")\n            b = qs.join(sizes, how=\"left\")\n            b[\"iqr\"]  = b[\"q3\"] - b[\"q1\"]\n            b[\"low\"]  = b[\"q1\"] - whisker * b[\"iqr\"]\n            b[\"high\"] = b[\"q3\"] + whisker * b[\"iqr\"]\n\n            # Fallback to global bounds for small groups\n            low_g, high_g = _iqr_bounds(out[col], whisker)\n            small = b[\"n\"] < min_group_size\n            b.loc[small, [\"low\", \"high\"]] = [low_g, high_g]\n\n            # Join bounds to rows\n            out = out.merge(b[[\"low\", \"high\"]], left_on=keys, right_index=True, how=\"left\")\n            mask = (out[col] < out[\"low\"]) | (out[col] > out[\"high\"])\n            n_out = int(mask.sum())\n            frac = n_out / max(len(out), 1)\n\n            if mode == \"remove\" and frac <= max_remove_frac:\n                out = out.loc[~mask].copy()\n                action = \"removed\"\n            elif mode == \"remove\" and frac > max_remove_frac:\n                out.loc[mask, col] = out.loc[mask, col].clip(lower=out.loc[mask, \"low\"], upper=out.loc[mask, \"high\"])\n                action = \"capped_due_to_fraction\"\n            else:  # mode == \"cap\"\n                out[col] = out[col].clip(lower=out[\"low\"], upper=out[\"high\"])\n                action = \"capped\"\n\n            out = out.drop(columns=[\"low\", \"high\"])  # cleanup\n            records.append({\n                \"feature\": col, \"by\": \"+\".join(keys),\n                \"low\": low_g, \"high\": high_g,  # global fallback (for reference)\n                \"n_outliers\": n_out, \"frac_outliers\": frac,\n                \"action\": action\n            })\n\n    report = pd.DataFrame.from_records(records)\n    return out, report.sort_values([\"frac_outliers\", \"feature\"], ascending=[False, True]).reset_index(drop=True)\n\ndef plot_boxplots(df: pd.DataFrame, num_cols, by: str | None = None, max_cols: int = 6, figsize=(12, 8)):\n    \"\"\"Quick visual check: draws simple matplotlib boxplots (no seaborn).\"\"\"\n    cols = list(num_cols)[:max_cols]\n    n = len(cols)\n    ncols = min(3, n)\n    nrows = (n + ncols - 1) // ncols\n    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n    axes = np.atleast_1d(axes).ravel()\n\n    for ax, col in zip(axes, cols):\n        if by is None:\n            ax.boxplot(df[col].dropna(), vert=True, showfliers=True)\n            ax.set_title(col)\n            ax.set_xticks([])\n        else:\n            # Show up to top-10 categories by frequency\n            topcats = df[by].astype(\"object\").value_counts().head(10).index\n            data = [df.loc[df[by] == cat, col].dropna() for cat in topcats]\n            ax.boxplot(data, vert=True, showfliers=True)\n            ax.set_title(f\"{col} by {by}\")\n            ax.set_xticklabels([str(c) for c in topcats], rotation=45, ha=\"right\")\n\n    # Hide any unused axes\n    for j in range(len(cols), len(axes)):\n        fig.delaxes(axes[j])\n\n    fig.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Global cleaning (per feature)\ntrain_clean, outlier_report = boxplot_clean(\n    train, num_feats,\n    mode=\"remove\",        # or \"cap\"\n    whisker=1.5,          # 1.5 (standard), 3.0 (more conservative)\n    max_remove_frac=0.10  # auto-cap if >10% would be dropped\n)\n\n\ntest_clean, outlier_report_test = boxplot_clean(\n    test, num_feats,\n    mode=\"remove\",        # or \"cap\"\n    whisker=1.5,          # 1.5 (standard), 3.0 (more conservative)\n    max_remove_frac=0.10  # auto-cap if >10% would be dropped\n)\n# 2) Group-wise cleaning by a categorical (e.g., the most important from your cat_feats)\n#    Use \"cap\" to be gentler on row counts\n#'''\n#train_clean_by_store, report_store = boxplot_clean(\n#    train, num_feats,\n#    by=\"store_id\",        # or any one of your cat_feats\n#    mode=\"cap\",\n#    whisker=1.5\n#)\n#'''\n# 3) Quick visual check (before / after)\nplot_boxplots(train, num_feats, max_cols=6)           # before\nplot_boxplots(train_clean, num_feats, max_cols=6)     # after\n\n# 4) (Optional) Iterate through a few key categoricals one by one (be cautious: sequential passes get stricter)\n# for c in [\"store_id\", \"item_category\"]:  # pick 1â€“2 most relevant cats from cat_feats\n#     train, _ = boxplot_clean(train, num_feats, by=c, mode=\"cap\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"code","source":"def featurize(df):\n    df['logical_square_']=df['']**2\n    \n    df['logical_sqrt_']=np.sqrt(df[''])\n\n    df['logical_mutliplication_']=df['']*df['']\n\n    df['logical_ratio_']=df['']/df['']\n\n    #space for any creative features my dude \n    df['']=\n\n\n\n\n\n\n\n    \n\n\n\n    \n    \n    # end of space my dudeeeeeeee\n\n    #kinda multiplication for categorical(if any ofc)\n\n    df['multi_cat_']=df[''] + '_' + df['']\n\n\n    #squares for categorical  ðŸ¤¡ðŸ¤¡ðŸ¤¡ðŸ’€ðŸ’€ðŸ’€\n\n    df['square_cat_']=df[''] + '_' + df['']\n\n    return df\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_full=featurize(train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_full=featurize(test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# skf catboost","metadata":{}},{"cell_type":"markdown","source":"## maybe diffirent hyperharameters for catboost?","metadata":{}},{"cell_type":"code","source":"model_cfgs=[\n    \n    dict(name='',\n        params=dict()),\n    \n    dict(name='',\n        params=dict()),\n    \n    dict(name='',\n        params=dict()),\n    \n    dict(name='',\n        params=dict()),\n    \n    dict(name='',\n        params=dict()),\n    \n    \n    \n]\n#find them my dudeeeee","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for classification:\n'''\nmodel_cfgs = [\n    # Long-run, small LR, Bayesian bootstrap â€” a common winner pattern for AUC, esp. S4E7\n    dict(name='PS_LongRun_Bayesian_AUC_Imbalanced',\n         params=dict(\n             loss_function='Logloss',\n             eval_metric='AUC',\n             iterations=30000,\n             learning_rate=0.02,\n             depth=8,\n             l2_leaf_reg=10.0,\n             bootstrap_type='Bayesian',\n             bagging_temperature=0.5,\n             border_count=254,\n             random_strength=1.0,\n             use_best_model=True,\n             od_type='Iter',\n             od_wait=300,\n             auto_class_weights='Balanced',\n             random_seed=42\n         )),\n\n    # Fast, strong CPU default using MVS bootstrap (CatBoostâ€™s CPU default for many cases)\n    dict(name='PS_MVS_CPU_Fast',\n         params=dict(\n             loss_function='Logloss',\n             eval_metric='AUC',\n             iterations=8000,\n             learning_rate=0.05,\n             depth=6,\n             l2_leaf_reg=8.0,\n             bootstrap_type='MVS',\n             subsample=0.8,          # active for MVS\n             # mvs_reg can be tuned; omit to use auto\n             random_strength=2.0,\n             border_count=254,\n             use_best_model=True,\n             od_type='Iter',\n             od_wait=200,\n             auto_class_weights='Balanced',\n             random_seed=42\n         )),\n\n    # Robust Bernoulli (SGB-style) bagging; good regularization, stable across folds\n    dict(name='PS_Bernoulli_SGB_Robust',\n         params=dict(\n             loss_function='Logloss',\n             eval_metric='AUC',\n             iterations=15000,\n             learning_rate=0.03,\n             depth=8,\n             l2_leaf_reg=12.0,\n             bootstrap_type='Bernoulli',\n             subsample=0.66,         # classic SGB rate\n             random_strength=1.5,\n             border_count=254,\n             use_best_model=True,\n             od_type='Iter',\n             od_wait=300,\n             auto_class_weights='Balanced',\n             random_seed=42\n         )),\n\n    # GPU-heavy: Poisson bootstrap + Lossguide grow policy for wide/high-card data\n    dict(name='PS_GPU_Poisson_Lossguide_BigData',\n         params=dict(\n             loss_function='Logloss',\n             eval_metric='AUC',\n             task_type='GPU',\n             iterations=20000,\n             learning_rate=0.03,\n             grow_policy='Lossguide',\n             max_leaves=63,          # keep <=64 for speed/quality balance\n             min_data_in_leaf=20,\n             bootstrap_type='Poisson',  # GPU-only\n             subsample=0.66,\n             border_count=128,       # 128 often best balance on GPU\n             l2_leaf_reg=6.0,\n             random_strength=1.0,\n             use_best_model=True,\n             od_type='Iter',\n             od_wait=200,\n             auto_class_weights='Balanced',\n             random_seed=42\n         )),\n\n    # Newton leaf updates (second-order) + mild Bayesian bagging â€” strong on many tabular AUC tasks\n    dict(name='PS_Newton_LeafEstimation_StrongReg',\n         params=dict(\n             loss_function='Logloss',\n             eval_metric='AUC',\n             iterations=15000,\n             learning_rate=0.03,\n             depth=10,\n             l2_leaf_reg=12.0,\n             leaf_estimation_method='Newton',\n             leaf_estimation_iterations=10,\n             bootstrap_type='Bayesian',\n             bagging_temperature=0.25,\n             border_count=254,\n             random_strength=1.0,\n             use_best_model=True,\n             od_type='Iter',\n             od_wait=300,\n             auto_class_weights='Balanced',\n             random_seed=42\n         )),\n]\n'''\n\n\n\n\n# for regression:\n\n'''\nmodel_cfgs = [\n    # 1) Long-run, tiny LR, Bayesian bagging â€” great default for RMSE-driven tabular\n    dict(name='PS_Reg_LongRun_Bayesian_RMSE',\n         params=dict(\n             loss_function='RMSE',\n             eval_metric='RMSE',\n             iterations=30000,\n             learning_rate=0.02,\n             depth=8,\n             l2_leaf_reg=10.0,\n             bootstrap_type='Bayesian',\n             bagging_temperature=0.5,\n             border_count=254,     # CPU: finer bins\n             rsm=0.8,              # CPU only\n             random_strength=1.0,\n             early_stopping_rounds=300,\n             use_best_model=True,\n             random_seed=42\n         )),\n\n    # 2) Fast, strong CPU setup using MVS bootstrap (good when you want speed)\n    dict(name='PS_Reg_MVS_CPU_Fast',\n         params=dict(\n             loss_function='RMSE',\n             eval_metric='RMSE',\n             iterations=8000,\n             learning_rate=0.05,\n             depth=6,\n             l2_leaf_reg=8.0,\n             bootstrap_type='MVS',\n             subsample=0.8,        # active with MVS\n             rsm=0.9,              # CPU only\n             random_strength=1.5,\n             border_count=254,\n             early_stopping_rounds=200,\n             use_best_model=True,\n             random_seed=42\n         )),\n\n    # 3) Robust to outliers using Huber loss (heavy-tailed targets)\n    dict(name='PS_Reg_Huber_Outliers',\n         params=dict(\n             loss_function='Huber:delta=1.0',\n             eval_metric='RMSE',\n             iterations=20000,\n             learning_rate=0.03,\n             depth=8,\n             l2_leaf_reg=12.0,\n             bootstrap_type='Bernoulli',\n             subsample=0.66,\n             border_count=254,\n             random_strength=1.0,\n             early_stopping_rounds=300,\n             use_best_model=True,\n             random_seed=42\n         )),\n\n    # 4) Insurance/zero-inflated style targets (Tweedie GLM-like objective)\n    dict(name='PS_Reg_Tweedie_Exposure',\n         params=dict(\n             loss_function='Tweedie:variance_power=1.5',  # tune 1.2â€“1.8\n             eval_metric='RMSE',\n             iterations=20000,\n             learning_rate=0.03,\n             depth=8,\n             l2_leaf_reg=10.0,\n             bootstrap_type='Bayesian',\n             bagging_temperature=0.25,\n             border_count=254,\n             rsm=0.8,              # CPU only\n             random_strength=1.0,\n             early_stopping_rounds=300,\n             use_best_model=True,\n             random_seed=42\n         )),\n\n    # 5) Wide/high-card data on GPU â€” Lossguide + Poisson bootstrap\n    dict(name='PS_Reg_GPU_Lossguide_BigData',\n         params=dict(\n             task_type='GPU',\n             loss_function='RMSE',\n             eval_metric='RMSE',\n             iterations=20000,\n             learning_rate=0.03,\n             grow_policy='Lossguide',\n             max_leaves=63,        # keep â‰¤64 for speed/quality\n             min_data_in_leaf=20,\n             bootstrap_type='Poisson',  # GPU-only\n             subsample=0.66,\n             border_count=128,     # GPU bin count\n             l2_leaf_reg=6.0,\n             random_strength=1.0,\n             early_stopping_rounds=200,\n             use_best_model=True,\n             random_seed=42\n         )),\n]\n\n\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X=train_full.drop('target')\ny=train_full['target']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_feats_full=train_full.select_dtypes(include='object').columns.tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ð”Ð»Ñ Classifier Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ±Ð¾Ñ€ Ñ‚Ñ€ÐµÑˆÑ…Ð¾Ð»Ð´Ð°(predict_proba)","metadata":{}},{"cell_type":"code","source":"skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=seed) #Or just KFold, one word is the diffirence \nn_models=len(model_cfgs)\nn_folds=5\noof_preds=np.zeros((len(y), n_models), dtype=float)\ntest_preds=np.zeros(len(test_full), n_models), dtype=float)\n\ncv_scores=[]\n\ntest_pool=Pool(\n    data=test_full\n)\n\nfor m_idx, cfg in enumerate(model_cfgs):\n    name, params=cfg['name'], cfg['params']\n    oof_pred=np.zeros(len(y), dtype=float)\n    test_pred=np.zeros(len(test_full), dtype=float)\n    fold_metric=[]\n    for fold, (train_idx, eval_idx) in enumerate(skf.split(X,y), 1):\n        X_train=X.iloc[train_idx]\n        X_eval=X.iloc[eval_idx]\n        y_train=y.iloc[train_idx]\n        y_eval=y.iloc[eval_idx]\n\n        train_pool=Pool(\n            data=X_train,\n            label=y_train,\n            cat_features=cat_feats_full,\n        \n        )\n        eval_pool=Pool(\n            data=X_eval,\n            label=y_eval,\n            cat_features=cat_feats_full,\n        \n        )\n        model=CatBoostClassifier(        # Ð½Ñƒ Ð¸Ð»Ð¸ Regressor\n            **params\n        )\n        model.fit(train_pool, eval_set=eval_pool, verbose=200, use_best_model=True, early_stopping_rounds=400)\n        eval_pred=model.predict(eval_pool)\n        oof_pred[eval_idx]=eval_pred\n        fold_metric.append((y_eval, eval_pred))\n\n        test_pred+=model.predict(test_pool)/n_folds\n    print(f'CV :{np.mean(fold_metric):.5f} +- {np.std(fold_metric):.5f}')\n    oof_preds[:, m_idx]=oof_pred\n    test_preds[:, m_idx]=test_pred\n    model_cv=(np.mean(fold_metric), np.std(fold_metric))\n    cv_scores.append(name, *model_cv)\n    print(f'CV :{model_cv[0]:.5f} Â± {model_cv[1]:.5f}')\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Meta models","metadata":{}},{"cell_type":"code","source":"colnames=[cfg['name'] for cfg in model_cfgs]\noof_df=pd.DataFrame(oof_preds, columns=colnames)\ntest_df=pd.DataFrame(test_preds, columns=colnames)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Linreg over predictions(meta model)","metadata":{}},{"cell_type":"code","source":"model_lasso=Lasso(alpha=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_lasso.fit(oof_df, y)\n\nlinreg_test_pred = model_lasso.predict(test_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub1=pd.DataFrame({\n    'id': sample['id'],\n    'target' : linreg_test_pred\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub1.to_csv('sub_lasso_as_meta_model_first_try.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Catboost over predictions(meta model)","metadata":{}},{"cell_type":"code","source":"model_cat=CatBoostClassifier( # or Regressor\n    iterations=500,\n    depth=3,\n    learning_rate=0.05,\n    l2_leaf_reg=10.0,\n    task_type='GPU',\n    devices='0',\n   # loss_function='RMSE',\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_cat.fit(oof_df, y, verbose=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"catboost_test_pred=model_cat.predict(test_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub2=pd.DataFrame({\n    'id':sample['id'],\n    'target': catboost_test_pred\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub2.to_csv('catboost_as_meta_model_first_try_gol.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Just average of skf catboost","metadata":{}},{"cell_type":"code","source":"blend = test_df.mean(axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub3=pd.DataFrame({\n    'id': sample['id'],\n    'target': blend\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub3.to_csv('just_a_blend_oout_of_skf.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# optuna for better ensemble ÐœÐ•Ð¢Ð Ð˜ÐšÐ£ ÐŸÐžÐœÐ•ÐÐ¯Ð¢Ð¬ ","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n     raw = np.array([trial.suggest_float(f\"w{i}\", 0.0, 1.0) for i in range(n_models)])\n     w = raw / (raw.sum() + 1e-12)\n     blend = oof_df.values @ w\n     return mean_squared_error(y, blend, squared=False) \n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=200)\nbest_raw = np.array([study.best_params[f\"w{i}\"] for i in range(n_models)])\nw = best_raw / (best_raw.sum() + 1e-12)\nprint(\"Best weights:\", dict(zip(colnames, w.round(4))))\ntest_blend = test_df.values @ w\n\n#Ð¡Ð²Ð¾Ñ€Ð¾Ð²Ð°Ð» Ð½Ð¾ Ð¿Ð¾Ð½ÑÐ» Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚, Ð½Ð°Ð´Ð¾ ÑÐ°Ð¼Ð¸Ð¼ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð² ÑÐ»ÐµÐ´ Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐµ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub4=pd.DataFrame({\n    'id': sample['id'],\n    'target': test_blend\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub4.to_csv('ensemble_skf_optuna.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Average of all submissions(or optuna of all submissions, idk) or both my dude ","metadata":{}},{"cell_type":"code","source":"mean_pred = pd.concat([\n    pd.Series(catboost_test_pred, index=test_df.index, name='catboost'),\n    pd.Series(linreg_test_pred,   index=test_df.index, name='linreg'),\n    pd.Series(blend,              index=test_df.index, name='blend'),\n    pd.Series(test_blend,         index=test_df.index, name='optuna_blend'),\n], axis=1).mean(axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub5=pd.DataFrame({\n    'id': sample['id'],\n    'target':mean_pred\n    \n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub5.to_csv('mean_of_all_subs_my_dude.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ÐœÐ•Ð¢Ð Ð˜ÐšÐ£ ÐŸÐžÐœÐ•ÐÐ¯Ð¢Ð¬  Ð Ð•Ð©Ð• Ð›Ð˜ÐÐ Ð•Ð“ Ð”ÐžÐ‘ÐÐ’Ð˜Ð¢Ð¬ ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nimport optuna\n\n# --- 1) Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ð°Ñ€Ñ‹ (OOF, TEST) Ð´Ð»Ñ Ñ‚Ñ€Ñ‘Ñ… Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² ---\n# ÐŸÑ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñƒ Ñ‚ÐµÐ±Ñ ÑƒÐ¶Ðµ ÐµÑÑ‚ÑŒ:\n# y               : pandas Series Ð´Ð»Ð¸Ð½Ñ‹ N (Ñ‚Ð°Ñ€Ð³ÐµÑ‚ train)\n# oof_df, test_df : Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ OOF/TEST Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ (DataFrame)\n# w               : Ð²ÐµÑÐ° Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ blend Ð¸Ð· Optuna (Ð¿Ð¾ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð°Ð¼ oof_df/test_df)\n# blend           : Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ ÑÑ€ÐµÐ´Ð½Ð¸Ð¹ Ð¿Ð¾ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°Ð¼ test_df (Series)\n# test_blend      : Ð²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾ w Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ blend (ndarray/Series)\n# catboost_oof_pred, catboost_test_pred : OOF/TEST Ð¸Ð· CatBoost-Ð¼Ð¾Ð´ÐµÐ»Ð¸\n\n# OOF Ð´Ð»Ñ mean Ð¸ opt_w:\noof_mean = oof_df.mean(axis=1).values                    # shape (N,)\noof_opt  = (oof_df.values @ w).ravel()                   # shape (N,)\n\n# ÐŸÑ€Ð¸Ð²Ð¾Ð´Ð¸Ð¼ TEST-ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹ Ðº Series Ñ ÐµÐ´Ð¸Ð½Ñ‹Ð¼ Ð¸Ð½Ð´ÐµÐºÑÐ¾Ð¼ (ÐºÐ°Ðº Ñƒ blend/test_df)\ntest_index = getattr(blend, 'index', None) or getattr(test_df, 'index', None)\ncatboost_test_s = pd.Series(np.asarray(catboost_test_pred).ravel(), index=test_index, name='catboost')\n#linreg_test_s = pd.Series(np.asarray(linreg_test_pred).ravel(), index=test_index, name='lasso')\n\nblend_s         = blend.rename('mean') if hasattr(blend, 'rename') else pd.Series(np.asarray(blend).ravel(), index=test_index, name='mean')\ntest_blend_s    = pd.Series(np.asarray(test_blend).ravel(), index=test_index, name='opt_w')\n\n# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ„Ð¾Ñ€Ð¼ Ð¸ Ð´Ð»Ð¸Ð½\nassert len(y) == len(oof_mean) == len(oof_opt) == len(catboost_oof_pred)\nassert len(catboost_test_s) == len(blend_s) == len(test_blend_s)\n\n# Ð¡Ñ‚ÐµÐº OOF (N x 3) Ð¸ TEST (T x 3)\noof_stack  = np.column_stack([\n    np.asarray(catboost_oof_pred).ravel(),  # catboost\n    oof_mean,                               # mean\n    oof_opt,                                 # opt_w (Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ð¹)\n    #np.asarray(linreg_oof_pred).ravel()\n])\ntest_stack = np.column_stack([\n    catboost_test_s.values,\n    blend_s.values,\n    test_blend_s.values,\n   # linreg_test_s.values,\n])\nnames = ['catboost', 'mean', 'opt_w']\n\n# --- 2) ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²ÐµÑÐ¾Ð² Ð¿Ð¾ OOF Ñ‡ÐµÑ€ÐµÐ· Optuna ---\ndef objective(trial):\n    raw = np.array([trial.suggest_float(f\"w_{n}\", 0.0, 1.0) for n in names], dtype=float)\n    w2  = raw / (raw.sum() + 1e-12)                 # simplex\n    blend_oof = oof_stack @ w2\n    rmse = mean_squared_error(y, blend_oof, squared=False)\n    return rmse\n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=300, show_progress_bar=False)\n\nbest_raw = np.array([study.best_params[f\"w_{n}\"] for n in names], dtype=float)\nw2 = best_raw / (best_raw.sum() + 1e-12)\nprint(\"Best weights (catboost, mean, opt_w):\", dict(zip(names, np.round(w2, 4))))\n\n# --- 3) Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ TEST-Ð±Ð»ÐµÐ½Ð´ Ð¸Ð· Ñ‚Ñ€Ñ‘Ñ… Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² ---\nfinal_test_pred = test_stack @ w2  # shape (T,)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub6=pd.DataFrame({\n    'id': sample['id'],\n    'target': final_test_pred\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub6.to_csv('optuna_of_all_my_subs_first_try.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}