{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":24286,"databundleVersionId":1878097,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Сиды","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport os\nimport random\n    \n\nseed=42\n\nos.environ['PYTHONHASHSEED']=str(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:09.988947Z","iopub.execute_input":"2025-10-10T09:23:09.989775Z","iopub.status.idle":"2025-10-10T09:23:13.990389Z","shell.execute_reply.started":"2025-10-10T09:23:09.989740Z","shell.execute_reply":"2025-10-10T09:23:13.989615Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:13.991832Z","iopub.execute_input":"2025-10-10T09:23:13.992253Z","iopub.status.idle":"2025-10-10T09:23:14.060585Z","shell.execute_reply.started":"2025-10-10T09:23:13.992234Z","shell.execute_reply":"2025-10-10T09:23:14.059813Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Импорты","metadata":{}},{"cell_type":"code","source":"from torch import nn\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import v2\nimport tqdm \nfrom tqdm import tqdm\nfrom PIL import Image\nimport math\nfrom transformers import AutoTokenizer, AutoModel\nimport joblib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:14.061475Z","iopub.execute_input":"2025-10-10T09:23:14.061737Z","iopub.status.idle":"2025-10-10T09:23:24.560673Z","shell.execute_reply.started":"2025-10-10T09:23:14.061714Z","shell.execute_reply":"2025-10-10T09:23:24.559901Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# TEST MODE","metadata":{}},{"cell_type":"code","source":"TEST_MODE=True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.561516Z","iopub.execute_input":"2025-10-10T09:23:24.561920Z","iopub.status.idle":"2025-10-10T09:23:24.566165Z","shell.execute_reply.started":"2025-10-10T09:23:24.561900Z","shell.execute_reply":"2025-10-10T09:23:24.565032Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')\ntest=pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')\nsample=pd.read_csv('/kaggle/input/shopee-product-matching/sample_submission.csv')\n\ntrain_img_dir='/kaggle/input/shopee-product-matching/train_images'\ntest_img_dir='/kaggle/input/shopee-product-matching/test_images'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.568138Z","iopub.execute_input":"2025-10-10T09:23:24.568346Z","iopub.status.idle":"2025-10-10T09:23:24.812852Z","shell.execute_reply.started":"2025-10-10T09:23:24.568330Z","shell.execute_reply":"2025-10-10T09:23:24.812102Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.813510Z","iopub.execute_input":"2025-10-10T09:23:24.813751Z","iopub.status.idle":"2025-10-10T09:23:24.851530Z","shell.execute_reply.started":"2025-10-10T09:23:24.813727Z","shell.execute_reply":"2025-10-10T09:23:24.850771Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"posting_id     34250\nimage          32412\nimage_phash    28735\ntitle          33117\nlabel_group    11014\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"if TEST_MODE:\n    #train=train.sample(n=100, random_state=seed).reset_index(drop=True)\n    train=train[:32000]\nelse:\n    train=train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.852239Z","iopub.execute_input":"2025-10-10T09:23:24.852476Z","iopub.status.idle":"2025-10-10T09:23:24.856466Z","shell.execute_reply.started":"2025-10-10T09:23:24.852459Z","shell.execute_reply":"2025-10-10T09:23:24.855711Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Маппинг","metadata":{}},{"cell_type":"code","source":"label2id = {lg: i for i, lg in enumerate(sorted(train['label_group'].unique()))}\nid2label = {i: lg for lg, i in label2id.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.857233Z","iopub.execute_input":"2025-10-10T09:23:24.857495Z","iopub.status.idle":"2025-10-10T09:23:24.885144Z","shell.execute_reply.started":"2025-10-10T09:23:24.857474Z","shell.execute_reply":"2025-10-10T09:23:24.884207Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train['class_id']=train['label_group'].map(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.885862Z","iopub.execute_input":"2025-10-10T09:23:24.886099Z","iopub.status.idle":"2025-10-10T09:23:24.938088Z","shell.execute_reply.started":"2025-10-10T09:23:24.886079Z","shell.execute_reply":"2025-10-10T09:23:24.937398Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## train_test_split","metadata":{}},{"cell_type":"code","source":"train_data, eval_data=train_test_split(train, test_size=0.2)\n#stratify=train['class_id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.939123Z","iopub.execute_input":"2025-10-10T09:23:24.939551Z","iopub.status.idle":"2025-10-10T09:23:24.951646Z","shell.execute_reply.started":"2025-10-10T09:23:24.939527Z","shell.execute_reply":"2025-10-10T09:23:24.950900Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Датасет","metadata":{}},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    def __init__(self, df, img_root, transform, train):\n        self.df=df\n        self.img_root=img_root\n        self.transform=transform\n        self.train=train\n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        image_path=row['image']\n        image_path_all=os.path.join(self.img_root, f'{image_path}')\n        image=Image.open(image_path_all).convert('RGB')\n\n        if self.transform is not None:\n            image=self.transform(image)\n        else:\n            image=image\n        \n        if self.train:\n            return({\n                'image': image,\n                'label': torch.tensor(row['class_id'], dtype=torch.long),\n                'posting_id': row['posting_id']\n            })\n        else:\n            return({\n                'image': image,\n                'posting_id': row['posting_id']\n            })\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.952360Z","iopub.execute_input":"2025-10-10T09:23:24.952596Z","iopub.status.idle":"2025-10-10T09:23:24.959491Z","shell.execute_reply.started":"2025-10-10T09:23:24.952580Z","shell.execute_reply":"2025-10-10T09:23:24.958600Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# === TEXT dataset / loaders ===\nclass ShopeeTextDataset(Dataset):\n    def __init__(self, df, is_train=True):\n        self.df = df.reset_index(drop=True)\n        self.is_train = is_train\n    def __len__(self): return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        item = {\n            'title': str(row['title']) if not pd.isna(row['title']) else '',\n            'posting_id': row['posting_id'],\n        }\n        if self.is_train:\n            item['label'] = torch.tensor(row['class_id'], dtype=torch.long)\n        return item\n\ntrain_text_ds = ShopeeTextDataset(train_data, is_train=True)\neval_text_ds  = ShopeeTextDataset(eval_data,  is_train=True)\n\ntrain_text_loader = DataLoader(train_text_ds, batch_size=128, shuffle=True,\n                               num_workers=4, pin_memory=True, persistent_workers=True, drop_last=True)\neval_text_loader  = DataLoader(eval_text_ds,  batch_size=256, shuffle=False,\n                               num_workers=4, pin_memory=True, persistent_workers=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.960337Z","iopub.execute_input":"2025-10-10T09:23:24.960919Z","iopub.status.idle":"2025-10-10T09:23:24.987567Z","shell.execute_reply.started":"2025-10-10T09:23:24.960893Z","shell.execute_reply":"2025-10-10T09:23:24.986906Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Аугментации ","metadata":{}},{"cell_type":"code","source":"transforms_train=v2.Compose([\n    v2.Resize((224, 224)), \n    v2.RandomHorizontalFlip(),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntransforms_eval=v2.Compose([\n    v2.Resize((224,224)),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransforms_test=v2.Compose([\n    v2.Resize((224,224)),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.988430Z","iopub.execute_input":"2025-10-10T09:23:24.988886Z","iopub.status.idle":"2025-10-10T09:23:24.995577Z","shell.execute_reply.started":"2025-10-10T09:23:24.988835Z","shell.execute_reply":"2025-10-10T09:23:24.994828Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Создание датасетов","metadata":{}},{"cell_type":"code","source":"train_dataset=ShopeeDataset(train_data, train_img_dir, transform=transforms_train, train=True)\neval_dataset=ShopeeDataset(eval_data,train_img_dir, transform=transforms_eval, train=True)\ntest_dataset=ShopeeDataset(test, test_img_dir, transform=transforms_test, train=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:24.998209Z","iopub.execute_input":"2025-10-10T09:23:24.998466Z","iopub.status.idle":"2025-10-10T09:23:25.011693Z","shell.execute_reply.started":"2025-10-10T09:23:24.998450Z","shell.execute_reply":"2025-10-10T09:23:25.010963Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Даталоадеры","metadata":{}},{"cell_type":"code","source":"train_dataloader=DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\neval_dataloader=DataLoader(eval_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_dataloader=DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:25.012459Z","iopub.execute_input":"2025-10-10T09:23:25.012694Z","iopub.status.idle":"2025-10-10T09:23:25.026155Z","shell.execute_reply.started":"2025-10-10T09:23:25.012675Z","shell.execute_reply":"2025-10-10T09:23:25.025376Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Кол-во эпох","metadata":{}},{"cell_type":"code","source":"EPOCHS=5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:25.026933Z","iopub.execute_input":"2025-10-10T09:23:25.027191Z","iopub.status.idle":"2025-10-10T09:23:25.040913Z","shell.execute_reply.started":"2025-10-10T09:23:25.027168Z","shell.execute_reply":"2025-10-10T09:23:25.040144Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Model for image","metadata":{}},{"cell_type":"code","source":"model=timm.create_model('eca_nfnet_l1', pretrained=True,  num_classes=0).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:25.041893Z","iopub.execute_input":"2025-10-10T09:23:25.042154Z","iopub.status.idle":"2025-10-10T09:23:29.586329Z","shell.execute_reply.started":"2025-10-10T09:23:25.042131Z","shell.execute_reply":"2025-10-10T09:23:29.585532Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27f64ee982a04017b8e2e4164342b1e8"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"def build_image_embeddings(loader):\n    embs, ids, labels_opt = [], [], []\n    for b in tqdm(loader, desc=\"Embed/img\"):\n        x = b['image'].to(device, non_blocking=True)\n        e = model(x)\n        e = embedding_head(e)\n        e = nn.functional.normalize(e, dim=1)\n        embs.append(e.cpu())\n        ids.extend(b['posting_id'])\n        if 'label' in b:\n            labels_opt.extend(b['label'].cpu().numpy().tolist())\n    embs = torch.cat(embs, dim=0).numpy().astype('float32')  # (N, 512)\n    embs /= (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-8)\n    return embs, ids, (np.array(labels_opt) if labels_opt else None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:29.587176Z","iopub.execute_input":"2025-10-10T09:23:29.587398Z","iopub.status.idle":"2025-10-10T09:23:29.593422Z","shell.execute_reply.started":"2025-10-10T09:23:29.587382Z","shell.execute_reply":"2025-10-10T09:23:29.592567Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Model for text","metadata":{}},{"cell_type":"code","source":"# === TEXT encoder (XLM-RoBERTa) finetune + ArcFace head ===\nTEXT_MODEL_NAME = 'xlm-roberta-base'\ntext_tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME, use_fast=True)\ntext_model = AutoModel.from_pretrained(TEXT_MODEL_NAME).to(device)  # будет тренироваться\ntext_feat_dim = text_model.config.hidden_size  # 768\n\ntext_embedding_head = nn.Sequential(\n    nn.Linear(text_feat_dim, 512, bias=False),\n    nn.BatchNorm1d(512)\n).to(device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:29.594295Z","iopub.execute_input":"2025-10-10T09:23:29.594572Z","iopub.status.idle":"2025-10-10T09:23:57.276273Z","shell.execute_reply.started":"2025-10-10T09:23:29.594549Z","shell.execute_reply":"2025-10-10T09:23:57.275511Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e20a27f27ed54237b27fe58a886e896d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa37d017726a44789fa62595409a3666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0febd8360a914c2a8277c574f74e817c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b4f1cdbbcf4a309f225a8b1bc6cc00"}},"metadata":{}},{"name":"stderr","text":"2025-10-10 09:23:39.633070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760088219.820729      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760088219.879437      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b61a1df457fd42e1b7583e39934b4845"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"@torch.no_grad()\ndef build_text_embeddings_for_df(df, batch_size=256, max_len=64):\n    \"\"\"\n    Возвращает L2-нормированные эмбеддинги заголовков (N, 768) в float16.\n    Порядок совпадает с df.\n    \"\"\"\n    titles = df['title'].fillna('').astype(str).tolist()\n    embs = []\n    for start in tqdm(range(0, len(titles), batch_size), desc=\"Embed/text\"):\n        batch = titles[start:start+batch_size]\n        tok = text_tokenizer(batch, padding=True, truncation=True,\n                             max_length=max_len, return_tensors='pt')\n        tok = {k: v.to(device, non_blocking=True) for k, v in tok.items()}\n        out = text_model(**tok)\n        sent = mean_pooling(out.last_hidden_state, tok['attention_mask'])  # (B, 768)\n        sent = nn.functional.normalize(sent, dim=1)\n        embs.append(sent.cpu())\n    embs = torch.cat(embs, dim=0).numpy().astype('float32')  # (N,768)\n    # safety L2 + экономия RAM\n    norms = np.linalg.norm(embs, axis=1, keepdims=True) + 1e-8\n    return (embs / norms).astype('float16')\n\ndef topk_chunked_cos(embs_f16: np.ndarray, K: int, qbs: int = 128):\n    \"\"\"\n    OOM-safe top-K по косинусу с помощью torch (без FAISS).\n    embs_f16: (N, D) float16, L2-нормированные\n    Возвращает sims, idxs: по (N, K) в float32 / int32\n    \"\"\"\n    N, D = embs_f16.shape\n    device_t = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    db = torch.from_numpy(embs_f16.astype('float32', copy=False)).to(device_t, non_blocking=True)\n\n    K = min(K, N)\n    idxs_list, sims_list = [], []\n    for start in tqdm(range(0, N, qbs), desc=\"TopK (torch-chunk)\"):\n        q = db[start:start+qbs]                 # (qbs, D)\n        S = torch.matmul(q, db.T)               # (qbs, N) — косинус\n        vals, ids = torch.topk(S, k=K, dim=1, largest=True, sorted=True)\n        idxs_list.append(ids.cpu().numpy().astype('int32'))\n        sims_list.append(vals.cpu().numpy().astype('float32'))\n        del S, vals, ids\n        if device_t.type == 'cuda':\n            torch.cuda.empty_cache()\n    idxs = np.vstack(idxs_list)   # (N, K)\n    sims = np.vstack(sims_list)   # (N, K)\n    del db\n    return sims, idxs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:57.277050Z","iopub.execute_input":"2025-10-10T09:23:57.278361Z","iopub.status.idle":"2025-10-10T09:23:57.287840Z","shell.execute_reply.started":"2025-10-10T09:23:57.278341Z","shell.execute_reply":"2025-10-10T09:23:57.287062Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"feat_dim = model.num_features \n\nembedding_head = nn.Sequential(\n    nn.Linear(feat_dim, 512, bias=False),\n    nn.BatchNorm1d(512)\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:57.289491Z","iopub.execute_input":"2025-10-10T09:23:57.289729Z","iopub.status.idle":"2025-10-10T09:23:58.669190Z","shell.execute_reply.started":"2025-10-10T09:23:57.289708Z","shell.execute_reply":"2025-10-10T09:23:58.668392Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# ArcFace голова","metadata":{}},{"cell_type":"code","source":"class ArcFace(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.5, easy_margin=False):\n        super().__init__()\n        \n        self.in_features=in_features\n        self.out_features=out_features\n        self.m=m\n        self.s=s\n        self.easy_margin=easy_margin\n\n        self.weight=nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.cos_m=math.cos(self.m)\n        self.sin_m=math.sin(self.m)\n\n        self.th=math.cos(math.pi-m)\n        self.mm=math.sin(math.pi-m)*m\n        \n        \n\n    def forward(self, embeddings, labels):\n        weights=nn.functional.normalize(self.weight)\n        cosine=nn.functional.linear(embeddings, weights)\n        sine=torch.sqrt(torch.clamp(1.0-cosine**2, min=1e-6))\n\n        phi=cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, labels.view(-1,1), 1.0)\n\n        \n        logits = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        logits = logits * self.s\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:58.669945Z","iopub.execute_input":"2025-10-10T09:23:58.670227Z","iopub.status.idle":"2025-10-10T09:23:58.677318Z","shell.execute_reply.started":"2025-10-10T09:23:58.670202Z","shell.execute_reply":"2025-10-10T09:23:58.676462Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"NUM_CLASSES = train['class_id'].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:58.678099Z","iopub.execute_input":"2025-10-10T09:23:58.678344Z","iopub.status.idle":"2025-10-10T09:23:58.696627Z","shell.execute_reply.started":"2025-10-10T09:23:58.678325Z","shell.execute_reply":"2025-10-10T09:23:58.695977Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"arcface_head=ArcFace(512, NUM_CLASSES, s=30.0, m=0.5).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:58.697428Z","iopub.execute_input":"2025-10-10T09:23:58.697769Z","iopub.status.idle":"2025-10-10T09:23:58.764299Z","shell.execute_reply.started":"2025-10-10T09:23:58.697748Z","shell.execute_reply":"2025-10-10T09:23:58.763573Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"text_arcface_head = ArcFace(512, NUM_CLASSES, s=30.0, m=0.5).to(device)\n\ntext_criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n\n# разные LR для энкодера и головы\nfrom torch.cuda.amp import autocast, GradScaler\ntxt_lr_backbone = 2e-5\ntxt_lr_head     = 1e-3\n\ntext_optimizer = torch.optim.AdamW([\n    {'params': text_model.parameters(), 'lr': txt_lr_backbone, 'weight_decay': 0.01},\n    {'params': text_embedding_head.parameters(), 'lr': txt_lr_head, 'weight_decay': 0.01},\n    {'params': text_arcface_head.parameters(), 'lr': txt_lr_head, 'weight_decay': 0.00},\n])\n\nsteps_per_epoch_txt = len(train_text_loader)\nEPOCHS_TEXT = 2  # можно 1 в TEST_MODE\ntext_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n    text_optimizer, max_lr=[txt_lr_backbone, txt_lr_head, txt_lr_head],\n    epochs=EPOCHS_TEXT, steps_per_epoch=steps_per_epoch_txt,\n    pct_start=0.1, div_factor=10, final_div_factor=1e4\n)\n\nscaler_txt = GradScaler()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:58.765010Z","iopub.execute_input":"2025-10-10T09:23:58.765299Z","iopub.status.idle":"2025-10-10T09:23:58.827042Z","shell.execute_reply.started":"2025-10-10T09:23:58.765276Z","shell.execute_reply":"2025-10-10T09:23:58.826334Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/846053085.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler_txt = GradScaler()\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# Criterion ","metadata":{}},{"cell_type":"code","source":"criterion=torch.nn.CrossEntropyLoss(label_smoothing=0.05)\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:58.827775Z","iopub.execute_input":"2025-10-10T09:23:58.828458Z","iopub.status.idle":"2025-10-10T09:23:58.832231Z","shell.execute_reply.started":"2025-10-10T09:23:58.828433Z","shell.execute_reply":"2025-10-10T09:23:58.831459Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Optimizer","metadata":{}},{"cell_type":"code","source":"optimizer=torch.optim.AdamW(list(model.parameters()) +\n    list(embedding_head.parameters()) +\n    list(arcface_head.parameters()), lr=3e-4, weight_decay=0.05)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:58.833115Z","iopub.execute_input":"2025-10-10T09:23:58.833388Z","iopub.status.idle":"2025-10-10T09:23:58.849181Z","shell.execute_reply.started":"2025-10-10T09:23:58.833364Z","shell.execute_reply":"2025-10-10T09:23:58.848384Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# Scheduler","metadata":{}},{"cell_type":"code","source":"scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:58.849786Z","iopub.execute_input":"2025-10-10T09:23:58.850213Z","iopub.status.idle":"2025-10-10T09:23:58.865056Z","shell.execute_reply.started":"2025-10-10T09:23:58.850186Z","shell.execute_reply":"2025-10-10T09:23:58.864411Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"#  Training loop","metadata":{}},{"cell_type":"code","source":"for epoch in range(1, EPOCHS+1):\n    model.train()\n    embedding_head.train()\n    arcface_head.train()\n    running_loss, num_correct, n=0.0,0,0\n    pbar=tqdm(train_dataloader, desc='train', leave=False)\n    for step, batch in enumerate(pbar):\n        optimizer.zero_grad()\n        X=batch['image'].to(device)\n        y=batch['label'].to(device)\n    \n        feats=model(X)\n        embeddings = embedding_head(feats)\n        embeddings=nn.functional.normalize(embeddings, dim=1)\n        logits=arcface_head(embeddings, y)\n        loss=criterion(logits, y)\n        loss.backward()\n        \n        \n        optimizer.step()\n        running_loss+=loss.item()*X.size(0)\n        pbar.set_postfix(loss=running_loss/((step+1)*X.size(0)))\n\n    scheduler.step()\n# ===== Validation: build embeddings -> cosine-kNN -> global tau -> F1 =====\nimport numpy as np\ndef tokenize_titles(titles, max_len=64):\n    return text_tokenizer(titles, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n\ndef mean_pooling(last_hidden_state, attention_mask):\n    mask = attention_mask.unsqueeze(-1).float()\n    summed = (last_hidden_state * mask).sum(dim=1)\n    denom = mask.sum(dim=1).clamp(min=1e-6)\n    return summed / denom\n\nfor epoch in range(1, EPOCHS_TEXT+1):\n    text_model.train(); text_embedding_head.train(); text_arcface_head.train()\n    pbar = tqdm(train_text_loader, desc=f'train/text e{epoch}', leave=False)\n    running = 0.0; nseen = 0\n    for batch in pbar:\n        titles = batch['title']\n        y = batch['label'].to(device, non_blocking=True)\n\n        tok = tokenize_titles(titles)\n        tok = {k: v.to(device, non_blocking=True) for k, v in tok.items()}\n\n        text_optimizer.zero_grad(set_to_none=True)\n        with autocast():\n            out = text_model(**tok)  # last_hidden_state\n            sent = mean_pooling(out.last_hidden_state, tok['attention_mask'])     # (B, 768)\n            emb  = text_embedding_head(sent)                                      # (B, 512)\n            emb  = nn.functional.normalize(emb, dim=1)\n            logits = text_arcface_head(emb, y)\n            loss = text_criterion(logits, y)\n\n        scaler_txt.scale(loss).backward()\n        scaler_txt.step(text_optimizer)\n        scaler_txt.update()\n        text_scheduler.step()\n\n        bs = y.size(0)\n        running += loss.item() * bs\n        nseen += bs\n        pbar.set_postfix(loss=running / max(1, nseen))\n\ntext_model.eval(); text_embedding_head.eval(); text_arcface_head.eval()\n@torch.no_grad()\ndef build_text_embeddings_for_df_ft(df, batch_size=256, max_len=64):\n    titles = df['title'].fillna('').astype(str).tolist()\n    embs = []\n    for i in tqdm(range(0, len(titles), batch_size), desc=\"Embed/text(ft)\"):\n        batch = titles[i:i+batch_size]\n        tok = tokenize_titles(batch, max_len=max_len)\n        tok = {k: v.to(device, non_blocking=True) for k, v in tok.items()}\n        out = text_model(**tok)\n        sent = mean_pooling(out.last_hidden_state, tok['attention_mask'])  # (B,768)\n        e = text_embedding_head(sent)                                      # (B,512)\n        e = nn.functional.normalize(e, dim=1)\n        embs.append(e.cpu())\n    embs = torch.cat(embs, dim=0).numpy().astype('float32')\n    embs /= (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-8)\n    return embs.astype('float16')  # (N,512) float16\n\nmodel.eval(); embedding_head.eval(); arcface_head.eval()\n\n@torch.no_grad()\ndef build_val_embeddings(loader):\n    embs, ids, labels = [], [], []\n    for b in tqdm(loader, desc=\"Embed/val\"):\n        x = b['image'].to(device, non_blocking=True)\n        e = model(x)                         # (B, feat_dim)\n        e = embedding_head(e)                # (B, 512)\n        e = nn.functional.normalize(e, dim=1)\n        embs.append(e.cpu())\n        ids.extend(b['posting_id'])\n        # важно: eval_dataset должен возвращать label (class_id)\n        labels.extend(b['label'].cpu().numpy().tolist())\n    embs = torch.cat(embs, dim=0).numpy()    # (N, 512)\n    labels = np.array(labels)\n    return embs, ids, labels\n\ndef build_preds(embs, ids, K=50, tau=0.50, mutual=True, cap=50):\n    \"\"\"\n    embs: (N, D) L2-нормированные векторы\n    ids:  список posting_id в том же порядке\n    Возвращает dict: posting_id -> set(predicted_ids) (включая self), с ограничением cap.\n    \"\"\"\n    # Косинусная матрица: для L2-нормированных это просто e @ e^T\n    S = embs @ embs.T        # (N, N)\n    N = S.shape[0]\n\n    # Предвычислим top-K индексы для каждого i (быстро и экономно)\n    topk_idx = np.argsort(-S, axis=1)[:, :K]  # индексы соседей по убыванию сходства\n\n    preds = {}\n    for i in range(N):\n        cand = []\n        for j in topk_idx[i]:\n            if S[i, j] >= tau:\n                if not mutual or i in topk_idx[j]:   # взаимность (mutual-kNN) уменьшает false-merge\n                    cand.append(ids[j])\n        # обязательно self-match\n        if ids[i] not in cand:\n            cand = [ids[i]] + cand\n        # кап по условию соревна\n        preds[ids[i]] = set(cand[:cap])\n    return preds\n\ndef f1_matches(ids, labels, preds):\n    \"\"\"\n    Средний F1 по каждому посту:\n      - истина: все posting_id той же class_id\n      - предсказание: preds[posting_id]\n    \"\"\"\n    # сгруппируем истину: class_id -> set(posting_id)\n    truth = {}\n    for pid, g in zip(ids, labels):\n        truth.setdefault(g, set()).add(pid)\n\n    f1s = []\n    for pid, g in zip(ids, labels):\n        T = truth[g]\n        P = preds[pid]\n        inter = len(T & P)\n        denom = len(T) + len(P)\n        f1s.append( 2*inter/denom if denom > 0 else 0.0 )\n    return float(np.mean(f1s))\n\n# 1) эмбеддинги на валидации\nval_embs, val_ids, val_labels = build_val_embeddings(eval_dataloader)\n# === TEXT embeddings на валидации (в порядке eval_dataset.df) ===\nval_text_embs = build_text_embeddings_for_df_ft(eval_dataset.df, batch_size=256, max_len=64)  # (Nv,768) float16\n\n# === top-K для image и text (шире cap, потом обрежем) ===\nKQ = 100  # ширина кандидатов перед обрезкой до 50\nsims_img, idxs_img = topk_chunked_cos(val_embs.astype('float16'), K=KQ, qbs=128)     # (Nv,KQ)\nsims_txt, idxs_txt = topk_chunked_cos(val_text_embs,              K=KQ, qbs=256)     # (Nv,KQ)\n\n# === REPLACE this function with the one below ===\ndef build_preds_fused_mutual(ids, idxs_img, sims_img, idxs_txt, sims_txt,\n                             alpha=0.7, tau=0.50, K_cap=50):\n    \"\"\"\n    ids: список posting_id длины N\n    idxs_*: (N, KQ) индексы кандидатов\n    sims_*: (N, KQ) косинусы [-1,1]\n    alpha: вес image (0..1), (1-alpha) — вес text\n    tau: порог на fused-скор (после приведения в [0,1])\n    K_cap: ограничение размера группы\n    \"\"\"\n    N = len(ids)\n    # объединённые кандидаты для каждого i\n    cand_sets = [ set(idxs_img[i]).union(set(idxs_txt[i])) for i in range(N) ]\n\n    out = {}\n    for i in range(N):\n        # карты скорингов для быстрого доступа\n        map_img = {int(j): float(s) for j, s in zip(idxs_img[i], sims_img[i])}\n        map_txt = {int(j): float(s) for j, s in zip(idxs_txt[i], sims_txt[i])}\n\n        fused = []\n        for j in cand_sets[i]:\n            # приводим косинусы в [0,1] и смешиваем\n            si = (map_img.get(j, -1.0) + 1.0) / 2.0\n            st = (map_txt.get(j, -1.0) + 1.0) / 2.0\n            s  = alpha * si + (1.0 - alpha) * st\n            # взаимность на объединённых кандидатах\n            if s >= tau and (i in cand_sets[j]):\n                fused.append((j, s))\n\n        fused.sort(key=lambda x: -x[1])\n        keep = [ids[j] for j, _ in fused]\n        if ids[i] not in keep:\n            keep = [ids[i]] + keep\n        out[ids[i]] = set(keep[:K_cap])\n    return out\n\n\n# Поиск (alpha, tau) по сетке\n# --- grid search for fusion params ---\nalphas = np.linspace(0.4, 0.9, 6)     # 0.40..0.90\ntaus   = np.linspace(0.20, 0.80, 31)  # 0.20..0.80\n\nbest_fusion = {'f1': -1.0, 'alpha': None, 'tau': None}\nfor a in alphas:\n    for t in taus:\n        preds = build_preds_fused_mutual(\n            val_ids, idxs_img, sims_img, idxs_txt, sims_txt,\n            alpha=float(a), tau=float(t), K_cap=50\n        )\n        f1 = f1_matches(val_ids, val_labels, preds)\n        if f1 > best_fusion['f1']:\n            best_fusion = {'f1': float(f1), 'alpha': float(a), 'tau': float(t)}\n\nprint(f\"[VAL FUSION] Best F1={best_fusion['f1']:.4f} at alpha={best_fusion['alpha']:.2f}, tau={best_fusion['tau']:.2f}\")\n\n\n# (на всякий случай) L2-норм ещё раз, если вызывалась неявно\npreds_best_fused = build_preds_fused_mutual(\n    val_ids, idxs_img, sims_img, idxs_txt, sims_txt,\n    alpha=best_fusion['alpha'], tau=best_fusion['tau'], K_cap=50\n)\navg_group_size = np.mean([len(v) for v in preds_best_fused.values()])\nprint(f\"[VAL FUSION] Avg predicted group size: {avg_group_size:.2f}\")\n\n\n\n# (необязательно) Быстрый sanity-check: средний размер предсказанных групп\n# === Save checkpoint(s) ===\nSAVE_DIR = '/kaggle/working'\nos.makedirs(SAVE_DIR, exist_ok=True)\n\nckpt = {\n    'backbone_name': 'eca_nfnet_l1',          # FIX: было 'resnet50'\n    'feat_dim': model.num_features,\n    'emb_dim': 512,\n    'num_classes': NUM_CLASSES,\n    'arcface_cfg': {'s': 30.0, 'm': 0.5, 'easy_margin': False},\n    'state_dict': {\n        'backbone': model.state_dict(),\n        'embedding_head': embedding_head.state_dict(),\n        'arcface_head': arcface_head.state_dict(),\n    },\n    'label2id': label2id,\n    'fusion_alpha': float(best_fusion['alpha']),\n    'fusion_tau': float(best_fusion['tau']),\n    'val_f1_fused': float(best_fusion['f1']),\n    'epoch': EPOCHS,\n}\n\ntorch.save(ckpt, os.path.join(SAVE_DIR, 'arcface_eca_nfnet_l1_shopee_ckpt.pth'))\nprint('[SAVE] Full checkpoint ->', os.path.join(SAVE_DIR, 'arcface_eca_nfnet_l1_shopee_ckpt.pth'))\n\n# Лёгкий пакет для инференса (нужны веса и параметры фьюжна)\nembed_pkg = {\n    'backbone_name': 'eca_nfnet_l1',\n    'feat_dim': model.num_features,\n    'emb_dim': 512,\n    'state_dict': {\n        'backbone': model.state_dict(),\n        'embedding_head': embedding_head.state_dict(),\n    },\n    'fusion_alpha': float(best_fusion['alpha']),\n    'fusion_tau': float(best_fusion['tau']),\n}\ntorch.save(embed_pkg, os.path.join(SAVE_DIR, 'embedding_extractor.pth'))\nprint('[SAVE] Embedding extractor ->', os.path.join(SAVE_DIR, 'embedding_extractor.pth'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T09:23:58.865973Z","iopub.execute_input":"2025-10-10T09:23:58.866345Z","iopub.status.idle":"2025-10-10T10:24:53.669029Z","shell.execute_reply.started":"2025-10-10T09:23:58.866322Z","shell.execute_reply":"2025-10-10T10:24:53.668210Z"}},"outputs":[{"name":"stderr","text":"train/text e1:   0%|          | 0/200 [00:00<?, ?it/s]             /tmp/ipykernel_36/3844142818.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEmbed/val:   0%|          | 0/200 [00:00<?, ?it/s]                         huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEmbed/val: 100%|██████████| 200/200 [00:45<00:00,  4.42it/s]\nEmbed/text(ft): 100%|██████████| 25/25 [00:11<00:00,  2.25it/s]\nTopK (torch-chunk): 100%|██████████| 50/50 [00:00<00:00, 223.98it/s]\nTopK (torch-chunk): 100%|██████████| 25/25 [00:00<00:00, 1250.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"[VAL FUSION] Best F1=0.9166 at alpha=0.90, tau=0.74\n[VAL FUSION] Avg predicted group size: 1.78\n[SAVE] Full checkpoint -> /kaggle/working/arcface_eca_nfnet_l1_shopee_ckpt.pth\n[SAVE] Embedding extractor -> /kaggle/working/embedding_extractor.pth\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- SAVE full ckpt (image + text) ---\nckpt = {\n    'backbone_name_img': 'eca_nfnet_l1',\n    'backbone_name_txt': TEXT_MODEL_NAME,\n    'img_feat_dim': model.num_features,\n    'txt_feat_dim': text_feat_dim,  # 768\n    'emb_dim': 512,\n    'num_classes': NUM_CLASSES,\n    'arcface_cfg': {'s': 30.0, 'm': 0.5, 'easy_margin': False},\n    'state_dict': {\n        'img_backbone': model.state_dict(),\n        'img_embed_head': embedding_head.state_dict(),\n        'img_arcface_head': arcface_head.state_dict(),\n        'txt_backbone': text_model.state_dict(),\n        'txt_embed_head': text_embedding_head.state_dict(),\n        'txt_arcface_head': text_arcface_head.state_dict(),\n    },\n    'label2id': label2id,\n    'fusion_alpha': float(best_fusion['alpha']),\n    'fusion_tau': float(best_fusion['tau']),\n    'val_f1_fused': float(best_fusion['f1']),\n    'epoch_img': EPOCHS,\n    'epoch_txt': EPOCHS_TEXT,\n}\ntorch.save(ckpt, os.path.join(SAVE_DIR, 'imgtxt_arcface_shopee_ckpt.pth'))\n\n# --- SAVE light embed extractor (для теста) ---\nembed_pkg = {\n    'backbone_name_img': 'eca_nfnet_l1',\n    'backbone_name_txt': TEXT_MODEL_NAME,\n    'emb_dim': 512,\n    'state_dict': {\n        'img_backbone': model.state_dict(),\n        'img_embed_head': embedding_head.state_dict(),\n        'txt_backbone': text_model.state_dict(),\n        'txt_embed_head': text_embedding_head.state_dict(),\n    },\n    'fusion_alpha': float(best_fusion['alpha']),\n    'fusion_tau': float(best_fusion['tau']),\n}\ntorch.save(embed_pkg, os.path.join(SAVE_DIR, 'embedding_extractor_mix.pth'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T10:24:53.670319Z","iopub.execute_input":"2025-10-10T10:24:53.671114Z","iopub.status.idle":"2025-10-10T10:24:58.275062Z","shell.execute_reply.started":"2025-10-10T10:24:53.671083Z","shell.execute_reply":"2025-10-10T10:24:58.274230Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"#need inference notebook","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T10:24:58.276084Z","iopub.execute_input":"2025-10-10T10:24:58.276360Z","iopub.status.idle":"2025-10-10T10:24:58.280418Z","shell.execute_reply.started":"2025-10-10T10:24:58.276337Z","shell.execute_reply":"2025-10-10T10:24:58.279557Z"}},"outputs":[],"execution_count":31}]}