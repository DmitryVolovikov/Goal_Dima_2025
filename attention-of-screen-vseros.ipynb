{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TEST MODE","metadata":{}},{"cell_type":"code","source":"# 30 min + 30 + 10 + ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:25.306629Z","iopub.execute_input":"2025-10-27T13:09:25.307345Z","iopub.status.idle":"2025-10-27T13:09:25.312001Z","shell.execute_reply.started":"2025-10-27T13:09:25.307300Z","shell.execute_reply":"2025-10-27T13:09:25.311157Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"TEST_MODE=False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:25.322717Z","iopub.execute_input":"2025-10-27T13:09:25.322929Z","iopub.status.idle":"2025-10-27T13:09:25.354304Z","shell.execute_reply.started":"2025-10-27T13:09:25.322914Z","shell.execute_reply":"2025-10-27T13:09:25.353746Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Сиды","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\nimport os\n\nseed=105\n\nos.environ['PYTHONHASHSEED']=str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:25.355352Z","iopub.execute_input":"2025-10-27T13:09:25.355747Z","iopub.status.idle":"2025-10-27T13:09:25.368061Z","shell.execute_reply.started":"2025-10-27T13:09:25.355729Z","shell.execute_reply":"2025-10-27T13:09:25.367532Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Импорты","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import StratifiedKFold, train_test_split, KFold\nfrom catboost import CatBoostClassifier, Pool, CatBoostRegressor\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:25.368953Z","iopub.execute_input":"2025-10-27T13:09:25.369203Z","iopub.status.idle":"2025-10-27T13:09:36.275550Z","shell.execute_reply.started":"2025-10-27T13:09:25.369187Z","shell.execute_reply":"2025-10-27T13:09:36.274747Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"train_stat=pd.read_parquet('/kaggle/input/attention-on-screen/video_stat (1).parquet')\ntrain=pd.read_parquet('/kaggle/input/attention-on-screen/train (6).parquet')\ntest=pd.read_parquet('/kaggle/input/attention-on-screen/test (1).parquet')\nsample=pd.read_csv('/kaggle/input/attention-on-screen/sample_submission (14).csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:36.276822Z","iopub.execute_input":"2025-10-27T13:09:36.277534Z","iopub.status.idle":"2025-10-27T13:09:57.701786Z","shell.execute_reply.started":"2025-10-27T13:09:36.277512Z","shell.execute_reply":"2025-10-27T13:09:57.701210Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"num_feats=train.select_dtypes(include='number').columns.tolist()\n\ncat_feats=train.select_dtypes(include='object').columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:57.702424Z","iopub.execute_input":"2025-10-27T13:09:57.702638Z","iopub.status.idle":"2025-10-27T13:09:58.978124Z","shell.execute_reply.started":"2025-10-27T13:09:57.702621Z","shell.execute_reply":"2025-10-27T13:09:58.977533Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"num2_feats=train_stat.select_dtypes(include='number').columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:58.979445Z","iopub.execute_input":"2025-10-27T13:09:58.979733Z","iopub.status.idle":"2025-10-27T13:09:59.023935Z","shell.execute_reply.started":"2025-10-27T13:09:58.979715Z","shell.execute_reply":"2025-10-27T13:09:59.023171Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"if TEST_MODE:\n    train=train[:100]\n    test=test[:100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:59.024704Z","iopub.execute_input":"2025-10-27T13:09:59.024960Z","iopub.status.idle":"2025-10-27T13:09:59.028957Z","shell.execute_reply.started":"2025-10-27T13:09:59.024937Z","shell.execute_reply":"2025-10-27T13:09:59.028275Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:59.029618Z","iopub.execute_input":"2025-10-27T13:09:59.029844Z","iopub.status.idle":"2025-10-27T13:09:59.059733Z","shell.execute_reply.started":"2025-10-27T13:09:59.029829Z","shell.execute_reply":"2025-10-27T13:09:59.059044Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 14154564 entries, 0 to 14154563\nData columns (total 6 columns):\n #   Column           Dtype                        \n---  ------           -----                        \n 0   event_timestamp  datetime64[ms, Europe/Moscow]\n 1   user_id          object                       \n 2   region           object                       \n 3   city             object                       \n 4   video_id         object                       \n 5   watchtime        int64                        \ndtypes: datetime64[ms, Europe/Moscow](1), int64(1), object(4)\nmemory usage: 647.9+ MB\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Joining stuff","metadata":{}},{"cell_type":"code","source":"train_full=train.merge(train_stat, on=['video_id'], how='left')\n\ntest_full=test.merge(train_stat, on=['video_id'], how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:09:59.060465Z","iopub.execute_input":"2025-10-27T13:09:59.060712Z","iopub.status.idle":"2025-10-27T13:10:12.496800Z","shell.execute_reply.started":"2025-10-27T13:09:59.060696Z","shell.execute_reply":"2025-10-27T13:10:12.496166Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#train_full.to_csv('for_analysis.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:12.497599Z","iopub.execute_input":"2025-10-27T13:10:12.497830Z","iopub.status.idle":"2025-10-27T13:10:12.501404Z","shell.execute_reply.started":"2025-10-27T13:10:12.497813Z","shell.execute_reply":"2025-10-27T13:10:12.500683Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Still EDA","metadata":{}},{"cell_type":"code","source":"#v_duration                               0.004272\n#v_likes                                  0.001689","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:12.502141Z","iopub.execute_input":"2025-10-27T13:10:12.502441Z","iopub.status.idle":"2025-10-27T13:10:12.521796Z","shell.execute_reply.started":"2025-10-27T13:10:12.502391Z","shell.execute_reply":"2025-10-27T13:10:12.521111Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# 1) Keep only train rows whose user is present in test\nusers_in_test = pd.Index(test['user_id'].dropna().unique())\ntrain_new = train[train['user_id'].isin(users_in_test)].copy()\n\nprint(f\"train rows:     {len(train):,}\")\nprint(f\"train_new rows: {len(train_new):,} ({len(train_new)/len(train):.2%} of train)\\n\")\n\n# 2) Helper to report both unique-level and row-level coverage\ndef coverage_stats(train_series: pd.Series, test_series: pd.Series, name: str):\n    tr_u = pd.Index(train_series.dropna().unique())\n    te_u = pd.Index(test_series.dropna().unique())\n    n_common_u = tr_u.intersection(te_u).size\n    pct_common_u = n_common_u / te_u.size if te_u.size else np.nan\n\n    # Row-level: how many test rows have a value that exists in train_new\n    covered_rows = test_series.isin(tr_u).sum()\n    pct_rows = covered_rows / len(test_series)\n    unseen_rows = len(test_series) - covered_rows\n\n    print(f\"{name}:\")\n    print(f\"  test unique:          {te_u.size:,}\")\n    print(f\"  common unique:        {n_common_u:,}  ({pct_common_u:.2%})\")\n    print(f\"  test rows covered:    {covered_rows:,}  ({pct_rows:.2%})\")\n    print(f\"  unseen test rows:     {unseen_rows:,}  ({1 - pct_rows:.2%})\\n\")\n\n# 3) Re-check coverage after filtering train -> train_new\ncoverage_stats(train_new['event_timestamp'], test['event_timestamp'], \"event_timestamp\")\ncoverage_stats(train_new['video_id'],         test['video_id'],         \"video_id\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:12.524670Z","iopub.execute_input":"2025-10-27T13:10:12.524866Z","iopub.status.idle":"2025-10-27T13:10:17.654893Z","shell.execute_reply.started":"2025-10-27T13:10:12.524852Z","shell.execute_reply":"2025-10-27T13:10:17.654178Z"}},"outputs":[{"name":"stdout","text":"train rows:     14,154,564\ntrain_new rows: 3,317,176 (23.44% of train)\n\nevent_timestamp:\n  test unique:          85,061\n  common unique:        85,007  (99.94%)\n  test rows covered:    1,333,590  (99.96%)\n  unseen test rows:     542  (0.04%)\n\nvideo_id:\n  test unique:          155,006\n  common unique:        130,234  (84.02%)\n  test rows covered:    1,303,675  (97.72%)\n  unseen test rows:     30,457  (2.28%)\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"code","source":"train_full_new=train_new.merge(train_stat, on=['video_id'], how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:17.655622Z","iopub.execute_input":"2025-10-27T13:10:17.655835Z","iopub.status.idle":"2025-10-27T13:10:20.691619Z","shell.execute_reply.started":"2025-10-27T13:10:17.655820Z","shell.execute_reply":"2025-10-27T13:10:20.690764Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"useless=['v_cr_click_dislike_7_days','v_cr_click_dislike_30_days',\n         'v_avg_watchtime_7_day','v_avg_watchtime_30_day',\n         'v_frac_avg_watchtime_7_day_duration','v_frac_avg_watchtime_30_day_duration',\n         'v_month_views','v_week_views',\n         'v_cr_click_like_7_days','v_cr_click_like_30_days',\n         'v_cr_click_comment_7_days','v_cr_click_comment_30_days',\n         'v_cr_click_long_view_7_days','v_cr_click_long_view_30_days',\n         'v_category_popularity_percent_30_days',\n         'v_long_views_7_days','v_long_views_30_days',\n         'v_is_deleted','v_is_hidden','row_number'\n         \n        # 'user_id','category_id','author_id', 'video_id',\n         #'description','title',\n        # 'region','city'\n        ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:20.692463Z","iopub.execute_input":"2025-10-27T13:10:20.692729Z","iopub.status.idle":"2025-10-27T13:10:20.696896Z","shell.execute_reply.started":"2025-10-27T13:10:20.692704Z","shell.execute_reply":"2025-10-27T13:10:20.696149Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_full_new1=train_full_new.drop(columns=useless)\n\ntest_full_new1=test_full.drop(columns=useless)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:20.697672Z","iopub.execute_input":"2025-10-27T13:10:20.697977Z","iopub.status.idle":"2025-10-27T13:10:21.728788Z","shell.execute_reply.started":"2025-10-27T13:10:20.697959Z","shell.execute_reply":"2025-10-27T13:10:21.728110Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport numpy as np\nimport pandas as pd\n\ndef make_long_watch_flag(df, duration_col='v_duration', watch_col='watchtime', strict=True, unit='s'):\n    # 1) to seconds (if needed) and numeric\n    dur = pd.to_numeric(df[duration_col], errors='coerce')\n    wt  = pd.to_numeric(df[watch_col],  errors='coerce')\n    if unit == 'ms':\n        dur = dur / 1000.0\n        wt  = wt  / 1000.0\n\n    # 2) thresholds\n    thr = np.where(dur > 300.0, dur * 0.25, 30.0)  # 300s = 5 min\n\n    # 3) validity mask and comparison\n    valid = dur.notna() & wt.notna() & (dur > 0) & (wt >= 0)\n    cmp = (wt > thr) if strict else (wt >= thr)\n\n    # 4) build nullable Int8 target safely (pandas Series + pd.NA)\n    y = pd.Series(cmp, index=df.index)\n    y.loc[~valid] = pd.NA\n    df['y_long'] = y.astype('Int8')  # 0/1 with NA\n\n    # optional: keep threshold for debugging\n    df['longwatch_threshold_sec'] = pd.Series(np.where(valid, thr, np.nan), index=df.index)\n\n    return df\n\n\n# Example:\ntrain_full_new1 = make_long_watch_flag(train_full_new1, 'v_duration', 'watchtime', strict=True)\n# If test has watchtime and you want the same flag there:\n# test = make_long_watch_flag(test, 'v_duration', 'watchtime', strict=True)\n\n# Quick sanity check\nprint(train_full_new1['y_long'].value_counts(dropna=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:21.729567Z","iopub.execute_input":"2025-10-27T13:10:21.729803Z","iopub.status.idle":"2025-10-27T13:10:22.480076Z","shell.execute_reply.started":"2025-10-27T13:10:21.729785Z","shell.execute_reply":"2025-10-27T13:10:22.479401Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/1262398379.py:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n  y.loc[~valid] = pd.NA\n","output_type":"stream"},{"name":"stdout","text":"y_long\n1       1713484\n0       1549869\n<NA>      53823\nName: count, dtype: Int64\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Вариант 1 (рекомендую)\nbefore = len(train_full_new1)\ntrain_full_new1 = train_full_new1.dropna(subset=['y_long']).copy()\ntrain_full_new1['y_long'] = train_full_new1['y_long'].astype('int8')\nprint(f\"Dropped {before - len(train_full_new1)} rows\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:22.480883Z","iopub.execute_input":"2025-10-27T13:10:22.481152Z","iopub.status.idle":"2025-10-27T13:10:25.929863Z","shell.execute_reply.started":"2025-10-27T13:10:22.481133Z","shell.execute_reply":"2025-10-27T13:10:25.929022Z"}},"outputs":[{"name":"stdout","text":"Dropped 53823 rows\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nСовпадают значения \n\nv_frac_avg_watchtime_1_day_duration      401816\nv_frac_avg_watchtime_7_day_duration      401816\nv_frac_avg_watchtime_30_day_duration     401816\n\n\nv_month_views                              3284\nv_week_views                               3284\nv_day_views                                3284\n\n\n\nv_long_views_1_days                        2402\nv_long_views_7_days                        2402\nv_long_views_30_days                       2402\n\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:25.930711Z","iopub.execute_input":"2025-10-27T13:10:25.930976Z","iopub.status.idle":"2025-10-27T13:10:25.936801Z","shell.execute_reply.started":"2025-10-27T13:10:25.930950Z","shell.execute_reply":"2025-10-27T13:10:25.936170Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'\\nСовпадают значения \\n\\nv_frac_avg_watchtime_1_day_duration      401816\\nv_frac_avg_watchtime_7_day_duration      401816\\nv_frac_avg_watchtime_30_day_duration     401816\\n\\n\\nv_month_views                              3284\\nv_week_views                               3284\\nv_day_views                                3284\\n\\n\\n\\nv_long_views_1_days                        2402\\nv_long_views_7_days                        2402\\nv_long_views_30_days                       2402\\n\\n\\n'"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"'''\nv_cr_click_dislike_7_days                   980\nv_cr_click_dislike_1_days                   980\nv_cr_click_dislike_30_days                  980\n\n\nv_avg_watchtime_1_day                    220489\nv_avg_watchtime_7_day                    220489\nv_avg_watchtime_30_day                   220489\n\n\nv_frac_avg_watchtime_1_day_duration      401816\nv_frac_avg_watchtime_7_day_duration      401816\nv_frac_avg_watchtime_30_day_duration     401816\n\n\nv_month_views                              3284\nv_week_views                               3284\nv_day_views                                3284\n\n\nv_cr_click_like_1_days                     4869\nv_cr_click_like_30_days                    4869\nv_cr_click_like_7_days                     4869\n\n\nv_cr_click_comment_7_days                  1694\nv_cr_click_comment_30_days                 1694\nv_cr_click_comment_1_days                  1694\n\n\nv_cr_click_long_view_30_days              28910\nv_cr_click_long_view_1_days               28910\nv_cr_click_long_view_7_days               28910\n\n\nv_category_popularity_percent_7_days         56\nv_category_popularity_percent_30_days        56\n\nv_long_views_1_days                        2402\nv_long_views_7_days                        2402\nv_long_views_30_days                       2402\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:25.937500Z","iopub.execute_input":"2025-10-27T13:10:25.937677Z","iopub.status.idle":"2025-10-27T13:10:25.954166Z","shell.execute_reply.started":"2025-10-27T13:10:25.937663Z","shell.execute_reply":"2025-10-27T13:10:25.953523Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'\\nv_cr_click_dislike_7_days                   980\\nv_cr_click_dislike_1_days                   980\\nv_cr_click_dislike_30_days                  980\\n\\n\\nv_avg_watchtime_1_day                    220489\\nv_avg_watchtime_7_day                    220489\\nv_avg_watchtime_30_day                   220489\\n\\n\\nv_frac_avg_watchtime_1_day_duration      401816\\nv_frac_avg_watchtime_7_day_duration      401816\\nv_frac_avg_watchtime_30_day_duration     401816\\n\\n\\nv_month_views                              3284\\nv_week_views                               3284\\nv_day_views                                3284\\n\\n\\nv_cr_click_like_1_days                     4869\\nv_cr_click_like_30_days                    4869\\nv_cr_click_like_7_days                     4869\\n\\n\\nv_cr_click_comment_7_days                  1694\\nv_cr_click_comment_30_days                 1694\\nv_cr_click_comment_1_days                  1694\\n\\n\\nv_cr_click_long_view_30_days              28910\\nv_cr_click_long_view_1_days               28910\\nv_cr_click_long_view_7_days               28910\\n\\n\\nv_category_popularity_percent_7_days         56\\nv_category_popularity_percent_30_days        56\\n\\nv_long_views_1_days                        2402\\nv_long_views_7_days                        2402\\nv_long_views_30_days                       2402\\n'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nМусор фичи \nv_is_deleted\nv_is_hidden\nrow_number\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:25.954926Z","iopub.execute_input":"2025-10-27T13:10:25.955426Z","iopub.status.idle":"2025-10-27T13:10:25.967597Z","shell.execute_reply.started":"2025-10-27T13:10:25.955403Z","shell.execute_reply":"2025-10-27T13:10:25.967018Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'\\nМусор фичи \\nv_is_deleted\\nv_is_hidden\\nrow_number\\n'"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"'''\nВзять title и получить эмбеды \nВсякие лаг фичи, фурье фичи, по таймстемпу, цикличные фичи а также бинарные фичи по типу всякие праздники по типу нг \nпо id создателей сделать агреггированные фичи \n\nДля видео продолжительностью более 5 минут: просмотр считается долгим, если пользователь посмотрел больше 25% длительности видео.\nДля видео менее или равные 5 минут: просмотр считается долгим, если пользователь посмотрел более 30 секунд.\n\nРазница между event_timestamp и v_pub_timestamp\n\nНадо попробовать что Даня сказал с SSL и вот сделать тут также с текстом!\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:25.968198Z","iopub.execute_input":"2025-10-27T13:10:25.968360Z","iopub.status.idle":"2025-10-27T13:10:25.982875Z","shell.execute_reply.started":"2025-10-27T13:10:25.968347Z","shell.execute_reply":"2025-10-27T13:10:25.982100Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'\\nВзять title и получить эмбеды \\nВсякие лаг фичи, фурье фичи, по таймстемпу, цикличные фичи а также бинарные фичи по типу всякие праздники по типу нг \\nпо id создателей сделать агреггированные фичи \\n\\nДля видео продолжительностью более 5 минут: просмотр считается долгим, если пользователь посмотрел больше 25% длительности видео.\\nДля видео менее или равные 5 минут: просмотр считается долгим, если пользователь посмотрел более 30 секунд.\\n\\nРазница между event_timestamp и v_pub_timestamp\\n\\nНадо попробовать что Даня сказал с SSL и вот сделать тут также с текстом!\\n'"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"'''\nХорошие фичи\n\nv_duration                               0.004272\nv_likes                                  0.001689\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:25.983466Z","iopub.execute_input":"2025-10-27T13:10:25.983695Z","iopub.status.idle":"2025-10-27T13:10:25.998416Z","shell.execute_reply.started":"2025-10-27T13:10:25.983680Z","shell.execute_reply":"2025-10-27T13:10:25.997839Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'\\nХорошие фичи\\n\\nv_duration                               0.004272\\nv_likes                                  0.001689\\n'"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"'''\nТест и трейн один и тот же день. Надо об этом учитывать и делать фичи именно сильно дающие инфу о 2024-08-10 \nА также получается надо минутные цикличные или часовые(Надо построить спец график(есть имя ему) )\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:25.999463Z","iopub.execute_input":"2025-10-27T13:10:26.000033Z","iopub.status.idle":"2025-10-27T13:10:26.012238Z","shell.execute_reply.started":"2025-10-27T13:10:25.999997Z","shell.execute_reply":"2025-10-27T13:10:26.011535Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'\\nТест и трейн один и тот же день. Надо об этом учитывать и делать фичи именно сильно дающие инфу о 2024-08-10 \\nА также получается надо минутные цикличные или часовые(Надо построить спец график(есть имя ему) )\\n'"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"#Регрессия или классификация? Склоняюсь к регрессии и потом просто переводе в нули и единички ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:26.012928Z","iopub.execute_input":"2025-10-27T13:10:26.013084Z","iopub.status.idle":"2025-10-27T13:10:26.024299Z","shell.execute_reply.started":"2025-10-27T13:10:26.013072Z","shell.execute_reply":"2025-10-27T13:10:26.023771Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# =========================\n# Конфиг по умолчанию\n# =========================\nTZ = \"Europe/Moscow\"\nDEFAULT_TS_UNIT = \"s\"      # 's' или 'ms' для event_timestamp\nPUB_NAIVE_TZ = \"UTC\"       # если v_pub_datetime наивный, считаем его изначально в UTC\n\n# =========================\n# 1) Приведение времени\n# =========================\ndef standardize_time(\n    df: pd.DataFrame,\n    ts_col: str = \"event_timestamp\",\n    pub_col: str = \"v_pub_datetime\",\n    ts_unit: str = DEFAULT_TS_UNIT,\n    tz: str = TZ,\n    pub_naive_tz: str = PUB_NAIVE_TZ,\n) -> pd.DataFrame:\n    \"\"\"Возвращает копию с tz-aware датами: event_dt_msk, pub_dt_msk.\"\"\"\n    out = df.copy()\n\n    # event_timestamp (числовой epoch)\n    evt = pd.to_datetime(out[ts_col], unit=ts_unit, utc=True, errors=\"coerce\").dt.tz_convert(tz)\n\n    # v_pub_datetime (может быть tz-naive)\n    pub = pd.to_datetime(out[pub_col], errors=\"coerce\")\n    if getattr(pub.dt, \"tz\", None) is None:\n        pub = pub.dt.tz_localize(pub_naive_tz, nonexistent=\"shift_forward\", ambiguous=\"NaT\")\n    pub = pub.dt.tz_convert(tz)\n\n    out[\"event_dt_msk\"] = evt\n    out[\"pub_dt_msk\"] = pub\n    return out\n\n# =========================\n# 2) Интра-дневные фичи\n# =========================\ndef add_intraday_features(\n    df: pd.DataFrame,\n    dt_col: str = \"event_dt_msk\",\n    add_fourier: bool = True,\n    K_HOUR: int = 2\n) -> pd.DataFrame:\n    \"\"\"Сек/мин/час дня, циклические фичи по часу, прайм-тайм флаги.\"\"\"\n    out = df.copy()\n    evt = out[dt_col]\n\n    out[\"hour\"] = evt.dt.hour.astype(\"int8\")\n    out[\"minute\"] = evt.dt.minute.astype(\"int8\")\n    out[\"second\"] = evt.dt.second.astype(\"int8\")\n\n    out[\"minute_of_day\"] = (out[\"hour\"] * 60 + out[\"minute\"]).astype(\"int16\")\n    out[\"sec_of_day\"] = ((out[\"hour\"] * 3600) + (out[\"minute\"] * 60) + out[\"second\"]).astype(\"int32\")\n\n    # прайм-тайм (примерные окна — можно тюнить)\n    sod = out[\"sec_of_day\"]\n    out[\"is_morning\"] = sod.between(6*3600, 11*3600).astype(\"int8\")\n    out[\"is_day\"]     = sod.between(11*3600, 17*3600).astype(\"int8\")\n    out[\"is_evening\"] = sod.between(17*3600, 23*3600).astype(\"int8\")\n    out[\"is_night\"]   = ((sod < 6*3600) | (sod >= 23*3600)).astype(\"int8\")\n\n    if add_fourier:\n        # плавная доля суток [0,1)\n        frac_day = (out[\"sec_of_day\"].astype(\"float32\") / 86400.0).clip(0, 1)\n        two_pi = 2.0 * np.pi\n        for k in range(1, K_HOUR + 1):\n            ang = two_pi * k * frac_day\n            out[f\"f_day_sin_{k}\"] = np.sin(ang).astype(\"float32\")\n            out[f\"f_day_cos_{k}\"] = np.cos(ang).astype(\"float32\")\n\n    return out\n\n# =========================\n# 3) Возраст от публикации\n# =========================\ndef add_age_features(\n    df: pd.DataFrame,\n    evt_col: str = \"event_dt_msk\",\n    pub_col: str = \"pub_dt_msk\",\n) -> pd.DataFrame:\n    \"\"\"Возраст: секунды/часы/дни, лог-скейл, флаг отрицательной разницы.\"\"\"\n    out = df.copy()\n    age_sec = (out[evt_col] - out[pub_col]).dt.total_seconds()\n    out[\"age_sec\"] = age_sec.astype(\"float32\")\n    out[\"age_hours\"] = (out[\"age_sec\"] / 3600.0).astype(\"float32\")\n    out[\"age_days\"] = (out[\"age_sec\"] / 86400.0).astype(\"float32\")\n    out[\"age_log1p\"] = np.log1p(np.clip(out[\"age_sec\"], a_min=0, a_max=None)).astype(\"float32\")\n    out[\"age_neg_flag\"] = (out[\"age_sec\"] < 0).astype(\"int8\")\n\n    # быстрые пороги свежести\n    out[\"is_fresh_1h\"]  = (out[\"age_sec\"] <= 3600).astype(\"int8\")\n    out[\"is_fresh_3h\"]  = (out[\"age_sec\"] <= 3*3600).astype(\"int8\")\n    out[\"is_fresh_12h\"] = (out[\"age_sec\"] <= 12*3600).astype(\"int8\")\n    return out\n\n# =========================\n# 4) Квантили-бины возраста (из train) + маппинг в обе выборки\n# =========================\ndef fit_age_bins(train_age_sec: pd.Series, n_bins: int = 10) -> np.ndarray:\n    \"\"\"Квантильные бины возраста (секунды), устойчивы к хвостам.\"\"\"\n    x = train_age_sec.dropna().clip(lower=0)\n    qs = np.linspace(0, 1, n_bins + 1)\n    bins = np.unique(np.quantile(x.to_numpy(), qs))\n    if bins.size < 2:\n        bins = np.array([0.0, float(x.max() if len(x) else 1.0)], dtype=float)\n    return bins\n\ndef apply_age_bins(df: pd.DataFrame, bins: np.ndarray, col: str = \"age_sec\") -> pd.DataFrame:\n    out = df.copy()\n    out[\"age_bin\"] = pd.cut(out[col].clip(lower=0), bins=bins, include_lowest=True)\n    # числовой индекс бина (+ компактный int)\n    out[\"age_bin_idx\"] = out[\"age_bin\"].cat.codes.astype(\"int16\")\n    return out\n\n# =========================\n# 5) Временные приоры (смутые CTR) по train + маппинг\n# =========================\ndef _smoothed_ctr(sum_, cnt, alpha=2.0, beta=2.0):\n    return (sum_ + alpha) / (cnt + alpha + beta)\n\ndef build_time_priors(\n    train_df: pd.DataFrame,\n    y_col: str = \"y_long\",\n    alpha: float = 2.0,\n    beta: float = 2.0,\n) -> dict:\n    \"\"\"Считает p(y=1) по часу, 5-мин окнам, минуте дня и бинaм возраста на TRAIN.\"\"\"\n    p_glob = float(train_df[y_col].mean())\n\n    g = train_df.groupby(\"hour\")[y_col].agg([\"sum\", \"count\"])\n    p_hour = _smoothed_ctr(g[\"sum\"], g[\"count\"], alpha, beta).rename(\"p_long_hour\")\n\n    g = train_df.groupby(\"minute_of_day\")[y_col].agg([\"sum\", \"count\"])\n    p_minute = _smoothed_ctr(g[\"sum\"], g[\"count\"], alpha, beta).rename(\"p_long_minute\")\n\n    g = (train_df.assign(min5_bucket=(train_df[\"minute_of_day\"] // 5).astype(\"int16\"))\n                 .groupby(\"min5_bucket\")[y_col].agg([\"sum\", \"count\"]))\n    p_min5 = _smoothed_ctr(g[\"sum\"], g[\"count\"], alpha, beta).rename(\"p_long_min5\")\n\n    # по бинaм возраста (тут уже должен быть age_bin)\n    g = train_df.groupby(\"age_bin\")[y_col].agg([\"sum\", \"count\"])\n    p_agebin = _smoothed_ctr(g[\"sum\"], g[\"count\"], alpha, beta).rename(\"p_long_agebin\")\n    # индекс лучше строкой для однозначного маппинга\n    p_agebin.index = p_agebin.index.astype(str)\n\n    return {\n        \"p_glob\": p_glob,\n        \"p_hour\": p_hour,\n        \"p_minute\": p_minute,\n        \"p_min5\": p_min5,\n        \"p_agebin\": p_agebin,\n    }\n\ndef apply_time_priors(df: pd.DataFrame, priors: dict) -> pd.DataFrame:\n    out = df.copy()\n    out[\"min5_bucket\"] = (out[\"minute_of_day\"] // 5).astype(\"int16\")\n\n    out[\"p_long_hour\"]   = out[\"hour\"].map(priors[\"p_hour\"]).astype(\"float32\")\n    out[\"p_long_minute\"] = out[\"minute_of_day\"].map(priors[\"p_minute\"]).astype(\"float32\")\n    out[\"p_long_min5\"]   = out[\"min5_bucket\"].map(priors[\"p_min5\"]).astype(\"float32\")\n\n    # маппинг по строковому представлению age_bin\n    agebin_str = out[\"age_bin\"].astype(str)\n    out[\"p_long_agebin\"] = agebin_str.map(priors[\"p_agebin\"]).astype(\"float32\")\n\n    # бэкоф глобальным средним\n    for c in [\"p_long_hour\", \"p_long_minute\", \"p_long_min5\", \"p_long_agebin\"]:\n        out[c] = out[c].fillna(priors[\"p_glob\"]).astype(\"float32\")\n    return out\n\n# =========================\n# 6) Приор (video_id, hour) из TRAIN + бэкоф\n# =========================\ndef add_video_hour_prior(\n    train_df: pd.DataFrame,\n    test_df: pd.DataFrame,\n    y_col: str = \"y_long\",\n    min_count: int = 100,\n    alpha: float = 2.0,\n    beta: float = 2.0,\n) -> tuple[pd.DataFrame, pd.DataFrame]:\n    grp = train_df.groupby([\"video_id\", \"hour\"])[y_col].agg([\"sum\", \"count\"])\n    keep = grp[\"count\"] >= min_count\n    grp = grp[keep]\n    p_vh = _smoothed_ctr(grp[\"sum\"], grp[\"count\"], alpha, beta).rename(\"p_long_video_hour\")\n\n    for df in (train_df, test_df):\n        key = df.set_index([\"video_id\", \"hour\"]).index\n        df[\"p_long_video_hour\"] = pd.Series(key.map(p_vh), index=df.index).astype(\"float32\")\n        # бэкоф к часовому приору (уже должен быть)\n        df[\"p_long_video_hour\"] = df[\"p_long_video_hour\"].fillna(df[\"p_long_hour\"]).astype(\"float32\")\n    return train_df, test_df\n\n# =========================\n# 7) Роллинги «в прошлое» (без утечки)\n# =========================\ndef add_past_gap_features(\n    df: pd.DataFrame,\n    evt_col: str = \"event_dt_msk\",\n    by_user: bool = True,\n    by_uv: bool = True,\n) -> pd.DataFrame:\n    \"\"\"\n    time_since_prev_user: время с прошлого события пользователя\n    time_since_prev_uv:   время с прошлого события той же пары (user,video)\n    \"\"\"\n    out = df.copy().sort_values(evt_col).reset_index(drop=True)\n    sec = lambda x: x.dt.total_seconds().astype(\"float32\")\n\n    if by_user and \"user_id\" in out.columns:\n        prev_u = (\n            out.groupby(\"user_id\")[evt_col].shift(1)\n        )\n        out[\"time_since_prev_user\"] = sec(out[evt_col] - prev_u).fillna(-1.0)\n\n    if by_uv and {\"user_id\",\"video_id\"}.issubset(out.columns):\n        prev_uv = (\n            out.groupby([\"user_id\",\"video_id\"])[evt_col].shift(1)\n        )\n        out[\"time_since_prev_uv\"] = sec(out[evt_col] - prev_uv).fillna(-1.0)\n\n    return out\n\n# =========================\n# 8) Оркестратор: строим «с нуля»\n# =========================\ndef build_temporal_features(\n    train_df: pd.DataFrame,\n    test_df: pd.DataFrame,\n    ts_unit: str = DEFAULT_TS_UNIT,\n    tz: str = TZ,\n    pub_naive_tz: str = PUB_NAIVE_TZ,\n    y_col: str = \"y_long\",\n    n_age_bins: int = 10,\n    alpha: float = 2.0,\n    beta: float = 2.0,\n    min_count_vh: int = 100,\n) -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n    # 1) приведение времени\n    tr = standardize_time(train_df, ts_unit=ts_unit, tz=tz, pub_naive_tz=pub_naive_tz)\n    te = standardize_time(test_df,  ts_unit=ts_unit, tz=tz, pub_naive_tz=pub_naive_tz)\n\n    # 2) базовые задачи времени\n    tr = add_intraday_features(tr, add_fourier=True, K_HOUR=2)\n    te = add_intraday_features(te, add_fourier=True, K_HOUR=2)\n\n    # 3) возраст от публикации\n    tr = add_age_features(tr)\n    te = add_age_features(te)\n\n    # 4) квантили-бины возраста (по train) + маппинг\n    bins = fit_age_bins(tr[\"age_sec\"], n_bins=n_age_bins)\n    tr = apply_age_bins(tr, bins)\n    te = apply_age_bins(te, bins)\n\n    # 5) временные приоры из train и маппинг\n    priors = build_time_priors(tr, y_col=y_col, alpha=alpha, beta=beta)\n    tr = apply_time_priors(tr, priors)\n    te = apply_time_priors(te, priors)\n\n    # 6) (video,hour) приор с бэкофом\n    tr, te = add_video_hour_prior(tr, te, y_col=y_col, min_count=min_count_vh, alpha=alpha, beta=beta)\n\n    # 7) роллинги \"в прошлое\" без утечки (отдельно в каждом df)\n    tr = add_past_gap_features(tr)\n    te = add_past_gap_features(te)\n\n    artifacts = {\"age_bins\": bins, \"priors\": priors}\n    return tr, te, artifacts\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:26.025069Z","iopub.execute_input":"2025-10-27T13:10:26.025289Z","iopub.status.idle":"2025-10-27T13:10:26.054448Z","shell.execute_reply.started":"2025-10-27T13:10:26.025273Z","shell.execute_reply":"2025-10-27T13:10:26.053845Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Пример: у нас уже есть train_full_new1 (с y_long) и test_full\ntrain_time, test_time, artifacts = build_temporal_features(\n    train_full_new1, \n    test_full_new1, \n    ts_unit=\"s\",           # у тебя именно секунды\n    tz=\"Europe/Moscow\",\n    pub_naive_tz=\"UTC\",\n    y_col=\"y_long\",\n    n_age_bins=12,         # можно 8-16; подберёшь по CV\n    alpha=2.0, beta=2.0,\n    min_count_vh=100       # приор (video,hour) только для достаточно частых\n)\n\nprint(train_time.shape, test_time.shape)\ntrain_time.filter(regex=\"^(sec_of_day|f_day_|age_|p_long_|time_since_)\").head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:26.055281Z","iopub.execute_input":"2025-10-27T13:10:26.055603Z","iopub.status.idle":"2025-10-27T13:10:58.672120Z","shell.execute_reply.started":"2025-10-27T13:10:26.055580Z","shell.execute_reply":"2025-10-27T13:10:58.671459Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/2612827446.py:144: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  g = train_df.groupby(\"age_bin\")[y_col].agg([\"sum\", \"count\"])\n","output_type":"stream"},{"name":"stdout","text":"(3263353, 63) (1334132, 60)\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   sec_of_day  f_day_sin_1  f_day_cos_1  f_day_sin_2  f_day_cos_2     age_sec  \\\n0           0          0.0          1.0          0.0          1.0  13265531.0   \n1           0          0.0          1.0          0.0          1.0  39946360.0   \n2           0          0.0          1.0          0.0          1.0  13319931.0   \n3           0          0.0          1.0          0.0          1.0  28715980.0   \n4           0          0.0          1.0          0.0          1.0  35114164.0   \n\n      age_hours    age_days  age_log1p  age_neg_flag  \\\n0   3684.869629  153.536240  16.400681             0   \n1  11096.210938  462.342133  17.503048             0   \n2   3699.980713  154.165863  16.404772             0   \n3   7976.661133  332.360870  17.172964             0   \n4   9753.934570  406.413940  17.374115             0   \n\n                    age_bin  age_bin_idx  p_long_hour  p_long_minute  \\\n0  (13179702.0, 13304546.0]            3      0.48226        0.48935   \n1  (38012924.0, 50872940.0]            8      0.48226        0.48935   \n2  (13304546.0, 13759221.0]            4      0.48226        0.48935   \n3  (26606688.0, 38012924.0]            7      0.48226        0.48935   \n4  (26606688.0, 38012924.0]            7      0.48226        0.48935   \n\n   p_long_min5  p_long_agebin  p_long_video_hour  time_since_prev_user  \\\n0     0.498806       0.055709            0.48226                  -1.0   \n1     0.498806       0.646778            0.48226                  -1.0   \n2     0.498806       0.075433            0.48226                  -1.0   \n3     0.498806       0.584863            0.48226                  -1.0   \n4     0.498806       0.584863            0.48226                  -1.0   \n\n   time_since_prev_uv  \n0                -1.0  \n1                -1.0  \n2                -1.0  \n3                -1.0  \n4                -1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sec_of_day</th>\n      <th>f_day_sin_1</th>\n      <th>f_day_cos_1</th>\n      <th>f_day_sin_2</th>\n      <th>f_day_cos_2</th>\n      <th>age_sec</th>\n      <th>age_hours</th>\n      <th>age_days</th>\n      <th>age_log1p</th>\n      <th>age_neg_flag</th>\n      <th>age_bin</th>\n      <th>age_bin_idx</th>\n      <th>p_long_hour</th>\n      <th>p_long_minute</th>\n      <th>p_long_min5</th>\n      <th>p_long_agebin</th>\n      <th>p_long_video_hour</th>\n      <th>time_since_prev_user</th>\n      <th>time_since_prev_uv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13265531.0</td>\n      <td>3684.869629</td>\n      <td>153.536240</td>\n      <td>16.400681</td>\n      <td>0</td>\n      <td>(13179702.0, 13304546.0]</td>\n      <td>3</td>\n      <td>0.48226</td>\n      <td>0.48935</td>\n      <td>0.498806</td>\n      <td>0.055709</td>\n      <td>0.48226</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>39946360.0</td>\n      <td>11096.210938</td>\n      <td>462.342133</td>\n      <td>17.503048</td>\n      <td>0</td>\n      <td>(38012924.0, 50872940.0]</td>\n      <td>8</td>\n      <td>0.48226</td>\n      <td>0.48935</td>\n      <td>0.498806</td>\n      <td>0.646778</td>\n      <td>0.48226</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13319931.0</td>\n      <td>3699.980713</td>\n      <td>154.165863</td>\n      <td>16.404772</td>\n      <td>0</td>\n      <td>(13304546.0, 13759221.0]</td>\n      <td>4</td>\n      <td>0.48226</td>\n      <td>0.48935</td>\n      <td>0.498806</td>\n      <td>0.075433</td>\n      <td>0.48226</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>28715980.0</td>\n      <td>7976.661133</td>\n      <td>332.360870</td>\n      <td>17.172964</td>\n      <td>0</td>\n      <td>(26606688.0, 38012924.0]</td>\n      <td>7</td>\n      <td>0.48226</td>\n      <td>0.48935</td>\n      <td>0.498806</td>\n      <td>0.584863</td>\n      <td>0.48226</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>35114164.0</td>\n      <td>9753.934570</td>\n      <td>406.413940</td>\n      <td>17.374115</td>\n      <td>0</td>\n      <td>(26606688.0, 38012924.0]</td>\n      <td>7</td>\n      <td>0.48226</td>\n      <td>0.48935</td>\n      <td>0.498806</td>\n      <td>0.584863</td>\n      <td>0.48226</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\n'''\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.cluster import KMeans\n\n# -------------------------\n# 1) НОРМАЛИЗАЦИЯ ТЕКСТА\n# -------------------------\ndef normalize_title_series(s: pd.Series) -> pd.Series:\n    s = s.fillna(\"\")\n    # нижний регистр + единичные пробелы\n    s = s.str.lower()\n    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n    return s\n\n# -------------------------\n# 2) РЕГЕКСЫ И СЛОВАРИ\n# -------------------------\nRX_EMOJI = re.compile(\n    \"[\"                                   # очень грубый детектор эмодзи\n    \"\\U0001F300-\\U0001F64F\"\n    \"\\U0001F680-\\U0001F6FF\"\n    \"\\U0001F900-\\U0001F9FF\"\n    \"\\u2600-\\u26FF\\u2700-\\u27BF\"\n    \"]+\"\n)\n\n# ключевые хинты (EN/RU)\nHINT_LONG  = [\n    r\"стрим\", r\"прямой эфир\", r\"запись стрима\", r\"трансляц\",\n    r\"live\", r\"stream\", r\"podcast\", r\"подкаст\", r\"full episode\", r\"full version\",\n    r\"полная верс\", r\"longplay\", r\"полный выпуск\"\n]\nHINT_SHORT = [\n    r\"shorts?\", r\"\\bshort\\b\", r\"тизер\", r\"teaser\", r\"трейлер\", r\"trailer\",\n    r\"clip\\b\", r\"клип\\b\", r\"highlights?\", r\"нарезка\", r\"cut\\b\", r\"шортс\"\n]\nHINT_EDU   = [r\"\\bкак\\b\", r\"how to\", r\"tutorial\", r\"урок\", r\"гайд\", r\"инструкц\", r\"обзор\", r\"review\"]\nHINT_OFFICIAL = [r\"official\", r\"официальн\"]\n\n# part/episode/season\nRX_PART_EP = re.compile(r\"(?:\\bpart\\s*\\d+\\b|\\bчаст[ьи]\\s*\\d+\\b|\\bs\\d{1,2}e\\d{1,2}\\b)\", re.I)\n\n# годы/числа\nRX_YEAR = re.compile(r\"\\b(19\\d{2}|20\\d{2}|210\\d)\\b\")\n\n# паттерны длительности внутри title (грубо)\n# поддерживаем: \"10 часов\", \"2 часа 30 минут\", \"1h 20m\", \"90 мин\", \"00:30\", \"1:20:00\"\nRX_TIME_BLOCKS = [\n    (re.compile(r\"(\\d+)\\s*(?:час|часа|часов|h|hr|hour)s?\\b\", re.I), 60),           # часы → минуты\n    (re.compile(r\"(\\d+)\\s*(?:мин|минут|minute|m)\\b\", re.I), 1),                   # минуты\n    (re.compile(r\"(\\d+)\\s*(?:сек|секунд|second|s)\\b\", re.I), 1/60),               # секунды → минуты\n    (re.compile(r\"\\b(\\d{1,2}):([0-5]\\d)(?::([0-5]\\d))?\\b\"), \"hh:mm:ss\"),          # 1:20 или 1:20:00\n]\n\ndef _extract_title_duration_min(title: str) -> float:\n    \"\"\"Пытаемся вытащить упоминание длительности из title, вернуть минуты (float) или np.nan.\"\"\"\n    if not title:\n        return np.nan\n    t = title\n\n    # форматы типа 1:20:00 / 1:20\n    m = RX_TIME_BLOCKS[3][0].search(t)\n    if m:\n        h = int(m.group(1))\n        mm = int(m.group(2))\n        ss = int(m.group(3)) if m.group(3) else 0\n        return h*60 + mm + ss/60.0\n\n    total_min = 0.0\n    found = False\n    for rx, mul in RX_TIME_BLOCKS[:3]:\n        for g in rx.findall(t):\n            try:\n                num = float(g if isinstance(g, str) else g[0])\n            except Exception:\n                continue\n            total_min += num * (mul if isinstance(mul, (int, float)) else 1.0)\n            found = True\n    return total_min if found else np.nan\n\n# -------------------------\n# 3) ЛЕКСИКО-СТРУКТУРНЫЕ ФИЧИ\n# -------------------------\ndef extract_title_lex_features(df: pd.DataFrame, title_col: str = \"title\") -> pd.DataFrame:\n    out = df.copy()\n    t = normalize_title_series(out[title_col])\n\n    # базовые длины\n    out[\"title_len_char\"] = t.str.len().astype(\"int32\")\n    out[\"title_n_words\"]  = t.str.split().str.len().fillna(0).astype(\"int16\")\n\n    # доли символов\n    # кириллица/латиница/цифры/верхний регистр\n    s = out[title_col].fillna(\"\")\n    has_cyr = s.str.contains(r\"[А-Яа-яЁё]\")\n    has_lat = s.str.contains(r\"[A-Za-z]\")\n    out[\"title_has_cyr\"] = has_cyr.astype(\"int8\")\n    out[\"title_has_lat\"] = has_lat.astype(\"int8\")\n\n    # грубая доля цифр/знаков/прописных\n    out[\"title_digits_ratio\"] = s.str.count(r\"\\d\").div(out[\"title_len_char\"].replace(0, np.nan)).fillna(0).astype(\"float32\")\n    out[\"title_punct_ratio\"]  = s.str.count(r\"[^\\w\\s]\").div(out[\"title_len_char\"].replace(0, np.nan)).fillna(0).astype(\"float32\")\n    out[\"title_excl_cnt\"]     = s.str.count(\"!\").astype(\"int16\")\n    out[\"title_quest_cnt\"]    = s.str.count(\"\\?\").astype(\"int16\")\n    out[\"title_hash_cnt\"]     = s.str.count(\"#\").astype(\"int16\")\n    out[\"title_emoji_cnt\"]    = s.apply(lambda x: len(RX_EMOJI.findall(x))).astype(\"int16\")\n\n    # ключевые хинты (binary)\n    def any_match(patterns, text):\n        for p in patterns:\n            if re.search(p, text, re.I):\n                return 1\n        return 0\n\n    out[\"title_hint_long\"]   = t.apply(lambda x: any_match(HINT_LONG, x)).astype(\"int8\")\n    out[\"title_hint_short\"]  = t.apply(lambda x: any_match(HINT_SHORT, x)).astype(\"int8\")\n    out[\"title_hint_edu\"]    = t.apply(lambda x: any_match(HINT_EDU, x)).astype(\"int8\")\n    out[\"title_hint_offcl\"]  = t.apply(lambda x: any_match(HINT_OFFICIAL, x)).astype(\"int8\")\n\n    # part/episode + год\n    out[\"title_has_part_ep\"] = t.str.contains(RX_PART_EP).astype(\"int8\")\n    out[\"title_has_year\"]    = t.str.contains(RX_YEAR).astype(\"int8\")\n\n    # длительность, упомянутая в title\n    out[\"title_dur_min_inferred\"] = t.apply(_extract_title_duration_min).astype(\"float32\")\n    out[\"title_has_dur\"]          = out[\"title_dur_min_inferred\"].notna().astype(\"int8\")\n\n    # полезные пересечения\n    out[\"title_is_trailer_or_teaser\"] = ((out[\"title_hint_short\"]==1) & (t.str.contains(r\"trailer|тизер|teaser\", regex=True))).astype(\"int8\")\n    out[\"title_is_stream_live\"]       = out[\"title_hint_long\"]\n    out[\"title_is_shorts\"]            = t.str.contains(r\"\\bshorts?\\b|шортс\", regex=True).astype(\"int8\")\n\n    # длиновые бины\n    out[\"title_len_char_bin\"] = pd.cut(out[\"title_len_char\"], bins=[-1, 20, 35, 60, 100, 1000], labels=[0,1,2,3,4]).astype(\"int8\")\n    out[\"title_n_words_bin\"]  = pd.cut(out[\"title_n_words\"],  bins=[-1, 3, 6, 12, 20, 100],   labels=[0,1,2,3,4]).astype(\"int8\")\n\n    return out\n\n# -------------------------\n# 4) TF-IDF (char n-grams) → SVD\n# -------------------------\ndef add_tfidf_svd_features(\n    train_df: pd.DataFrame,\n    test_df: pd.DataFrame,\n    title_col: str = \"title\",\n    max_features: int = 30000,\n    n_components: int = 32,\n    ngram_range=(3,5),\n    random_state: int = 42,\n):\n    tr = train_df.copy()\n    te = test_df.copy()\n\n    tr_text = normalize_title_series(tr[title_col]).fillna(\"\")\n    te_text = normalize_title_series(te[title_col]).fillna(\"\")\n\n    vec = TfidfVectorizer(\n        analyzer=\"char\",\n        ngram_range=ngram_range,\n        max_features=max_features,\n        min_df=2\n    )\n    X_tr = vec.fit_transform(tr_text)\n    X_te = vec.transform(te_text)\n\n    svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n    Z_tr = svd.fit_transform(X_tr).astype(\"float32\")\n    Z_te = svd.transform(X_te).astype(\"float32\")\n\n    for i in range(n_components):\n        tr[f\"title_svd_{i:02d}\"] = Z_tr[:, i]\n        te[f\"title_svd_{i:02d}\"] = Z_te[:, i]\n\n    artifacts = {\"vectorizer\": vec, \"svd\": svd}\n    return tr, te, artifacts\n\n# -------------------------\n# 5) КЛАСТЕРЫ + ПРИОРЫ ПО КЛАСТЕРАМ\n# -------------------------\ndef add_title_cluster_priors(\n    train_df: pd.DataFrame,\n    test_df: pd.DataFrame,\n    y_col: str = \"y_long\",\n    n_clusters: int = 50,\n    base_cols_pattern: str = r\"^title_svd_\\d+$\",\n    alpha: float = 2.0,\n    beta: float = 2.0,\n    random_state: int = 42,\n):\n    \"\"\"Кластерим SVD-компоненты заголовков, считаем p(y=1) по кластерам (train) и мапим в обе выборки.\"\"\"\n    tr = train_df.copy()\n    te = test_df.copy()\n\n    svd_cols = [c for c in tr.columns if re.match(base_cols_pattern, c)]\n    X_tr = tr[svd_cols].to_numpy(dtype=np.float32)\n    X_te = te[svd_cols].to_numpy(dtype=np.float32)\n\n    km = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=\"auto\")\n    tr[\"_title_cluster\"] = km.fit_predict(X_tr).astype(\"int16\")\n    te[\"_title_cluster\"] = km.predict(X_te).astype(\"int16\")\n\n    # смутый CTR по кластерам\n    g = tr.groupby(\"_title_cluster\")[y_col].agg([\"sum\",\"count\"])\n    p = (g[\"sum\"] + alpha) / (g[\"count\"] + alpha + beta)\n    p = p.rename(\"p_long_title_cluster\")\n\n    tr[\"p_long_title_cluster\"] = tr[\"_title_cluster\"].map(p).astype(\"float32\")\n    te[\"p_long_title_cluster\"] = te[\"_title_cluster\"].map(p).astype(\"float32\")\n\n    # необязательный feature: расстояние до центроида (инерция)\n    centers = km.cluster_centers_.astype(np.float32)\n    tr[\"title_cluster_dist\"] = ((X_tr - centers[tr[\"_title_cluster\"]])**2).sum(axis=1)**0.5\n    te[\"title_cluster_dist\"] = ((X_te - centers[te[\"_title_cluster\"]])**2).sum(axis=1)**0.5\n    tr[\"title_cluster_dist\"] = tr[\"title_cluster_dist\"].astype(\"float32\")\n    te[\"title_cluster_dist\"] = te[\"title_cluster_dist\"].astype(\"float32\")\n\n    artifacts = {\"kmeans\": km, \"cluster_priors\": p}\n    return tr, te, artifacts\n\n# -------------------------\n# 6) ОРКЕСТРАТОР ДЛЯ TITLE\n# -------------------------\ndef build_title_features(\n    train_df: pd.DataFrame,\n    test_df: pd.DataFrame,\n    title_col: str = \"title\",\n    y_col: str = \"y_long\",\n    tfidf_max_features: int = 30000,\n    svd_components: int = 32,\n    kmeans_clusters: int = 50,\n):\n    # a) лексические/структурные\n    tr = extract_title_lex_features(train_df, title_col=title_col)\n    te = extract_title_lex_features(test_df,  title_col=title_col)\n\n    # b) TF-IDF (char) → SVD\n    tr, te, arts_tfidf = add_tfidf_svd_features(\n        tr, te, title_col=title_col,\n        max_features=tfidf_max_features, n_components=svd_components\n    )\n\n    # c) Кластеры заголовков + приор p(y=1) по кластерам (по train)\n    tr, te, arts_cl = add_title_cluster_priors(\n        tr, te, y_col=y_col, n_clusters=kmeans_clusters\n    )\n\n    artifacts = {\"tfidf_svd\": arts_tfidf, \"title_clusters\": arts_cl}\n    return tr, te, artifacts\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.672900Z","iopub.execute_input":"2025-10-27T13:10:58.673171Z","iopub.status.idle":"2025-10-27T13:10:58.683888Z","shell.execute_reply.started":"2025-10-27T13:10:58.673153Z","shell.execute_reply":"2025-10-27T13:10:58.683341Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.decomposition import TruncatedSVD\\nfrom sklearn.cluster import KMeans\\n\\n# -------------------------\\n# 1) НОРМАЛИЗАЦИЯ ТЕКСТА\\n# -------------------------\\ndef normalize_title_series(s: pd.Series) -> pd.Series:\\n    s = s.fillna(\"\")\\n    # нижний регистр + единичные пробелы\\n    s = s.str.lower()\\n    s = s.str.replace(r\"\\\\s+\", \" \", regex=True).str.strip()\\n    return s\\n\\n# -------------------------\\n# 2) РЕГЕКСЫ И СЛОВАРИ\\n# -------------------------\\nRX_EMOJI = re.compile(\\n    \"[\"                                   # очень грубый детектор эмодзи\\n    \"🌀-🙏\"\\n    \"🚀-\\U0001f6ff\"\\n    \"🤀-🧿\"\\n    \"☀-⛿✀-➿\"\\n    \"]+\"\\n)\\n\\n# ключевые хинты (EN/RU)\\nHINT_LONG  = [\\n    r\"стрим\", r\"прямой эфир\", r\"запись стрима\", r\"трансляц\",\\n    r\"live\", r\"stream\", r\"podcast\", r\"подкаст\", r\"full episode\", r\"full version\",\\n    r\"полная верс\", r\"longplay\", r\"полный выпуск\"\\n]\\nHINT_SHORT = [\\n    r\"shorts?\", r\"\\x08short\\x08\", r\"тизер\", r\"teaser\", r\"трейлер\", r\"trailer\",\\n    r\"clip\\x08\", r\"клип\\x08\", r\"highlights?\", r\"нарезка\", r\"cut\\x08\", r\"шортс\"\\n]\\nHINT_EDU   = [r\"\\x08как\\x08\", r\"how to\", r\"tutorial\", r\"урок\", r\"гайд\", r\"инструкц\", r\"обзор\", r\"review\"]\\nHINT_OFFICIAL = [r\"official\", r\"официальн\"]\\n\\n# part/episode/season\\nRX_PART_EP = re.compile(r\"(?:\\x08part\\\\s*\\\\d+\\x08|\\x08част[ьи]\\\\s*\\\\d+\\x08|\\x08s\\\\d{1,2}e\\\\d{1,2}\\x08)\", re.I)\\n\\n# годы/числа\\nRX_YEAR = re.compile(r\"\\x08(19\\\\d{2}|20\\\\d{2}|210\\\\d)\\x08\")\\n\\n# паттерны длительности внутри title (грубо)\\n# поддерживаем: \"10 часов\", \"2 часа 30 минут\", \"1h 20m\", \"90 мин\", \"00:30\", \"1:20:00\"\\nRX_TIME_BLOCKS = [\\n    (re.compile(r\"(\\\\d+)\\\\s*(?:час|часа|часов|h|hr|hour)s?\\x08\", re.I), 60),           # часы → минуты\\n    (re.compile(r\"(\\\\d+)\\\\s*(?:мин|минут|minute|m)\\x08\", re.I), 1),                   # минуты\\n    (re.compile(r\"(\\\\d+)\\\\s*(?:сек|секунд|second|s)\\x08\", re.I), 1/60),               # секунды → минуты\\n    (re.compile(r\"\\x08(\\\\d{1,2}):([0-5]\\\\d)(?::([0-5]\\\\d))?\\x08\"), \"hh:mm:ss\"),          # 1:20 или 1:20:00\\n]\\n\\ndef _extract_title_duration_min(title: str) -> float:\\n    \"\"\"Пытаемся вытащить упоминание длительности из title, вернуть минуты (float) или np.nan.\"\"\"\\n    if not title:\\n        return np.nan\\n    t = title\\n\\n    # форматы типа 1:20:00 / 1:20\\n    m = RX_TIME_BLOCKS[3][0].search(t)\\n    if m:\\n        h = int(m.group(1))\\n        mm = int(m.group(2))\\n        ss = int(m.group(3)) if m.group(3) else 0\\n        return h*60 + mm + ss/60.0\\n\\n    total_min = 0.0\\n    found = False\\n    for rx, mul in RX_TIME_BLOCKS[:3]:\\n        for g in rx.findall(t):\\n            try:\\n                num = float(g if isinstance(g, str) else g[0])\\n            except Exception:\\n                continue\\n            total_min += num * (mul if isinstance(mul, (int, float)) else 1.0)\\n            found = True\\n    return total_min if found else np.nan\\n\\n# -------------------------\\n# 3) ЛЕКСИКО-СТРУКТУРНЫЕ ФИЧИ\\n# -------------------------\\ndef extract_title_lex_features(df: pd.DataFrame, title_col: str = \"title\") -> pd.DataFrame:\\n    out = df.copy()\\n    t = normalize_title_series(out[title_col])\\n\\n    # базовые длины\\n    out[\"title_len_char\"] = t.str.len().astype(\"int32\")\\n    out[\"title_n_words\"]  = t.str.split().str.len().fillna(0).astype(\"int16\")\\n\\n    # доли символов\\n    # кириллица/латиница/цифры/верхний регистр\\n    s = out[title_col].fillna(\"\")\\n    has_cyr = s.str.contains(r\"[А-Яа-яЁё]\")\\n    has_lat = s.str.contains(r\"[A-Za-z]\")\\n    out[\"title_has_cyr\"] = has_cyr.astype(\"int8\")\\n    out[\"title_has_lat\"] = has_lat.astype(\"int8\")\\n\\n    # грубая доля цифр/знаков/прописных\\n    out[\"title_digits_ratio\"] = s.str.count(r\"\\\\d\").div(out[\"title_len_char\"].replace(0, np.nan)).fillna(0).astype(\"float32\")\\n    out[\"title_punct_ratio\"]  = s.str.count(r\"[^\\\\w\\\\s]\").div(out[\"title_len_char\"].replace(0, np.nan)).fillna(0).astype(\"float32\")\\n    out[\"title_excl_cnt\"]     = s.str.count(\"!\").astype(\"int16\")\\n    out[\"title_quest_cnt\"]    = s.str.count(\"\\\\?\").astype(\"int16\")\\n    out[\"title_hash_cnt\"]     = s.str.count(\"#\").astype(\"int16\")\\n    out[\"title_emoji_cnt\"]    = s.apply(lambda x: len(RX_EMOJI.findall(x))).astype(\"int16\")\\n\\n    # ключевые хинты (binary)\\n    def any_match(patterns, text):\\n        for p in patterns:\\n            if re.search(p, text, re.I):\\n                return 1\\n        return 0\\n\\n    out[\"title_hint_long\"]   = t.apply(lambda x: any_match(HINT_LONG, x)).astype(\"int8\")\\n    out[\"title_hint_short\"]  = t.apply(lambda x: any_match(HINT_SHORT, x)).astype(\"int8\")\\n    out[\"title_hint_edu\"]    = t.apply(lambda x: any_match(HINT_EDU, x)).astype(\"int8\")\\n    out[\"title_hint_offcl\"]  = t.apply(lambda x: any_match(HINT_OFFICIAL, x)).astype(\"int8\")\\n\\n    # part/episode + год\\n    out[\"title_has_part_ep\"] = t.str.contains(RX_PART_EP).astype(\"int8\")\\n    out[\"title_has_year\"]    = t.str.contains(RX_YEAR).astype(\"int8\")\\n\\n    # длительность, упомянутая в title\\n    out[\"title_dur_min_inferred\"] = t.apply(_extract_title_duration_min).astype(\"float32\")\\n    out[\"title_has_dur\"]          = out[\"title_dur_min_inferred\"].notna().astype(\"int8\")\\n\\n    # полезные пересечения\\n    out[\"title_is_trailer_or_teaser\"] = ((out[\"title_hint_short\"]==1) & (t.str.contains(r\"trailer|тизер|teaser\", regex=True))).astype(\"int8\")\\n    out[\"title_is_stream_live\"]       = out[\"title_hint_long\"]\\n    out[\"title_is_shorts\"]            = t.str.contains(r\"\\x08shorts?\\x08|шортс\", regex=True).astype(\"int8\")\\n\\n    # длиновые бины\\n    out[\"title_len_char_bin\"] = pd.cut(out[\"title_len_char\"], bins=[-1, 20, 35, 60, 100, 1000], labels=[0,1,2,3,4]).astype(\"int8\")\\n    out[\"title_n_words_bin\"]  = pd.cut(out[\"title_n_words\"],  bins=[-1, 3, 6, 12, 20, 100],   labels=[0,1,2,3,4]).astype(\"int8\")\\n\\n    return out\\n\\n# -------------------------\\n# 4) TF-IDF (char n-grams) → SVD\\n# -------------------------\\ndef add_tfidf_svd_features(\\n    train_df: pd.DataFrame,\\n    test_df: pd.DataFrame,\\n    title_col: str = \"title\",\\n    max_features: int = 30000,\\n    n_components: int = 32,\\n    ngram_range=(3,5),\\n    random_state: int = 42,\\n):\\n    tr = train_df.copy()\\n    te = test_df.copy()\\n\\n    tr_text = normalize_title_series(tr[title_col]).fillna(\"\")\\n    te_text = normalize_title_series(te[title_col]).fillna(\"\")\\n\\n    vec = TfidfVectorizer(\\n        analyzer=\"char\",\\n        ngram_range=ngram_range,\\n        max_features=max_features,\\n        min_df=2\\n    )\\n    X_tr = vec.fit_transform(tr_text)\\n    X_te = vec.transform(te_text)\\n\\n    svd = TruncatedSVD(n_components=n_components, random_state=random_state)\\n    Z_tr = svd.fit_transform(X_tr).astype(\"float32\")\\n    Z_te = svd.transform(X_te).astype(\"float32\")\\n\\n    for i in range(n_components):\\n        tr[f\"title_svd_{i:02d}\"] = Z_tr[:, i]\\n        te[f\"title_svd_{i:02d}\"] = Z_te[:, i]\\n\\n    artifacts = {\"vectorizer\": vec, \"svd\": svd}\\n    return tr, te, artifacts\\n\\n# -------------------------\\n# 5) КЛАСТЕРЫ + ПРИОРЫ ПО КЛАСТЕРАМ\\n# -------------------------\\ndef add_title_cluster_priors(\\n    train_df: pd.DataFrame,\\n    test_df: pd.DataFrame,\\n    y_col: str = \"y_long\",\\n    n_clusters: int = 50,\\n    base_cols_pattern: str = r\"^title_svd_\\\\d+$\",\\n    alpha: float = 2.0,\\n    beta: float = 2.0,\\n    random_state: int = 42,\\n):\\n    \"\"\"Кластерим SVD-компоненты заголовков, считаем p(y=1) по кластерам (train) и мапим в обе выборки.\"\"\"\\n    tr = train_df.copy()\\n    te = test_df.copy()\\n\\n    svd_cols = [c for c in tr.columns if re.match(base_cols_pattern, c)]\\n    X_tr = tr[svd_cols].to_numpy(dtype=np.float32)\\n    X_te = te[svd_cols].to_numpy(dtype=np.float32)\\n\\n    km = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=\"auto\")\\n    tr[\"_title_cluster\"] = km.fit_predict(X_tr).astype(\"int16\")\\n    te[\"_title_cluster\"] = km.predict(X_te).astype(\"int16\")\\n\\n    # смутый CTR по кластерам\\n    g = tr.groupby(\"_title_cluster\")[y_col].agg([\"sum\",\"count\"])\\n    p = (g[\"sum\"] + alpha) / (g[\"count\"] + alpha + beta)\\n    p = p.rename(\"p_long_title_cluster\")\\n\\n    tr[\"p_long_title_cluster\"] = tr[\"_title_cluster\"].map(p).astype(\"float32\")\\n    te[\"p_long_title_cluster\"] = te[\"_title_cluster\"].map(p).astype(\"float32\")\\n\\n    # необязательный feature: расстояние до центроида (инерция)\\n    centers = km.cluster_centers_.astype(np.float32)\\n    tr[\"title_cluster_dist\"] = ((X_tr - centers[tr[\"_title_cluster\"]])**2).sum(axis=1)**0.5\\n    te[\"title_cluster_dist\"] = ((X_te - centers[te[\"_title_cluster\"]])**2).sum(axis=1)**0.5\\n    tr[\"title_cluster_dist\"] = tr[\"title_cluster_dist\"].astype(\"float32\")\\n    te[\"title_cluster_dist\"] = te[\"title_cluster_dist\"].astype(\"float32\")\\n\\n    artifacts = {\"kmeans\": km, \"cluster_priors\": p}\\n    return tr, te, artifacts\\n\\n# -------------------------\\n# 6) ОРКЕСТРАТОР ДЛЯ TITLE\\n# -------------------------\\ndef build_title_features(\\n    train_df: pd.DataFrame,\\n    test_df: pd.DataFrame,\\n    title_col: str = \"title\",\\n    y_col: str = \"y_long\",\\n    tfidf_max_features: int = 30000,\\n    svd_components: int = 32,\\n    kmeans_clusters: int = 50,\\n):\\n    # a) лексические/структурные\\n    tr = extract_title_lex_features(train_df, title_col=title_col)\\n    te = extract_title_lex_features(test_df,  title_col=title_col)\\n\\n    # b) TF-IDF (char) → SVD\\n    tr, te, arts_tfidf = add_tfidf_svd_features(\\n        tr, te, title_col=title_col,\\n        max_features=tfidf_max_features, n_components=svd_components\\n    )\\n\\n    # c) Кластеры заголовков + приор p(y=1) по кластерам (по train)\\n    tr, te, arts_cl = add_title_cluster_priors(\\n        tr, te, y_col=y_col, n_clusters=kmeans_clusters\\n    )\\n\\n    artifacts = {\"tfidf_svd\": arts_tfidf, \"title_clusters\": arts_cl}\\n    return tr, te, artifacts\\n\\n'"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Предполагаем, что у тебя уже есть:\n# - train_time (или train_full_new1_feats) с колонками ['title', 'y_long', ...]\n# - test_time  (или test_full_feats)       с колонкой    ['title', ...]\n# (названия можешь подставить свои)\n'''\ntrain_title, test_title, title_artifacts = build_title_features(\n    train_time, test_time,\n    title_col=\"title\",\n    y_col=\"y_long\",\n    tfidf_max_features=30000,   # можно 50k, если хватает памяти\n    svd_components=32,          # 16–64 — здоровый диапазон\n    kmeans_clusters=50          # 30–100 — попробуй подобрать по CV\n)\n\n# Быстрый sanity:\nfeat_cols = [c for c in train_title.columns if c.startswith((\"title_\", \"p_long_title_cluster\"))]\nprint(len(feat_cols), \"title-features\")\nprint(train_title[feat_cols].head())\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.684735Z","iopub.execute_input":"2025-10-27T13:10:58.684966Z","iopub.status.idle":"2025-10-27T13:10:58.702859Z","shell.execute_reply.started":"2025-10-27T13:10:58.684947Z","shell.execute_reply":"2025-10-27T13:10:58.702232Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'\\ntrain_title, test_title, title_artifacts = build_title_features(\\n    train_time, test_time,\\n    title_col=\"title\",\\n    y_col=\"y_long\",\\n    tfidf_max_features=30000,   # можно 50k, если хватает памяти\\n    svd_components=32,          # 16–64 — здоровый диапазон\\n    kmeans_clusters=50          # 30–100 — попробуй подобрать по CV\\n)\\n\\n# Быстрый sanity:\\nfeat_cols = [c for c in train_title.columns if c.startswith((\"title_\", \"p_long_title_cluster\"))]\\nprint(len(feat_cols), \"title-features\")\\nprint(train_title[feat_cols].head())\\n'"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SKF catboost","metadata":{}},{"cell_type":"code","source":"useless=['v_cr_click_dislike_7_days','v_cr_click_dislike_30_days',\n         'v_avg_watchtime_7_day','v_avg_watchtime_30_day',\n         'v_frac_avg_watchtime_7_day_duration','v_frac_avg_watchtime_30_day_duration',\n         'v_month_views','v_week_views',\n         'v_cr_click_like_7_days','v_cr_click_like_30_days',\n         'v_cr_click_comment_7_days','v_cr_click_comment_30_days',\n         'v_cr_click_long_view_7_days','v_cr_click_long_view_30_days',\n         'v_category_popularity_percent_30_days',\n         'v_long_views_7_days','v_long_views_30_days',\n         'v_is_deleted','v_is_hidden','row_number',\n         \n         'user_id','category_id','author_id', 'video_id',\n         'description','title',\n         'region','city']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.703556Z","iopub.execute_input":"2025-10-27T13:10:58.703834Z","iopub.status.idle":"2025-10-27T13:10:58.717897Z","shell.execute_reply.started":"2025-10-27T13:10:58.703818Z","shell.execute_reply":"2025-10-27T13:10:58.717246Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"#train_full_new1=train_full_new.drop(columns=useless)\n\n#test_full_new1=test_full.drop(columns=useless)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.721843Z","iopub.execute_input":"2025-10-27T13:10:58.722315Z","iopub.status.idle":"2025-10-27T13:10:58.735045Z","shell.execute_reply.started":"2025-10-27T13:10:58.722295Z","shell.execute_reply":"2025-10-27T13:10:58.734287Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"#train_new","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.735797Z","iopub.execute_input":"2025-10-27T13:10:58.736065Z","iopub.status.idle":"2025-10-27T13:10:58.747653Z","shell.execute_reply.started":"2025-10-27T13:10:58.736050Z","shell.execute_reply":"2025-10-27T13:10:58.746923Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport numpy as np\nimport pandas as pd\n\ndef make_long_watch_flag(df, duration_col='v_duration', watch_col='watchtime', strict=True, unit='s'):\n    # 1) to seconds (if needed) and numeric\n    dur = pd.to_numeric(df[duration_col], errors='coerce')\n    wt  = pd.to_numeric(df[watch_col],  errors='coerce')\n    if unit == 'ms':\n        dur = dur / 1000.0\n        wt  = wt  / 1000.0\n\n    # 2) thresholds\n    thr = np.where(dur > 300.0, dur * 0.25, 30.0)  # 300s = 5 min\n\n    # 3) validity mask and comparison\n    valid = dur.notna() & wt.notna() & (dur > 0) & (wt >= 0)\n    cmp = (wt > thr) if strict else (wt >= thr)\n\n    # 4) build nullable Int8 target safely (pandas Series + pd.NA)\n    y = pd.Series(cmp, index=df.index)\n    y.loc[~valid] = pd.NA\n    df['y_long'] = y.astype('Int8')  # 0/1 with NA\n\n    # optional: keep threshold for debugging\n    df['longwatch_threshold_sec'] = pd.Series(np.where(valid, thr, np.nan), index=df.index)\n\n    return df\n\n\n# Example:\n#train_full_new1 = make_long_watch_flag(train_full_new1, 'v_duration', 'watchtime', strict=True)\n# If test has watchtime and you want the same flag there:\n# test = make_long_watch_flag(test, 'v_duration', 'watchtime', strict=True)\n\n# Quick sanity check\n#print(train_full_new1['y_long'].value_counts(dropna=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.748237Z","iopub.execute_input":"2025-10-27T13:10:58.748398Z","iopub.status.idle":"2025-10-27T13:10:58.761827Z","shell.execute_reply.started":"2025-10-27T13:10:58.748386Z","shell.execute_reply":"2025-10-27T13:10:58.761114Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"train_time.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.762605Z","iopub.execute_input":"2025-10-27T13:10:58.762814Z","iopub.status.idle":"2025-10-27T13:10:58.785258Z","shell.execute_reply.started":"2025-10-27T13:10:58.762799Z","shell.execute_reply":"2025-10-27T13:10:58.784610Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3263353 entries, 0 to 3263352\nData columns (total 63 columns):\n #   Column                                Dtype                        \n---  ------                                -----                        \n 0   event_timestamp                       datetime64[ms, Europe/Moscow]\n 1   user_id                               object                       \n 2   region                                object                       \n 3   city                                  object                       \n 4   video_id                              object                       \n 5   watchtime                             int64                        \n 6   v_pub_datetime                        datetime64[ms]               \n 7   v_total_comments                      uint64                       \n 8   v_year_views                          uint64                       \n 9   v_day_views                           uint64                       \n 10  v_likes                               uint64                       \n 11  v_dislikes                            uint64                       \n 12  v_duration                            float64                      \n 13  v_cr_click_vtop_7_days                float64                      \n 14  v_cr_click_vtop_30_days               float64                      \n 15  v_cr_click_like_1_days                float64                      \n 16  v_cr_click_dislike_1_days             float64                      \n 17  v_cr_click_vtop_1_days                float64                      \n 18  v_cr_click_long_view_1_days           float64                      \n 19  v_cr_click_comment_1_days             float64                      \n 20  v_avg_watchtime_1_day                 float64                      \n 21  v_frac_avg_watchtime_1_day_duration   float64                      \n 22  v_category_popularity_percent_7_days  float64                      \n 23  v_long_views_1_days                   uint64                       \n 24  title                                 object                       \n 25  description                           object                       \n 26  category_id                           object                       \n 27  author_id                             object                       \n 28  y_long                                int8                         \n 29  longwatch_threshold_sec               float64                      \n 30  event_dt_msk                          datetime64[ms, Europe/Moscow]\n 31  pub_dt_msk                            datetime64[ms, Europe/Moscow]\n 32  hour                                  int8                         \n 33  minute                                int8                         \n 34  second                                int8                         \n 35  minute_of_day                         int16                        \n 36  sec_of_day                            int32                        \n 37  is_morning                            int8                         \n 38  is_day                                int8                         \n 39  is_evening                            int8                         \n 40  is_night                              int8                         \n 41  f_day_sin_1                           float32                      \n 42  f_day_cos_1                           float32                      \n 43  f_day_sin_2                           float32                      \n 44  f_day_cos_2                           float32                      \n 45  age_sec                               float32                      \n 46  age_hours                             float32                      \n 47  age_days                              float32                      \n 48  age_log1p                             float32                      \n 49  age_neg_flag                          int8                         \n 50  is_fresh_1h                           int8                         \n 51  is_fresh_3h                           int8                         \n 52  is_fresh_12h                          int8                         \n 53  age_bin                               category                     \n 54  age_bin_idx                           int16                        \n 55  min5_bucket                           int16                        \n 56  p_long_hour                           float32                      \n 57  p_long_minute                         float32                      \n 58  p_long_min5                           float32                      \n 59  p_long_agebin                         float32                      \n 60  p_long_video_hour                     float32                      \n 61  time_since_prev_user                  float32                      \n 62  time_since_prev_uv                    float32                      \ndtypes: category(1), datetime64[ms, Europe/Moscow](3), datetime64[ms](1), float32(15), float64(12), int16(3), int32(1), int64(1), int8(12), object(8), uint64(6)\nmemory usage: 1.0+ GB\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"useless_cols=['event_dt_msk','pub_dt_msk','age_bin','event_timestamp',\n          'v_pub_datetime']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.786075Z","iopub.execute_input":"2025-10-27T13:10:58.786325Z","iopub.status.idle":"2025-10-27T13:10:58.798647Z","shell.execute_reply.started":"2025-10-27T13:10:58.786292Z","shell.execute_reply":"2025-10-27T13:10:58.797940Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"train_time=train_time.drop(columns=useless_cols)\n\ntest_time=test_time.drop(columns=useless_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:10:58.799285Z","iopub.execute_input":"2025-10-27T13:10:58.799548Z","iopub.status.idle":"2025-10-27T13:11:00.128448Z","shell.execute_reply.started":"2025-10-27T13:10:58.799524Z","shell.execute_reply":"2025-10-27T13:11:00.127844Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train_time=train_time[:2_000_000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:11:00.129280Z","iopub.execute_input":"2025-10-27T13:11:00.129563Z","iopub.status.idle":"2025-10-27T13:11:00.133251Z","shell.execute_reply.started":"2025-10-27T13:11:00.129537Z","shell.execute_reply":"2025-10-27T13:11:00.132535Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"X=train_time.drop(columns=['watchtime', 'y_long', 'longwatch_threshold_sec', 'title', 'description'])\ny=train_time['y_long']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:11:00.133977Z","iopub.execute_input":"2025-10-27T13:11:00.134228Z","iopub.status.idle":"2025-10-27T13:11:00.632709Z","shell.execute_reply.started":"2025-10-27T13:11:00.134206Z","shell.execute_reply":"2025-10-27T13:11:00.632044Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"X_train, X_eval, y_train, y_eval=train_test_split(X, y, test_size=0.15, random_state=seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:11:00.633534Z","iopub.execute_input":"2025-10-27T13:11:00.633794Z","iopub.status.idle":"2025-10-27T13:11:02.286724Z","shell.execute_reply.started":"2025-10-27T13:11:00.633770Z","shell.execute_reply":"2025-10-27T13:11:02.286097Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"#for now just one catboost \n\nmodel=CatBoostClassifier(\n    iterations=1000,\n    depth=6,\n    learning_rate=0.03,\n    loss_function='Logloss',\n    eval_metric='F1',\n    task_type='GPU',\n    #l2_leaf_reg=,\n    \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:11:02.287465Z","iopub.execute_input":"2025-10-27T13:11:02.287745Z","iopub.status.idle":"2025-10-27T13:11:02.293191Z","shell.execute_reply.started":"2025-10-27T13:11:02.287719Z","shell.execute_reply":"2025-10-27T13:11:02.292382Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"cat_feats=[ 'user_id','video_id','category_id','author_id',  'region','city']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:11:02.294039Z","iopub.execute_input":"2025-10-27T13:11:02.294356Z","iopub.status.idle":"2025-10-27T13:11:02.306469Z","shell.execute_reply.started":"2025-10-27T13:11:02.294339Z","shell.execute_reply":"2025-10-27T13:11:02.305786Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"model.fit(X_train, y_train, eval_set=(X_eval, y_eval),cat_features=cat_feats, verbose=200, early_stopping_rounds=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:11:02.307236Z","iopub.execute_input":"2025-10-27T13:11:02.307505Z","iopub.status.idle":"2025-10-27T13:13:51.488932Z","shell.execute_reply.started":"2025-10-27T13:11:02.307464Z","shell.execute_reply":"2025-10-27T13:13:51.488222Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.7935981\ttest: 0.7943852\tbest: 0.7943852 (0)\ttotal: 5.88s\tremaining: 1h 37m 53s\n200:\tlearn: 0.8136516\ttest: 0.8161151\tbest: 0.8161233 (196)\ttotal: 29.5s\tremaining: 1m 57s\n400:\tlearn: 0.8176377\ttest: 0.8195704\tbest: 0.8195920 (399)\ttotal: 52.6s\tremaining: 1m 18s\n600:\tlearn: 0.8215543\ttest: 0.8226410\tbest: 0.8226450 (599)\ttotal: 1m 16s\tremaining: 50.7s\n800:\tlearn: 0.8246161\ttest: 0.8249453\tbest: 0.8249453 (800)\ttotal: 1m 39s\tremaining: 24.8s\n999:\tlearn: 0.8266115\ttest: 0.8265104\tbest: 0.8265104 (999)\ttotal: 2m 3s\tremaining: 0us\nbestTest = 0.826510408\nbestIteration = 999\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<catboost.core.CatBoostClassifier at 0x7e74fb66e090>"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"# Just mean of them ","metadata":{}},{"cell_type":"code","source":"num_feats=train_full_new1.select_dtypes(include='number').columns.tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:13:51.489782Z","iopub.execute_input":"2025-10-27T13:13:51.490020Z","iopub.status.idle":"2025-10-27T13:13:51.979794Z","shell.execute_reply.started":"2025-10-27T13:13:51.490001Z","shell.execute_reply":"2025-10-27T13:13:51.978996Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"corr=train_full_new1[num_feats].corrwith(train_full_new1['y_long'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:13:51.980655Z","iopub.execute_input":"2025-10-27T13:13:51.980878Z","iopub.status.idle":"2025-10-27T13:13:54.708361Z","shell.execute_reply.started":"2025-10-27T13:13:51.980862Z","shell.execute_reply":"2025-10-27T13:13:54.707752Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"corr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:13:54.709116Z","iopub.execute_input":"2025-10-27T13:13:54.709362Z","iopub.status.idle":"2025-10-27T13:13:54.715176Z","shell.execute_reply.started":"2025-10-27T13:13:54.709342Z","shell.execute_reply":"2025-10-27T13:13:54.714445Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"watchtime                               0.411520\nv_total_comments                       -0.017482\nv_year_views                           -0.011971\nv_day_views                             0.050856\nv_likes                                 0.010362\nv_dislikes                             -0.001967\nv_duration                             -0.070463\nv_cr_click_vtop_7_days                  0.006475\nv_cr_click_vtop_30_days                 0.006475\nv_cr_click_like_1_days                 -0.003513\nv_cr_click_dislike_1_days               0.000486\nv_cr_click_vtop_1_days                  0.006475\nv_cr_click_long_view_1_days             0.550106\nv_cr_click_comment_1_days              -0.000820\nv_avg_watchtime_1_day                   0.050975\nv_frac_avg_watchtime_1_day_duration     0.007242\nv_category_popularity_percent_7_days    0.098284\nv_long_views_1_days                     0.166037\ny_long                                  1.000000\nlongwatch_threshold_sec                -0.081352\ndtype: float64"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"X_test=test_time.drop(columns=['title', 'description'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:13:54.715961Z","iopub.execute_input":"2025-10-27T13:13:54.716221Z","iopub.status.idle":"2025-10-27T13:13:55.032056Z","shell.execute_reply.started":"2025-10-27T13:13:54.716199Z","shell.execute_reply":"2025-10-27T13:13:55.031418Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"preds=model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:13:55.032767Z","iopub.execute_input":"2025-10-27T13:13:55.033024Z","iopub.status.idle":"2025-10-27T13:14:19.380353Z","shell.execute_reply.started":"2025-10-27T13:13:55.032997Z","shell.execute_reply":"2025-10-27T13:14:19.379748Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"sample['target']=preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:14:19.381109Z","iopub.execute_input":"2025-10-27T13:14:19.381293Z","iopub.status.idle":"2025-10-27T13:14:19.386300Z","shell.execute_reply.started":"2025-10-27T13:14:19.381279Z","shell.execute_reply":"2025-10-27T13:14:19.385755Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"sample.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T13:14:19.387035Z","iopub.execute_input":"2025-10-27T13:14:19.387285Z","iopub.status.idle":"2025-10-27T13:14:20.200104Z","shell.execute_reply.started":"2025-10-27T13:14:19.387264Z","shell.execute_reply":"2025-10-27T13:14:20.199330Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"# Meta Models","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}