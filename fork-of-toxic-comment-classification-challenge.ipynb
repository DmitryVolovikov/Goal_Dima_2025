{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8076,"databundleVersionId":44219,"sourceType":"competition"},{"sourceId":12508243,"sourceType":"datasetVersion","datasetId":7894795}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:06:59.449572Z","iopub.execute_input":"2025-07-18T17:06:59.450111Z","iopub.status.idle":"2025-07-18T17:06:59.763562Z","shell.execute_reply.started":"2025-07-18T17:06:59.450077Z","shell.execute_reply":"2025-07-18T17:06:59.762834Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n/kaggle/input/toxic-comment-classification/train_preproccesed.csv\n/kaggle/input/toxic-comment-classification/test_preproccesed.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Сиды","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\n\ntry:\n    # Hugging Face convenience fn; sets Python/Rand, NumPy, Torch seeds\n    from transformers import set_seed  \nexcept ImportError:\n    set_seed = None\n\ndef seed_everything(seed: int = 42):\n    # 1. Python built‑ins\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n\n    # 2. NumPy\n    np.random.seed(seed)\n\n    # 3. PyTorch (CPU & GPU)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    # 4. CuDNN: make deterministic, but may slow you down\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n    # 5. Transformers (if installed)\n    if set_seed is not None:\n        set_seed(seed)\n\n# call it!\nseed_everything(42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:06:59.764935Z","iopub.execute_input":"2025-07-18T17:06:59.765265Z","iopub.status.idle":"2025-07-18T17:07:19.198840Z","shell.execute_reply.started":"2025-07-18T17:06:59.765246Z","shell.execute_reply":"2025-07-18T17:07:19.198265Z"}},"outputs":[{"name":"stderr","text":"2025-07-18 17:07:07.559800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752858427.763788      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752858427.826919      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:19.199447Z","iopub.execute_input":"2025-07-18T17:07:19.199963Z","iopub.status.idle":"2025-07-18T17:07:19.266884Z","shell.execute_reply.started":"2025-07-18T17:07:19.199943Z","shell.execute_reply":"2025-07-18T17:07:19.265981Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Импорты","metadata":{}},{"cell_type":"code","source":"!pip install --quiet evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:19.268863Z","iopub.execute_input":"2025-07-18T17:07:19.269103Z","iopub.status.idle":"2025-07-18T17:07:24.004301Z","shell.execute_reply.started":"2025-07-18T17:07:19.269080Z","shell.execute_reply":"2025-07-18T17:07:24.003538Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch \nimport spacy\nfrom transformers import Trainer, TrainingArguments, AutoModelForCausalLM, PreTrainedTokenizer, BertTokenizer, AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, EvalPrediction \nimport re\nimport evaluate \nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:24.005760Z","iopub.execute_input":"2025-07-18T17:07:24.006057Z","iopub.status.idle":"2025-07-18T17:07:35.107866Z","shell.execute_reply.started":"2025-07-18T17:07:24.006021Z","shell.execute_reply":"2025-07-18T17:07:35.107283Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"#train=pd.read_csv(\"/kaggle/input/toxic-comment-classification/train_preproccesed.csv\")\n#test=pd.read_csv(\"/kaggle/input/toxic-comment-classification/test_preproccesed.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:35.108620Z","iopub.execute_input":"2025-07-18T17:07:35.109211Z","iopub.status.idle":"2025-07-18T17:07:35.112537Z","shell.execute_reply.started":"2025-07-18T17:07:35.109192Z","shell.execute_reply":"2025-07-18T17:07:35.111832Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")\ntest=pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\")\ntest_labels=pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\")\nsample=pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:35.113262Z","iopub.execute_input":"2025-07-18T17:07:35.113533Z","iopub.status.idle":"2025-07-18T17:07:38.890814Z","shell.execute_reply.started":"2025-07-18T17:07:35.113504Z","shell.execute_reply":"2025-07-18T17:07:38.890026Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"'''\nубрать большие буквы\nубрать кавычки \nубрать обратные слеши и n (\\n)\nдо базовых слов сделать \nлеммитизация (стемминг на крайний случай)\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:38.891724Z","iopub.execute_input":"2025-07-18T17:07:38.892008Z","iopub.status.idle":"2025-07-18T17:07:38.898586Z","shell.execute_reply.started":"2025-07-18T17:07:38.891977Z","shell.execute_reply":"2025-07-18T17:07:38.898019Z"},"editable":false},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'\\nубрать большие буквы\\nубрать кавычки \\nубрать обратные слеши и n (\\n)\\nдо базовых слов сделать \\nлеммитизация (стемминг на крайний случай)\\n'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:38.899249Z","iopub.execute_input":"2025-07-18T17:07:38.899455Z","iopub.status.idle":"2025-07-18T17:07:38.912504Z","shell.execute_reply.started":"2025-07-18T17:07:38.899439Z","shell.execute_reply":"2025-07-18T17:07:38.911831Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Чистка данных ","metadata":{}},{"cell_type":"code","source":"#nlp=spacy.load('en_core_web_sm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:38.915265Z","iopub.execute_input":"2025-07-18T17:07:38.915440Z","iopub.status.idle":"2025-07-18T17:07:38.930831Z","shell.execute_reply.started":"2025-07-18T17:07:38.915426Z","shell.execute_reply":"2025-07-18T17:07:38.930165Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"'''def clean(text):\n    #text=str(text)\n    text=text.lower()\n    text=text.replace('\\n', '')\n    text=re.sub(r'[^a-zA-Z0-9]', ' ', text)\n    text=re.sub(r\"\\s+\", \" \", text).strip()\n    doc=nlp(text)\n    lemmas=[token.lemma_ for token in doc if not token.is_space]\n    return \" \".join(lemmas)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:38.931506Z","iopub.execute_input":"2025-07-18T17:07:38.931741Z","iopub.status.idle":"2025-07-18T17:07:38.947190Z","shell.execute_reply.started":"2025-07-18T17:07:38.931718Z","shell.execute_reply":"2025-07-18T17:07:38.946546Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'def clean(text):\\n    #text=str(text)\\n    text=text.lower()\\n    text=text.replace(\\'\\n\\', \\'\\')\\n    text=re.sub(r\\'[^a-zA-Z0-9]\\', \\' \\', text)\\n    text=re.sub(r\"\\\\s+\", \" \", text).strip()\\n    doc=nlp(text)\\n    lemmas=[token.lemma_ for token in doc if not token.is_space]\\n    return \" \".join(lemmas)'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#train['comment_text']=train['comment_text'].apply(clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:38.947916Z","iopub.execute_input":"2025-07-18T17:07:38.948138Z","iopub.status.idle":"2025-07-18T17:07:38.960126Z","shell.execute_reply.started":"2025-07-18T17:07:38.948114Z","shell.execute_reply":"2025-07-18T17:07:38.959508Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#test['comment_text']=test['comment_text'].apply(clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:38.960830Z","iopub.execute_input":"2025-07-18T17:07:38.961063Z","iopub.status.idle":"2025-07-18T17:07:38.975478Z","shell.execute_reply.started":"2025-07-18T17:07:38.961038Z","shell.execute_reply":"2025-07-18T17:07:38.974791Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#train.to_csv(\"train_preproccesed.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:38.976270Z","iopub.execute_input":"2025-07-18T17:07:38.976597Z","iopub.status.idle":"2025-07-18T17:07:38.989267Z","shell.execute_reply.started":"2025-07-18T17:07:38.976573Z","shell.execute_reply":"2025-07-18T17:07:38.988740Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#test.to_csv(\"test_preproccesed.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:38.990079Z","iopub.execute_input":"2025-07-18T17:07:38.990346Z","iopub.status.idle":"2025-07-18T17:07:39.003978Z","shell.execute_reply.started":"2025-07-18T17:07:38.990325Z","shell.execute_reply":"2025-07-18T17:07:39.003209Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Датасет","metadata":{}},{"cell_type":"code","source":"class ToxicDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=256):\n        self.texts=texts\n        self.labels=labels\n        self.tokenizer=tokenizer\n        self.max_len=max_len\n        \n    def __len__(self):\n        return len(self.texts)\n\n        \n    def __getitem__(self, idx):\n        text  = str(self.texts[idx])\n        labels_for_one=self.labels[idx]\n        encoding=self.tokenizer(\n            text, \n            max_length=self.max_len,\n            truncation   = True,\n            padding='max_length',\n            add_special_tokens=True,\n            return_tensors='pt',\n            return_attention_mask=True,\n            \n            \n        )\n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'labels': torch.tensor(labels_for_one, dtype=torch.float),\n        }\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:39.004740Z","iopub.execute_input":"2025-07-18T17:07:39.005039Z","iopub.status.idle":"2025-07-18T17:07:39.020115Z","shell.execute_reply.started":"2025-07-18T17:07:39.005011Z","shell.execute_reply":"2025-07-18T17:07:39.019559Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"full_train_texts=train['comment_text'].tolist()\ntest_texts=test['comment_text'].tolist()\n\ntrain_labels=train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:39.020869Z","iopub.execute_input":"2025-07-18T17:07:39.021281Z","iopub.status.idle":"2025-07-18T17:07:39.063871Z","shell.execute_reply.started":"2025-07-18T17:07:39.021263Z","shell.execute_reply":"2025-07-18T17:07:39.063039Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_texts, eval_texts, train_targets, eval_targets=train_test_split(full_train_texts, train_labels, test_size=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:39.064725Z","iopub.execute_input":"2025-07-18T17:07:39.064975Z","iopub.status.idle":"2025-07-18T17:07:39.126209Z","shell.execute_reply.started":"2025-07-18T17:07:39.064951Z","shell.execute_reply":"2025-07-18T17:07:39.125650Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Токенайзер","metadata":{}},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:39.126984Z","iopub.execute_input":"2025-07-18T17:07:39.127254Z","iopub.status.idle":"2025-07-18T17:07:40.615817Z","shell.execute_reply.started":"2025-07-18T17:07:39.127228Z","shell.execute_reply":"2025-07-18T17:07:40.615201Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc2e55a1fa3a447ab962a5a8be6fb31d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a646a5f5da244f2831b75e6d9ad1fd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f12e3a10204b08abd7efe0255b5fdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18f35a7d9d5a4ba298ecdf73b77e6748"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"train_dataset=ToxicDataset(train_texts, train_targets,tokenizer, max_len=256 )\neval_dataset=ToxicDataset(eval_texts, eval_targets,tokenizer, max_len=256 )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:40.616536Z","iopub.execute_input":"2025-07-18T17:07:40.616784Z","iopub.status.idle":"2025-07-18T17:07:40.620500Z","shell.execute_reply.started":"2025-07-18T17:07:40.616757Z","shell.execute_reply":"2025-07-18T17:07:40.619890Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Моделька","metadata":{}},{"cell_type":"code","source":"config=AutoConfig.from_pretrained(\n    'bert-base-uncased', \n    num_labels=6,\n    problem_type=\"multi_label_classification\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:40.621212Z","iopub.execute_input":"2025-07-18T17:07:40.621758Z","iopub.status.idle":"2025-07-18T17:07:40.728064Z","shell.execute_reply.started":"2025-07-18T17:07:40.621735Z","shell.execute_reply":"2025-07-18T17:07:40.727551Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model=AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', config=config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:40.728763Z","iopub.execute_input":"2025-07-18T17:07:40.729023Z","iopub.status.idle":"2025-07-18T17:07:43.301940Z","shell.execute_reply.started":"2025-07-18T17:07:40.728996Z","shell.execute_reply":"2025-07-18T17:07:43.301281Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8f6f8d46e94575aa4e1473b7c6bb9e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:43.302619Z","iopub.execute_input":"2025-07-18T17:07:43.302826Z","iopub.status.idle":"2025-07-18T17:07:43.610411Z","shell.execute_reply.started":"2025-07-18T17:07:43.302809Z","shell.execute_reply":"2025-07-18T17:07:43.609807Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=6, bias=True)\n)"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"# Метрика","metadata":{}},{"cell_type":"code","source":"roc_auc = evaluate.load(\"roc_auc\", \"multilabel\")\n\n# 2) Define a compute_metrics fn\ndef compute_metrics(eval_pred: EvalPrediction):\n    logits, labels = eval_pred.predictions, eval_pred.label_ids\n    # Convert logits → probabilities with sigmoid\n    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n    # Pass them in as \"prediction_scores\"\n    result = roc_auc.compute(prediction_scores=probs, references=labels)\n    return {\"roc_auc\": result[\"roc_auc\"]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:43.611161Z","iopub.execute_input":"2025-07-18T17:07:43.611368Z","iopub.status.idle":"2025-07-18T17:07:44.707640Z","shell.execute_reply.started":"2025-07-18T17:07:43.611348Z","shell.execute_reply":"2025-07-18T17:07:44.707039Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945ead52475e480a8581fc8db91d4a9d"}},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# trainer ","metadata":{}},{"cell_type":"code","source":"import wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:44.708374Z","iopub.execute_input":"2025-07-18T17:07:44.708610Z","iopub.status.idle":"2025-07-18T17:07:46.805815Z","shell.execute_reply.started":"2025-07-18T17:07:44.708591Z","shell.execute_reply":"2025-07-18T17:07:46.805081Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"wandb.login(key='09a943df432f7799fb447e658f9b2149dee74ee0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:46.806675Z","iopub.execute_input":"2025-07-18T17:07:46.806947Z","iopub.status.idle":"2025-07-18T17:07:52.680703Z","shell.execute_reply.started":"2025-07-18T17:07:46.806921Z","shell.execute_reply":"2025-07-18T17:07:52.680074Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvolovikov-dmitry\u001b[0m (\u001b[33mvolovikov-dmitry-hse-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import os\n\n# chose a name for your W&B project\nos.environ[\"WANDB_PROJECT\"] = \"toxic-comment-classification\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:07:52.681337Z","iopub.execute_input":"2025-07-18T17:07:52.681894Z","iopub.status.idle":"2025-07-18T17:07:52.685511Z","shell.execute_reply.started":"2025-07-18T17:07:52.681876Z","shell.execute_reply":"2025-07-18T17:07:52.684773Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"args= TrainingArguments(\n    output_dir='gol',\n    #eval_strategy=\"epoch\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    learning_rate=3e-5,\n    num_train_epochs=1,\n    lr_scheduler_type='cosine',\n    #warmup_ratio=0.1,\n    warmup_steps=250,\n    #save_strategy='best',\n    save_total_limit=2,\n    seed=42,\n    #fp16=True,\n    greater_is_better=True,\n    #label_smoothing_factor=0.1,\n    logging_strategy=\"steps\",             # log every N steps (needed for WandB)\n    logging_steps=50,                     # change this to your desired frequency\n    report_to=\"wandb\",                    # enable WandB logging\n    run_name=\"toxic-comment-classifier22\", \n    load_best_model_at_end=True,\n    metric_for_best_model=\"roc_auc\",\n    eval_strategy=\"steps\",\n    eval_steps=500,\n\n    # save a checkpoint every 1000 steps (and keep only the last 2)\n    save_strategy=\"steps\",\n    save_steps=1000,\n\n    #project bame?\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:32:13.733875Z","iopub.execute_input":"2025-07-18T17:32:13.734125Z","iopub.status.idle":"2025-07-18T17:32:13.761992Z","shell.execute_reply.started":"2025-07-18T17:32:13.734107Z","shell.execute_reply":"2025-07-18T17:32:13.761437Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"trainer=Trainer(\n    args=args,\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:32:16.399790Z","iopub.execute_input":"2025-07-18T17:32:16.400340Z","iopub.status.idle":"2025-07-18T17:32:16.416438Z","shell.execute_reply.started":"2025-07-18T17:32:16.400313Z","shell.execute_reply":"2025-07-18T17:32:16.415684Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3289418210.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer=Trainer(\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# Обучение","metadata":{"editable":false}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:32:19.139380Z","iopub.execute_input":"2025-07-18T17:32:19.140245Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1501' max='4488' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1501/4488 26:48 < 53:24, 0.93 it/s, Epoch 0.33/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.032500</td>\n      <td>0.043737</td>\n      <td>0.984670</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.033400</td>\n      <td>0.043763</td>\n      <td>0.984871</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='457' max='499' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [457/499 01:57 < 00:10, 3.87 it/s]\n    </div>\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"from scipy.special import expit  # vectorized sigmoid\n\n# 1) Prepare your test dataset\n#    If your ToxicDataset requires labels, just pass dummy zeros — they won’t be used at predict time.\ntest_labels_dummy = np.zeros((len(test_texts), 6), dtype=float)\ntest_dataset = ToxicDataset(\n    texts    = test_texts,\n    labels   = test_labels_dummy,\n    tokenizer=tokenizer,\n    max_len  = 256\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:27:29.287104Z","iopub.status.idle":"2025-07-18T17:27:29.287317Z","shell.execute_reply.started":"2025-07-18T17:27:29.287211Z","shell.execute_reply":"2025-07-18T17:27:29.287221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.compute_metrics = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:27:29.288608Z","iopub.status.idle":"2025-07-18T17:27:29.288933Z","shell.execute_reply.started":"2025-07-18T17:27:29.288764Z","shell.execute_reply":"2025-07-18T17:27:29.288779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_out = trainer.predict(test_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:27:29.290194Z","iopub.status.idle":"2025-07-18T17:27:29.290513Z","shell.execute_reply.started":"2025-07-18T17:27:29.290350Z","shell.execute_reply":"2025-07-18T17:27:29.290365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"probs = expit(pred_out.predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:27:29.291899Z","iopub.status.idle":"2025-07-18T17:27:29.292172Z","shell.execute_reply.started":"2025-07-18T17:27:29.292027Z","shell.execute_reply":"2025-07-18T17:27:29.292041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame(\n    probs,\n    columns=[\n        \"toxic\",\n        \"severe_toxic\",\n        \"obscene\",\n        \"threat\",\n        \"insult\",\n        \"identity_hate\"\n    ]\n)\n# Don’t forget the test IDs\nsubmission.insert(0, \"id\", test[\"id\"].values)\n\n# 5) Save to CSV\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T17:27:29.293742Z","iopub.status.idle":"2025-07-18T17:27:29.293965Z","shell.execute_reply.started":"2025-07-18T17:27:29.293858Z","shell.execute_reply":"2025-07-18T17:27:29.293867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}