{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Сиды","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch \nimport os \nimport random \n\nseed=42\n\nos.environ['PYTHONHASHSEED']=str(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TEST MODE","metadata":{}},{"cell_type":"code","source":"TEST_MODE=True ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Импорты","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms as v2\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import Trainer, TrainingArguments, CLIPModel, CLIPProccesor\nimport PIL \nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"train=pd.read_tsv('/kaggle/input/image-text-matching-vseros-2024/train_df.tsv')\ntest=pd.read_tsv('/kaggle/input/image-text-matching-vseros-2024/test_df.tsv')\n\ntrain_dir='/kaggle/input/image-text-matching-vseros-2024/train.bin'\ntest_dir='/kaggle/input/image-text-matching-vseros-2024/test-001.bin'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# If TEST MODE","metadata":{}},{"cell_type":"code","source":"if TEST_MODE:\n    train=train[:100]\nelse:\n    train=train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split","metadata":{}},{"cell_type":"code","source":"train_data, eval_data =train_test_split(train, test_size=0.2, seed=seed)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"IMG_SIZE=384","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ImageTextDataset(Dataset):\n    def __init__(self, img_dir, df, train):\n        self.img_dir=img_dir\n\n        self.df=df\n\n\n        self.train=train\n        \n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        image_root=row['filename']\n        text_root=row['text']\n        image_all_root=os.path.join(img_dir, f'{image_root}')\n        image=Image.open(image_all_root).convert('RGB')\n        if self.transforms is not None:\n            image=self.transforms(image)\n        else:\n            image=image\n        if self.train:\n            label=torch\n            return{\n                'image': image,\n                'text': text_root, \n                'label': \n                \n            }\n        else:\n            return{\n                'image': image,\n                'text': text_root, \n                \n            }\n        \n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Аугментации","metadata":{}},{"cell_type":"code","source":"train_transforms=v2.Compose([\n    v2.Resize((IMG_SIZE)),\n    v2.Random\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.406, 0.456, 0.485], std=[0.209, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T13:04:59.039583Z","iopub.execute_input":"2025-09-24T13:04:59.039915Z","iopub.status.idle":"2025-09-24T13:04:59.146081Z","shell.execute_reply.started":"2025-09-24T13:04:59.039883Z","shell.execute_reply":"2025-09-24T13:04:59.144028Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/914937759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_transforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'v2' is not defined"],"ename":"NameError","evalue":"name 'v2' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"eval_transforms=v2.Compose([\n        \n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Создание датасетов","metadata":{}},{"cell_type":"code","source":"train_dataset=\neval_dataset=\ntest_dataset=","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model=CLIPModel.from_pretrained('ai-forever/ruclip-vit-base-patch32-384', num_classes=3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"proccesor=CLIPProcessor.from_pretrained('ai-forever/ruclip-vit-base-patch32-384')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MLP Coral ","metadata":{}},{"cell_type":"code","source":"class MLPCoral(nn.Module):\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EPOCHS","metadata":{}},{"cell_type":"code","source":"EPOCHS=1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLIP loss for trainer","metadata":{}},{"cell_type":"code","source":"class CLIPTrainer(Trainer):\n    def compute_loss():\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# compute metrics","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    \n    return {\n        'accuracy':\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Arguments","metadata":{}},{"cell_type":"code","source":"args=TrainingArguments(\n    \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"trainer=Trainer(\n    args=args,\n    model=model,\n    \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# train","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}