{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14429,"databundleVersionId":420648,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:16.829335Z","iopub.execute_input":"2025-09-10T20:17:16.829962Z","iopub.status.idle":"2025-09-10T20:17:17.086981Z","shell.execute_reply.started":"2025-09-10T20:17:16.829932Z","shell.execute_reply":"2025-09-10T20:17:17.086322Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sweden-traffic-signs-classification/sample.csv\n/kaggle/input/sweden-traffic-signs-classification/data.rar\n/kaggle/input/sweden-traffic-signs-classification/data.zip\n/kaggle/input/sweden-traffic-signs-classification/train.csv\n/kaggle/input/sweden-traffic-signs-classification/test.csv\n/kaggle/input/sweden-traffic-signs-classification/preprocessed.rar\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Сиды","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch \nimport os\n\nseed=42\nos.environ['PYTHONHASHSEED']=str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:17.088329Z","iopub.execute_input":"2025-09-10T20:17:17.088717Z","iopub.status.idle":"2025-09-10T20:17:21.040391Z","shell.execute_reply.started":"2025-09-10T20:17:17.088698Z","shell.execute_reply":"2025-09-10T20:17:21.039623Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:21.041248Z","iopub.execute_input":"2025-09-10T20:17:21.041577Z","iopub.status.idle":"2025-09-10T20:17:21.103083Z","shell.execute_reply.started":"2025-09-10T20:17:21.041547Z","shell.execute_reply":"2025-09-10T20:17:21.102287Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Импорты","metadata":{}},{"cell_type":"code","source":"import timm\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport tqdm \nfrom tqdm import tqdm \nfrom torchvision.transforms import v2 \nfrom PIL import Image \nfrom sklearn.metrics import f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:21.104590Z","iopub.execute_input":"2025-09-10T20:17:21.104815Z","iopub.status.idle":"2025-09-10T20:17:28.846241Z","shell.execute_reply.started":"2025-09-10T20:17:21.104798Z","shell.execute_reply":"2025-09-10T20:17:28.845601Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# TEST MODE","metadata":{}},{"cell_type":"code","source":"TEST_MODE=False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:28.846962Z","iopub.execute_input":"2025-09-10T20:17:28.847296Z","iopub.status.idle":"2025-09-10T20:17:28.850924Z","shell.execute_reply.started":"2025-09-10T20:17:28.847278Z","shell.execute_reply":"2025-09-10T20:17:28.850242Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/sweden-traffic-signs-classification/train.csv')\ntest=pd.read_csv('/kaggle/input/sweden-traffic-signs-classification/test.csv')\nsample=pd.read_csv('/kaggle/input/sweden-traffic-signs-classification/sample.csv')\n    \nimport zipfile\nfrom pathlib import Path\n\nzip_path = Path('/kaggle/input/sweden-traffic-signs-classification/data.zip')\nout_dir  = Path('/kaggle/working/data')\nout_dir.mkdir(parents=True, exist_ok=True)\n\nwith zipfile.ZipFile(zip_path, 'r') as z:\n    z.extractall(out_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:28.851701Z","iopub.execute_input":"2025-09-10T20:17:28.851875Z","iopub.status.idle":"2025-09-10T20:17:29.258033Z","shell.execute_reply.started":"2025-09-10T20:17:28.851859Z","shell.execute_reply":"2025-09-10T20:17:29.257261Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dir_of_all='/kaggle/working/data/data'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.258922Z","iopub.execute_input":"2025-09-10T20:17:29.259487Z","iopub.status.idle":"2025-09-10T20:17:29.263100Z","shell.execute_reply.started":"2025-09-10T20:17:29.259456Z","shell.execute_reply":"2025-09-10T20:17:29.262417Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"if TEST_MODE:\n    train=train.sample(n=500, random_state=seed).reset_index(drop=True)\nelse:\n    train=train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.263809Z","iopub.execute_input":"2025-09-10T20:17:29.264018Z","iopub.status.idle":"2025-09-10T20:17:29.276358Z","shell.execute_reply.started":"2025-09-10T20:17:29.264000Z","shell.execute_reply":"2025-09-10T20:17:29.275869Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.276928Z","iopub.execute_input":"2025-09-10T20:17:29.277103Z","iopub.status.idle":"2025-09-10T20:17:29.307904Z","shell.execute_reply.started":"2025-09-10T20:17:29.277087Z","shell.execute_reply":"2025-09-10T20:17:29.307344Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"               file_name                label\n0     picture-009375.jpg  PEDESTRIAN_CROSSING\n1     picture-511184.jpg  PEDESTRIAN_CROSSING\n2     picture-616769.jpg  PEDESTRIAN_CROSSING\n3     picture-963518.jpg  PEDESTRIAN_CROSSING\n4     picture-486207.jpg  PEDESTRIAN_CROSSING\n...                  ...                  ...\n2498  picture-565027.jpg      PASS_RIGHT_SIDE\n2499  picture-034604.jpg                OTHER\n2500  picture-258637.jpg        PRIORITY_ROAD\n2501  picture-586334.jpg           NO_PARKING\n2502  picture-492822.jpg  PEDESTRIAN_CROSSING\n\n[2503 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>picture-009375.jpg</td>\n      <td>PEDESTRIAN_CROSSING</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>picture-511184.jpg</td>\n      <td>PEDESTRIAN_CROSSING</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>picture-616769.jpg</td>\n      <td>PEDESTRIAN_CROSSING</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>picture-963518.jpg</td>\n      <td>PEDESTRIAN_CROSSING</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>picture-486207.jpg</td>\n      <td>PEDESTRIAN_CROSSING</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>picture-565027.jpg</td>\n      <td>PASS_RIGHT_SIDE</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>picture-034604.jpg</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>2500</th>\n      <td>picture-258637.jpg</td>\n      <td>PRIORITY_ROAD</td>\n    </tr>\n    <tr>\n      <th>2501</th>\n      <td>picture-586334.jpg</td>\n      <td>NO_PARKING</td>\n    </tr>\n    <tr>\n      <th>2502</th>\n      <td>picture-492822.jpg</td>\n      <td>PEDESTRIAN_CROSSING</td>\n    </tr>\n  </tbody>\n</table>\n<p>2503 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.309917Z","iopub.execute_input":"2025-09-10T20:17:29.310206Z","iopub.status.idle":"2025-09-10T20:17:29.316985Z","shell.execute_reply.started":"2025-09-10T20:17:29.310189Z","shell.execute_reply":"2025-09-10T20:17:29.316401Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"              file_name\n0    picture-176290.jpg\n1    picture-834444.jpg\n2    picture-768882.jpg\n3    picture-212331.jpg\n4    picture-277367.jpg\n..                  ...\n605  picture-641767.jpg\n606  picture-996017.jpg\n607  picture-671413.jpg\n608  picture-043377.jpg\n609  picture-751961.jpg\n\n[610 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>picture-176290.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>picture-834444.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>picture-768882.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>picture-212331.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>picture-277367.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>605</th>\n      <td>picture-641767.jpg</td>\n    </tr>\n    <tr>\n      <th>606</th>\n      <td>picture-996017.jpg</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>picture-671413.jpg</td>\n    </tr>\n    <tr>\n      <th>608</th>\n      <td>picture-043377.jpg</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>picture-751961.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>610 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_data, eval_data=train_test_split(train, test_size=0.2, stratify=train['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.317615Z","iopub.execute_input":"2025-09-10T20:17:29.317803Z","iopub.status.idle":"2025-09-10T20:17:29.334005Z","shell.execute_reply.started":"2025-09-10T20:17:29.317788Z","shell.execute_reply":"2025-09-10T20:17:29.333355Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"## Augmentations","metadata":{}},{"cell_type":"code","source":"trasforms_for_train=v2.Compose([\n    v2.Resize(224),\n    v2.ToTensor(), \n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    \n    ])\n\ntransforms_for_test=v2.Compose([\n    v2.Resize(224),\n    v2.ToTensor(), \n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:19:36.530062Z","iopub.execute_input":"2025-09-10T20:19:36.530343Z","iopub.status.idle":"2025-09-10T20:19:36.535359Z","shell.execute_reply.started":"2025-09-10T20:19:36.530323Z","shell.execute_reply":"2025-09-10T20:19:36.534651Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class SwedenDataset(Dataset):\n    def __init__(self, df, path_to_imgs, transforms, with_labels):\n        self.df=df\n        self.path_to_imgs=path_to_imgs\n        self.trasforms=transforms\n        self.with_labels=with_labels\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        image_name=row['file_name']\n        image_path=os.path.join(self.path_to_imgs, f'{image_name}.jpg')\n        image=Image.open(image_path).convert('RGB')\n        if self.trasforms is not None:\n            image=trasforms(image)\n        else:\n            image=image\n        if self.with_labels:\n            label=torch.tensor(int(row['label']), dtype=torch.long)\n            return {\n                'image': image, \n                'label': label\n            }\n        else:\n            return {\n                'image': image, \n                'image_name': image_name\n            }\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.402151Z","iopub.status.idle":"2025-09-10T20:17:29.402358Z","shell.execute_reply.started":"2025-09-10T20:17:29.402257Z","shell.execute_reply":"2025-09-10T20:17:29.402267Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Создание датасетов ","metadata":{}},{"cell_type":"code","source":"train_dataset=SwedenDataset(train_data, dir_of_all, trasforms_for_train, with_labels=True)\neval_dataset=SwedenDataset(train_data, dir_of_all, trasforms_for_train, with_labels=True)\ntest_dataset=SwedenDataset(train_data, dir_of_all, transforms_for_test, with_labels=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.403496Z","iopub.status.idle":"2025-09-10T20:17:29.403711Z","shell.execute_reply.started":"2025-09-10T20:17:29.403611Z","shell.execute_reply":"2025-09-10T20:17:29.403621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## DataLoaders","metadata":{}},{"cell_type":"code","source":"train_dataloader=DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8)\neval_dataloader=DataLoader(eval_dataset, batch_size=32, shuffle=False, num_workers=8)\ntest_dataloader=DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.405249Z","iopub.status.idle":"2025-09-10T20:17:29.405574Z","shell.execute_reply.started":"2025-09-10T20:17:29.405398Z","shell.execute_reply":"2025-09-10T20:17:29.405413Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Кол-во эпох","metadata":{}},{"cell_type":"code","source":"EPOCHS=10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.407013Z","iopub.status.idle":"2025-09-10T20:17:29.407336Z","shell.execute_reply.started":"2025-09-10T20:17:29.407177Z","shell.execute_reply":"2025-09-10T20:17:29.407192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model=timm.create_model('ecaresnet50d.ra2_in1k', pretrained=True, num_labels=5).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.408220Z","iopub.status.idle":"2025-09-10T20:17:29.408511Z","shell.execute_reply.started":"2025-09-10T20:17:29.408323Z","shell.execute_reply":"2025-09-10T20:17:29.408339Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loss","metadata":{}},{"cell_type":"code","source":"criteration=torch.nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.409681Z","iopub.status.idle":"2025-09-10T20:17:29.409971Z","shell.execute_reply.started":"2025-09-10T20:17:29.409806Z","shell.execute_reply":"2025-09-10T20:17:29.409822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimizer","metadata":{}},{"cell_type":"code","source":"optimizer=torch.optim.SGD(model.params, lr=0.001, momentum=0.9, weight_decay=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.410852Z","iopub.status.idle":"2025-09-10T20:17:29.411163Z","shell.execute_reply.started":"2025-09-10T20:17:29.411007Z","shell.execute_reply":"2025-09-10T20:17:29.411021Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Scheduler","metadata":{}},{"cell_type":"code","source":"scheduler=torch.optim.CosineAnnealingLR(optimizer, T_max=EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.412281Z","iopub.status.idle":"2025-09-10T20:17:29.412602Z","shell.execute_reply.started":"2025-09-10T20:17:29.412428Z","shell.execute_reply":"2025-09-10T20:17:29.412461Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training loop","metadata":{}},{"cell_type":"code","source":"best_f1=0.0\n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    running_loss, running_correct, n= 0.0, 0, 0\n    optimizer.zero_grad()\n    pbar=tqdm(train_dataloader, desc='train', leave=False)\n    for step, batch in enumerate(pbar):\n        X=batch['image'].to(device)\n        y=batch['label'].to(device)\n        optimizer.zero_grad()\n        logits=model(X)\n        loss=criteration(logits, y)\n        loss.backward()\n        optimizer.step()\n        running_loss=loss.item()* X.size(0)\n        preds=logtis.argmax(dim=1)\n        running_correct+=(preds==y).sum().item()\n        n+=X.size(0)\n\n        pbar.set_postfix(loss=running_loss/ max(n, 1), acc=running_correct / max(n, 1))\n    sheduler.step()\n    print(f'train: loss={running_loss/n:.4f}, acc={running_correct/n:.4f}')\n    model.eval()\n    loss_sum, correct, n=0.0,0,0\n    all_probs, all_targets=[], []\n\n    #####################################################################################################################\n    with torch.no_grad():\n        pbar=tqdm.tqdm(eval_dataloader, desc='validation', leave=False)\n    \n        for batch in pbar:\n            X=batch['image'].to(device)\n            y=batch['label'].to(device)\n\n            logits=model(X)\n            loss=criterion(logits, y)\n\n            loss_sum+=loss.item()* X.size(0)\n\n            preds=logits.argmax(dim=1)\n\n            correct+=(preds==y).sum().item()\n\n            n+=X.size(0)\n            probs=torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()\n\n            all_probs.append(probs)\n            all_targets.append(y.detach().cpu().numpy())\n        all_probs = np.concatenate(all_probs) if len(all_probs) else np.array([])\n        all_targets = np.concatenate(all_targets) if len(all_targets) else np.array([])\n        auc = roc_auc_score(all_targets, all_probs)\n        val_loss = loss_sum / n\n        val_acc  = correct / n\n        print(f\"valid: loss={val_loss:.4f}, acc={val_acc:.4f}, AUC={auc:.4f}\")\n\n        if auc > best_auc:\n            best_auc = auc\n            torch.save({\"model\": model.state_dict()}, \"best_resnet50.pt\")\n            print(f\"✓ Saved new best (AUC {best_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.413325Z","iopub.status.idle":"2025-09-10T20:17:29.413645Z","shell.execute_reply.started":"2025-09-10T20:17:29.413482Z","shell.execute_reply":"2025-09-10T20:17:29.413497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"ckpt_path=\"best_resnet50.pt\"\nstate=torch.load(ckpt_path, map_location=device)\nmodel.load_state_dict(state[\"model\"])\n\nmodel.eval()\n\ntest_names, test_probs=[], []\n\nwith torch.no_grad():\n    pbar = tqdm.tqdm(test_dataloader, desc=\"test\", leave=False)\n    for batch in pbar:\n        x = batch[\"image\"].to(device, non_blocking=True)\n        logits = model(x)                       # [B, 2]\n        probs  = torch.softmax(logits, 1)[:, 1] # positive-class probability\n        test_probs.append(probs.cpu().numpy())\n        test_names.extend(batch[\"image_name\"])\ntest_probs = np.concatenate(test_probs, axis=0)\npred_df = pd.DataFrame({\"image_name\": test_names, \"label\": test_probs})\n\n# 3) Align to sample order & save\nsubmission = sample[[\"image_name\"]].merge(pred_df, on=\"image_name\", how=\"left\")\n#submission[\"target\"] = submission[\"target\"].fillna(0.0)  # just in case\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(submission.head(), \"\\nSaved -> submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T20:17:29.414943Z","iopub.status.idle":"2025-09-10T20:17:29.415249Z","shell.execute_reply.started":"2025-09-10T20:17:29.415086Z","shell.execute_reply":"2025-09-10T20:17:29.415099Z"}},"outputs":[],"execution_count":null}]}