{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================\n# Shopee Inference Notebook (OOM-safe, FAISS-optional)\n# =========================\n\nimport os, gc, math, sys\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\nfrom tqdm import tqdm\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n# -----------------\n# Config & paths\n# -----------------\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nDATA_DIR = '/kaggle/input/shopee-product-matching'\nTEST_CSV = os.path.join(DATA_DIR, 'test.csv')\nTEST_IMG_DIR = os.path.join(DATA_DIR, 'test_images')\n\n# === Weights ===\n# Option A: lightweight embedding package (recommended)\nEMBED_PTH = '/kaggle/input/shopee-first-attempt/embedding_extractor.pth'  # <-- проверь путь\nUSE_EMBED_PKG = True\n\n# Option B: full training checkpoint (если нет EMBED_PTH)\nCKPT_PTH = None   # например: '/kaggle/input/your-upload/arcface_resnet50_shopee_ckpt.pth'\n\n# Retrieval params\nIMSIZE = 224\nBATCH_SIZE = 32                # инференс эмбеддингов\nNUM_WORKERS = 2\nK_CAP = 50                     # лимит Shopee\nK_SEARCH = 100                 # ищем шире, потом обрезаем до 50\nMUTUAL = False                 # включи True, если хватает времени/памяти\nFALLBACK_TAU = 0.50            # если best_tau не сохранён\nQBS = 64                      # запросов на чанк в torch-fallback (регулируй при 70k)\n\n# -----------------\n# Data & transforms\n# -----------------\ntest_df = pd.read_csv(TEST_CSV)\n\neval_tfms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(IMSIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n])\n\nclass ShopeeTestDS(Dataset):\n    def __init__(self, df, img_root, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_root = img_root\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_name = str(row['image'])\n        if not img_name.lower().endswith('.jpg'):\n            img_name = f\"{img_name}.jpg\"\n        img_path = os.path.join(self.img_root, img_name)\n        img = Image.open(img_path).convert('RGB')\n        if self.transform: img = self.transform(img)\n        return {'image': img, 'posting_id': row['posting_id']}\n\ntest_ds = ShopeeTestDS(test_df, TEST_IMG_DIR, eval_tfms)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n                         num_workers=NUM_WORKERS, pin_memory=True)\n\n# -----------------\n# Rebuild model (must match training)\n# -----------------\ndef build_embedding_head(in_dim, emb_dim=512):\n    return nn.Sequential(\n        nn.Linear(in_dim, emb_dim, bias=False),\n        nn.BatchNorm1d(emb_dim)\n    )\n\nif USE_EMBED_PKG:\n    pkg = torch.load(EMBED_PTH, map_location=device)\n    backbone_name = pkg['backbone_name']\n    emb_dim = int(pkg['emb_dim'])\n    best_tau = float(pkg.get('best_tau', FALLBACK_TAU))\n\n    backbone = timm.create_model(backbone_name, pretrained=False, num_classes=0).to(device).eval()\n    embedding_head = build_embedding_head(backbone.num_features, emb_dim).to(device).eval()\n\n    backbone.load_state_dict(pkg['state_dict']['backbone'])\n    embedding_head.load_state_dict(pkg['state_dict']['embedding_head'])\n    print(f\"[LOAD] EMBED pkg | backbone={backbone_name}, emb_dim={emb_dim}, tau={best_tau:.2f}\")\nelse:\n    if not CKPT_PTH:\n        raise ValueError(\"Set CKPT_PTH or USE_EMBED_PKG=True\")\n    ckpt = torch.load(CKPT_PTH, map_location=device)\n    backbone_name = ckpt['backbone_name']\n    emb_dim = int(ckpt['emb_dim'])\n    best_tau = float(ckpt.get('best_tau', FALLBACK_TAU))\n\n    backbone = timm.create_model(backbone_name, pretrained=False, num_classes=0).to(device).eval()\n    embedding_head = build_embedding_head(backbone.num_features, emb_dim).to(device).eval()\n\n    backbone.load_state_dict(ckpt['state_dict']['backbone'])\n    embedding_head.load_state_dict(ckpt['state_dict']['embedding_head'])\n    print(f\"[LOAD] FULL ckpt | backbone={backbone_name}, emb_dim={emb_dim}, tau={best_tau:.2f}\")\n\n@torch.no_grad()\ndef embed_loader(loader):\n    embs, ids = [], []\n    for b in tqdm(loader, desc=\"Embed/test\"):\n        x = b['image'].to(device, non_blocking=True)\n        f = backbone(x)\n        e = embedding_head(f)\n        e = F.normalize(e, dim=1)\n        embs.append(e.cpu())\n        ids.extend(b['posting_id'])\n    embs = torch.cat(embs, dim=0).numpy().astype('float32')  # (N, D)\n    norms = np.linalg.norm(embs, axis=1, keepdims=True) + 1e-8\n    embs = (embs / norms).astype('float16')                   # экономим RAM\n    return embs, ids\n\n# -----------------\n# Build embeddings\n# -----------------\ntest_embs, test_ids = embed_loader(test_loader)\nN, D = test_embs.shape\nprint(f\"[INFO] Test embeddings: {test_embs.shape} (stored float16)\")\n\n# -----------------\n# KNN search: FAISS if available, else torch chunked top-K\n# -----------------\nKQ = min(max(K_CAP, K_SEARCH), N)  # сколько соседей ищем до cap\n\ntry:\n    import faiss\n    use_faiss = True\nexcept Exception:\n    use_faiss = False\n    print(\"[INFO] faiss не найден — используем torch chunked top-K\")\n\nif use_faiss:\n    def build_ivf_index(vecs_f16, nlist=None, nprobe=16):\n        D = vecs_f16.shape[1]\n        if nlist is None:\n            nlist = max(4096, int(len(vecs_f16)//16))\n        xb = vecs_f16.astype('float32', copy=False)\n        quantizer = faiss.IndexFlatIP(D)\n        index = faiss.IndexIVFFlat(quantizer, D, nlist, faiss.METRIC_INNER_PRODUCT)\n        ntrain = min(20000, len(vecs_f16))\n        sel = np.random.choice(len(vecs_f16), size=ntrain, replace=False)\n        index.train(vecs_f16[sel].astype('float32', copy=False))\n        index.add(xb)\n        index.nprobe = nprobe\n        return index\n\n    def build_hnsw_index(vecs_f16, M=32, efSearch=64):\n        D = vecs_f16.shape[1]\n        index = faiss.IndexHNSWFlat(D, M)\n        index.hnsw.efSearch = efSearch\n        index.add(vecs_f16.astype('float32', copy=False))\n        return index\n\n    try:\n        index = build_ivf_index(test_embs, nlist=None, nprobe=16)\n        method = \"IVF\"\n    except Exception as e:\n        print(\"[WARN] IVF failed, fallback to HNSW:\", e)\n        try:\n            index = build_hnsw_index(test_embs, M=32, efSearch=64)\n            method = \"HNSW\"\n        except Exception as e2:\n            print(\"[WARN] HNSW failed, fallback to Flat:\", e2)\n            index = faiss.IndexFlatIP(D)\n            index.add(test_embs.astype('float32', copy=False))\n            method = \"FlatIP\"\n    print(f\"[FAISS] Built index: {method}\")\n\n    def faiss_search_batched(index, vecs_f16, K, bs=5000):\n        Nq = vecs_f16.shape[0]\n        I_all = np.empty((Nq, K), dtype='int32')\n        D_all = np.empty((Nq, K), dtype='float32')\n        ptr = 0\n        while ptr < Nq:\n            end = min(ptr + bs, Nq)\n            q = vecs_f16[ptr:end].astype('float32', copy=False)\n            Dq, Iq = index.search(q, K)\n            D_all[ptr:end] = Dq\n            I_all[ptr:end] = Iq\n            ptr = end\n        return D_all, I_all\n\n    sims, idxs = faiss_search_batched(index, test_embs, K=KQ, bs=5000)\n\nelse:\n    torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    db = torch.from_numpy(test_embs.astype('float32', copy=False)).to(torch_device, non_blocking=True)\n    qbs = QBS\n    idxs_list, sims_list = [], []\n    for start in tqdm(range(0, N, qbs), desc=\"TopK (torch-chunk)\"):\n        q = db[start:start+qbs]                  # (qbs, D)\n        sim_chunk = torch.matmul(q, db.T)        # (qbs, N), косинус (L2-норм)\n        topk_vals, topk_idx = torch.topk(sim_chunk, k=KQ, dim=1, largest=True, sorted=True)\n        idxs_list.append(topk_idx.cpu().numpy().astype('int32'))\n        sims_list.append(topk_vals.cpu().numpy().astype('float32'))\n        del sim_chunk, topk_vals, topk_idx\n        if torch_device.type == 'cuda':\n            torch.cuda.empty_cache()\n    idxs = np.vstack(idxs_list)   # (N, KQ)\n    sims = np.vstack(sims_list)   # (N, KQ)\n    del db; gc.collect()\n\n# -----------------\n# Build matches with global tau & optional mutual check\n# -----------------\ntau = float(best_tau)\nprint(f\"[INFO] Using global tau={tau:.2f}, KQ={KQ}, MUTUAL={MUTUAL}\")\n\npreds = []\nfor i in range(N):\n    neigh = idxs[i]\n    simv  = sims[i]\n    cand = []\n    for j, s in zip(neigh, simv):\n        if s < tau:\n            continue\n        if MUTUAL:\n            # взаимность: i должен быть в топ-KQ j\n            if np.any(idxs[j] == i):\n                cand.append(test_ids[j])\n        else:\n            cand.append(test_ids[j])\n    if test_ids[i] not in cand:\n        cand = [test_ids[i]] + cand\n    preds.append(\" \".join(cand[:K_CAP]))\n\nsub = pd.DataFrame({'posting_id': test_ids, 'matches': preds})\nout_path = '/kaggle/working/submission.csv'\nsub.to_csv(out_path, index=False)\nprint(f\"[SAVE] submission -> {out_path}\")\ndisplay(sub.head())\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T14:25:11.621691Z","iopub.execute_input":"2025-09-17T14:25:11.621961Z","iopub.status.idle":"2025-09-17T14:25:12.603601Z","shell.execute_reply.started":"2025-09-17T14:25:11.621942Z","shell.execute_reply":"2025-09-17T14:25:12.602904Z"}},"outputs":[{"name":"stdout","text":"[LOAD] EMBED pkg | backbone=resnet50, emb_dim=512, tau=0.70\n","output_type":"stream"},{"name":"stderr","text":"Embed/test: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] Test embeddings: (3, 512) (stored float16)\n[INFO] faiss не найден — используем torch chunked top-K\n","output_type":"stream"},{"name":"stderr","text":"TopK (torch-chunk): 100%|██████████| 1/1 [00:00<00:00, 351.49it/s]","output_type":"stream"},{"name":"stdout","text":"[INFO] Using global tau=0.70, KQ=3, MUTUAL=False\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"[SAVE] submission -> /kaggle/working/submission.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        posting_id          matches\n0  test_2255846744  test_2255846744\n1  test_3588702337  test_3588702337\n2  test_4015706929  test_4015706929","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>matches</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_2255846744</td>\n      <td>test_2255846744</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_3588702337</td>\n      <td>test_3588702337</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_4015706929</td>\n      <td>test_4015706929</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2}]}