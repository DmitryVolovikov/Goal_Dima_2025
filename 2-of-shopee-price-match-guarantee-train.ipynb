{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":24286,"databundleVersionId":1878097,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Сиды","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport os\nimport random\n    \n\nseed=42\n\nos.environ['PYTHONHASHSEED']=str(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:25:54.533780Z","iopub.execute_input":"2025-10-10T15:25:54.534300Z","iopub.status.idle":"2025-10-10T15:25:58.406034Z","shell.execute_reply.started":"2025-10-10T15:25:54.534277Z","shell.execute_reply":"2025-10-10T15:25:58.405466Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:25:58.407388Z","iopub.execute_input":"2025-10-10T15:25:58.407784Z","iopub.status.idle":"2025-10-10T15:25:58.468629Z","shell.execute_reply.started":"2025-10-10T15:25:58.407765Z","shell.execute_reply":"2025-10-10T15:25:58.467900Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Импорты","metadata":{}},{"cell_type":"code","source":"from torch import nn\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import v2\nimport tqdm \nfrom tqdm import tqdm\nfrom PIL import Image\nimport math\nfrom transformers import AutoTokenizer, AutoModel\nimport joblib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:25:58.469542Z","iopub.execute_input":"2025-10-10T15:25:58.470134Z","iopub.status.idle":"2025-10-10T15:26:09.174436Z","shell.execute_reply.started":"2025-10-10T15:25:58.470114Z","shell.execute_reply":"2025-10-10T15:26:09.173868Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# TEST MODE","metadata":{}},{"cell_type":"code","source":"TEST_MODE=True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.175851Z","iopub.execute_input":"2025-10-10T15:26:09.176277Z","iopub.status.idle":"2025-10-10T15:26:09.179916Z","shell.execute_reply.started":"2025-10-10T15:26:09.176257Z","shell.execute_reply":"2025-10-10T15:26:09.179221Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')\ntest=pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')\nsample=pd.read_csv('/kaggle/input/shopee-product-matching/sample_submission.csv')\n\ntrain_img_dir='/kaggle/input/shopee-product-matching/train_images'\ntest_img_dir='/kaggle/input/shopee-product-matching/test_images'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.180529Z","iopub.execute_input":"2025-10-10T15:26:09.180709Z","iopub.status.idle":"2025-10-10T15:26:09.381790Z","shell.execute_reply.started":"2025-10-10T15:26:09.180693Z","shell.execute_reply":"2025-10-10T15:26:09.381214Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.382595Z","iopub.execute_input":"2025-10-10T15:26:09.382871Z","iopub.status.idle":"2025-10-10T15:26:09.422307Z","shell.execute_reply.started":"2025-10-10T15:26:09.382846Z","shell.execute_reply":"2025-10-10T15:26:09.421679Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"posting_id     34250\nimage          32412\nimage_phash    28735\ntitle          33117\nlabel_group    11014\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"if TEST_MODE:\n    #train=train.sample(n=100, random_state=seed).reset_index(drop=True)\n    train=train[:32000]\nelse:\n    train=train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.423069Z","iopub.execute_input":"2025-10-10T15:26:09.423277Z","iopub.status.idle":"2025-10-10T15:26:09.426980Z","shell.execute_reply.started":"2025-10-10T15:26:09.423260Z","shell.execute_reply":"2025-10-10T15:26:09.426422Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Маппинг","metadata":{}},{"cell_type":"code","source":"label2id = {lg: i for i, lg in enumerate(sorted(train['label_group'].unique()))}\nid2label = {i: lg for lg, i in label2id.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.427672Z","iopub.execute_input":"2025-10-10T15:26:09.427925Z","iopub.status.idle":"2025-10-10T15:26:09.451625Z","shell.execute_reply.started":"2025-10-10T15:26:09.427907Z","shell.execute_reply":"2025-10-10T15:26:09.451082Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train['class_id']=train['label_group'].map(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.452292Z","iopub.execute_input":"2025-10-10T15:26:09.452504Z","iopub.status.idle":"2025-10-10T15:26:09.483437Z","shell.execute_reply.started":"2025-10-10T15:26:09.452488Z","shell.execute_reply":"2025-10-10T15:26:09.482825Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## train_test_split","metadata":{}},{"cell_type":"code","source":"train_data, eval_data=train_test_split(train, test_size=0.2)\n#stratify=train['class_id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.486590Z","iopub.execute_input":"2025-10-10T15:26:09.486967Z","iopub.status.idle":"2025-10-10T15:26:09.498910Z","shell.execute_reply.started":"2025-10-10T15:26:09.486948Z","shell.execute_reply":"2025-10-10T15:26:09.498297Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Датасет","metadata":{}},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    def __init__(self, df, img_root, transform, train):\n        self.df=df\n        self.img_root=img_root\n        self.transform=transform\n        self.train=train\n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        image_path=row['image']\n        image_path_all=os.path.join(self.img_root, f'{image_path}')\n        image=Image.open(image_path_all).convert('RGB')\n\n        if self.transform is not None:\n            image=self.transform(image)\n        else:\n            image=image\n        \n        if self.train:\n            return({\n                'image': image,\n                'label': torch.tensor(row['class_id'], dtype=torch.long),\n                'posting_id': row['posting_id']\n            })\n        else:\n            return({\n                'image': image,\n                'posting_id': row['posting_id']\n            })\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.499630Z","iopub.execute_input":"2025-10-10T15:26:09.499837Z","iopub.status.idle":"2025-10-10T15:26:09.505792Z","shell.execute_reply.started":"2025-10-10T15:26:09.499820Z","shell.execute_reply":"2025-10-10T15:26:09.505110Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# === TEXT dataset / loaders ===\nclass ShopeeTextDataset(Dataset):\n    def __init__(self, df, is_train=True):\n        self.df = df.reset_index(drop=True)\n        self.is_train = is_train\n    def __len__(self): return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        item = {\n            'title': str(row['title']) if not pd.isna(row['title']) else '',\n            'posting_id': row['posting_id'],\n        }\n        if self.is_train:\n            item['label'] = torch.tensor(row['class_id'], dtype=torch.long)\n        return item\n\ntrain_text_ds = ShopeeTextDataset(train_data, is_train=True)\neval_text_ds  = ShopeeTextDataset(eval_data,  is_train=True)\n\ntrain_text_loader = DataLoader(train_text_ds, batch_size=128, shuffle=True,\n                               num_workers=4, pin_memory=True, persistent_workers=True, drop_last=True)\neval_text_loader  = DataLoader(eval_text_ds,  batch_size=256, shuffle=False,\n                               num_workers=4, pin_memory=True, persistent_workers=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.506539Z","iopub.execute_input":"2025-10-10T15:26:09.506846Z","iopub.status.idle":"2025-10-10T15:26:09.529390Z","shell.execute_reply.started":"2025-10-10T15:26:09.506829Z","shell.execute_reply":"2025-10-10T15:26:09.528803Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Аугментации ","metadata":{}},{"cell_type":"code","source":"transforms_train=v2.Compose([\n    v2.Resize((224, 224)), \n    v2.RandomHorizontalFlip(),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntransforms_eval=v2.Compose([\n    v2.Resize((224,224)),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransforms_test=v2.Compose([\n    v2.Resize((224,224)),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.530182Z","iopub.execute_input":"2025-10-10T15:26:09.530496Z","iopub.status.idle":"2025-10-10T15:26:09.537375Z","shell.execute_reply.started":"2025-10-10T15:26:09.530471Z","shell.execute_reply":"2025-10-10T15:26:09.536759Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Создание датасетов","metadata":{}},{"cell_type":"code","source":"train_dataset=ShopeeDataset(train_data, train_img_dir, transform=transforms_train, train=True)\neval_dataset=ShopeeDataset(eval_data,train_img_dir, transform=transforms_eval, train=True)\ntest_dataset=ShopeeDataset(test, test_img_dir, transform=transforms_test, train=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.538076Z","iopub.execute_input":"2025-10-10T15:26:09.538320Z","iopub.status.idle":"2025-10-10T15:26:09.553835Z","shell.execute_reply.started":"2025-10-10T15:26:09.538298Z","shell.execute_reply":"2025-10-10T15:26:09.553077Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Даталоадеры","metadata":{}},{"cell_type":"code","source":"train_dataloader=DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\neval_dataloader=DataLoader(eval_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_dataloader=DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.554669Z","iopub.execute_input":"2025-10-10T15:26:09.554914Z","iopub.status.idle":"2025-10-10T15:26:09.567941Z","shell.execute_reply.started":"2025-10-10T15:26:09.554892Z","shell.execute_reply":"2025-10-10T15:26:09.567176Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Кол-во эпох","metadata":{}},{"cell_type":"code","source":"EPOCHS=5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.568787Z","iopub.execute_input":"2025-10-10T15:26:09.569085Z","iopub.status.idle":"2025-10-10T15:26:09.581151Z","shell.execute_reply.started":"2025-10-10T15:26:09.569059Z","shell.execute_reply":"2025-10-10T15:26:09.580637Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Model for image","metadata":{}},{"cell_type":"code","source":"model=timm.create_model('eca_nfnet_l1', pretrained=True,  num_classes=0).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:09.582081Z","iopub.execute_input":"2025-10-10T15:26:09.582329Z","iopub.status.idle":"2025-10-10T15:26:13.143577Z","shell.execute_reply.started":"2025-10-10T15:26:09.582303Z","shell.execute_reply":"2025-10-10T15:26:13.142918Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c05052a2896e4ee897084fa63514ef7e"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"def build_image_embeddings(loader):\n    embs, ids, labels_opt = [], [], []\n    for b in tqdm(loader, desc=\"Embed/img\"):\n        x = b['image'].to(device, non_blocking=True)\n        e = model(x)\n        e = embedding_head(e)\n        e = nn.functional.normalize(e, dim=1)\n        embs.append(e.cpu())\n        ids.extend(b['posting_id'])\n        if 'label' in b:\n            labels_opt.extend(b['label'].cpu().numpy().tolist())\n    embs = torch.cat(embs, dim=0).numpy().astype('float32')  # (N, 512)\n    embs /= (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-8)\n    return embs, ids, (np.array(labels_opt) if labels_opt else None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:13.144409Z","iopub.execute_input":"2025-10-10T15:26:13.144724Z","iopub.status.idle":"2025-10-10T15:26:13.150306Z","shell.execute_reply.started":"2025-10-10T15:26:13.144702Z","shell.execute_reply":"2025-10-10T15:26:13.149558Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Model for text","metadata":{}},{"cell_type":"code","source":"# === TEXT encoder (XLM-RoBERTa) finetune + ArcFace head ===\nTEXT_MODEL_NAME = 'xlm-roberta-base'\ntext_tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME, use_fast=True)\ntext_model = AutoModel.from_pretrained(TEXT_MODEL_NAME).to(device)  # будет тренироваться\ntext_feat_dim = text_model.config.hidden_size  # 768\n\ntext_embedding_head = nn.Sequential(\n    nn.Linear(text_feat_dim, 512, bias=False),\n    nn.BatchNorm1d(512)\n).to(device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:13.151255Z","iopub.execute_input":"2025-10-10T15:26:13.151628Z","iopub.status.idle":"2025-10-10T15:26:36.976368Z","shell.execute_reply.started":"2025-10-10T15:26:13.151597Z","shell.execute_reply":"2025-10-10T15:26:36.975634Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b4e06330e934093970ea3765eff4254"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0ff1c0182814fbeb6fdeb9082ba7512"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"106ea231390f4201bea8c2a8a44d3862"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4c37881c5c04a499753db03f0cab4c8"}},"metadata":{}},{"name":"stderr","text":"2025-10-10 15:26:20.379906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760109980.567289      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760109980.623493      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bb04f9b566c4253aef84dda558dfc6e"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"@torch.no_grad()\ndef build_text_embeddings_for_df(df, batch_size=256, max_len=64):\n    \"\"\"\n    Возвращает L2-нормированные эмбеддинги заголовков (N, 768) в float16.\n    Порядок совпадает с df.\n    \"\"\"\n    titles = df['title'].fillna('').astype(str).tolist()\n    embs = []\n    for start in tqdm(range(0, len(titles), batch_size), desc=\"Embed/text\"):\n        batch = titles[start:start+batch_size]\n        tok = text_tokenizer(batch, padding=True, truncation=True,\n                             max_length=max_len, return_tensors='pt')\n        tok = {k: v.to(device, non_blocking=True) for k, v in tok.items()}\n        out = text_model(**tok)\n        sent = mean_pooling(out.last_hidden_state, tok['attention_mask'])  # (B, 768)\n        sent = nn.functional.normalize(sent, dim=1)\n        embs.append(sent.cpu())\n    embs = torch.cat(embs, dim=0).numpy().astype('float32')  # (N,768)\n    # safety L2 + экономия RAM\n    norms = np.linalg.norm(embs, axis=1, keepdims=True) + 1e-8\n    return (embs / norms).astype('float16')\n\ndef topk_chunked_cos(embs_f16: np.ndarray, K: int, qbs: int = 128):\n    \"\"\"\n    OOM-safe top-K по косинусу с помощью torch (без FAISS).\n    embs_f16: (N, D) float16, L2-нормированные\n    Возвращает sims, idxs: по (N, K) в float32 / int32\n    \"\"\"\n    N, D = embs_f16.shape\n    device_t = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    db = torch.from_numpy(embs_f16.astype('float32', copy=False)).to(device_t, non_blocking=True)\n\n    K = min(K, N)\n    idxs_list, sims_list = [], []\n    for start in tqdm(range(0, N, qbs), desc=\"TopK (torch-chunk)\"):\n        q = db[start:start+qbs]                 # (qbs, D)\n        S = torch.matmul(q, db.T)               # (qbs, N) — косинус\n        vals, ids = torch.topk(S, k=K, dim=1, largest=True, sorted=True)\n        idxs_list.append(ids.cpu().numpy().astype('int32'))\n        sims_list.append(vals.cpu().numpy().astype('float32'))\n        del S, vals, ids\n        if device_t.type == 'cuda':\n            torch.cuda.empty_cache()\n    idxs = np.vstack(idxs_list)   # (N, K)\n    sims = np.vstack(sims_list)   # (N, K)\n    del db\n    return sims, idxs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:36.977168Z","iopub.execute_input":"2025-10-10T15:26:36.977704Z","iopub.status.idle":"2025-10-10T15:26:36.988902Z","shell.execute_reply.started":"2025-10-10T15:26:36.977683Z","shell.execute_reply":"2025-10-10T15:26:36.988167Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"feat_dim = model.num_features \n\nembedding_head = nn.Sequential(\n    nn.Linear(feat_dim, 512, bias=False),\n    nn.BatchNorm1d(512)\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:36.989733Z","iopub.execute_input":"2025-10-10T15:26:36.990244Z","iopub.status.idle":"2025-10-10T15:26:37.027097Z","shell.execute_reply.started":"2025-10-10T15:26:36.990215Z","shell.execute_reply":"2025-10-10T15:26:37.026271Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# ArcFace голова","metadata":{}},{"cell_type":"code","source":"class ArcFace(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.5, easy_margin=False):\n        super().__init__()\n        \n        self.in_features=in_features\n        self.out_features=out_features\n        self.m=m\n        self.s=s\n        self.easy_margin=easy_margin\n\n        self.weight=nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.cos_m=math.cos(self.m)\n        self.sin_m=math.sin(self.m)\n\n        self.th=math.cos(math.pi-m)\n        self.mm=math.sin(math.pi-m)*m\n        \n        \n\n    def forward(self, embeddings, labels):\n        weights=nn.functional.normalize(self.weight)\n        cosine=nn.functional.linear(embeddings, weights)\n        sine=torch.sqrt(torch.clamp(1.0-cosine**2, min=1e-6))\n\n        phi=cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, labels.view(-1,1), 1.0)\n\n        \n        logits = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        logits = logits * self.s\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:37.027985Z","iopub.execute_input":"2025-10-10T15:26:37.028177Z","iopub.status.idle":"2025-10-10T15:26:37.035545Z","shell.execute_reply.started":"2025-10-10T15:26:37.028162Z","shell.execute_reply":"2025-10-10T15:26:37.034819Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"NUM_CLASSES = train['class_id'].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:37.036331Z","iopub.execute_input":"2025-10-10T15:26:37.036631Z","iopub.status.idle":"2025-10-10T15:26:37.053041Z","shell.execute_reply.started":"2025-10-10T15:26:37.036614Z","shell.execute_reply":"2025-10-10T15:26:37.052406Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"arcface_head=ArcFace(512, NUM_CLASSES, s=30.0, m=0.5).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:37.053812Z","iopub.execute_input":"2025-10-10T15:26:37.054070Z","iopub.status.idle":"2025-10-10T15:26:37.126216Z","shell.execute_reply.started":"2025-10-10T15:26:37.054052Z","shell.execute_reply":"2025-10-10T15:26:37.125574Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"text_arcface_head = ArcFace(512, NUM_CLASSES, s=30.0, m=0.5).to(device)\n\ntext_criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n\n# разные LR для энкодера и головы\nfrom torch.cuda.amp import autocast, GradScaler\ntxt_lr_backbone = 2e-5\ntxt_lr_head     = 1e-3\n\ntext_optimizer = torch.optim.AdamW([\n    {'params': text_model.parameters(), 'lr': txt_lr_backbone, 'weight_decay': 0.01},\n    {'params': text_embedding_head.parameters(), 'lr': txt_lr_head, 'weight_decay': 0.01},\n    {'params': text_arcface_head.parameters(), 'lr': txt_lr_head, 'weight_decay': 0.00},\n])\n\nsteps_per_epoch_txt = len(train_text_loader)\nEPOCHS_TEXT = 2  # можно 1 в TEST_MODE\ntext_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n    text_optimizer, max_lr=[txt_lr_backbone, txt_lr_head, txt_lr_head],\n    epochs=EPOCHS_TEXT, steps_per_epoch=steps_per_epoch_txt,\n    pct_start=0.1, div_factor=10, final_div_factor=1e4\n)\n\nscaler_txt = GradScaler()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:37.126834Z","iopub.execute_input":"2025-10-10T15:26:37.127024Z","iopub.status.idle":"2025-10-10T15:26:37.194839Z","shell.execute_reply.started":"2025-10-10T15:26:37.127008Z","shell.execute_reply":"2025-10-10T15:26:37.193847Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/846053085.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler_txt = GradScaler()\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# Criterion ","metadata":{}},{"cell_type":"code","source":"criterion=torch.nn.CrossEntropyLoss(label_smoothing=0.05)\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:37.195718Z","iopub.execute_input":"2025-10-10T15:26:37.196021Z","iopub.status.idle":"2025-10-10T15:26:37.199884Z","shell.execute_reply.started":"2025-10-10T15:26:37.195995Z","shell.execute_reply":"2025-10-10T15:26:37.199168Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Optimizer","metadata":{}},{"cell_type":"code","source":"optimizer=torch.optim.AdamW(list(model.parameters()) +\n    list(embedding_head.parameters()) +\n    list(arcface_head.parameters()), lr=3e-4, weight_decay=0.05)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:37.200700Z","iopub.execute_input":"2025-10-10T15:26:37.200974Z","iopub.status.idle":"2025-10-10T15:26:37.217569Z","shell.execute_reply.started":"2025-10-10T15:26:37.200950Z","shell.execute_reply":"2025-10-10T15:26:37.216739Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# Scheduler","metadata":{}},{"cell_type":"code","source":"scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:37.220928Z","iopub.execute_input":"2025-10-10T15:26:37.221161Z","iopub.status.idle":"2025-10-10T15:26:37.234084Z","shell.execute_reply.started":"2025-10-10T15:26:37.221144Z","shell.execute_reply":"2025-10-10T15:26:37.233366Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"#  Training loop","metadata":{}},{"cell_type":"code","source":"for epoch in range(1, EPOCHS+1):\n    model.train()\n    embedding_head.train()\n    arcface_head.train()\n    running_loss, num_correct, n=0.0,0,0\n    pbar=tqdm(train_dataloader, desc='train', leave=False)\n    for step, batch in enumerate(pbar):\n        optimizer.zero_grad()\n        X=batch['image'].to(device)\n        y=batch['label'].to(device)\n    \n        feats=model(X)\n        embeddings = embedding_head(feats)\n        embeddings=nn.functional.normalize(embeddings, dim=1)\n        logits=arcface_head(embeddings, y)\n        loss=criterion(logits, y)\n        loss.backward()\n        \n        \n        optimizer.step()\n        running_loss+=loss.item()*X.size(0)\n        pbar.set_postfix(loss=running_loss/((step+1)*X.size(0)))\n\n    scheduler.step()\n# ===== Validation: build embeddings -> cosine-kNN -> global tau -> F1 =====\nimport numpy as np\ndef tokenize_titles(titles, max_len=64):\n    return text_tokenizer(titles, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n\ndef mean_pooling(last_hidden_state, attention_mask):\n    mask = attention_mask.unsqueeze(-1).float()\n    summed = (last_hidden_state * mask).sum(dim=1)\n    denom = mask.sum(dim=1).clamp(min=1e-6)\n    return summed / denom\n\nfor epoch in range(1, EPOCHS_TEXT+1):\n    text_model.train(); text_embedding_head.train(); text_arcface_head.train()\n    pbar = tqdm(train_text_loader, desc=f'train/text e{epoch}', leave=False)\n    running = 0.0; nseen = 0\n    for batch in pbar:\n        titles = batch['title']\n        y = batch['label'].to(device, non_blocking=True)\n\n        tok = tokenize_titles(titles)\n        tok = {k: v.to(device, non_blocking=True) for k, v in tok.items()}\n\n        text_optimizer.zero_grad(set_to_none=True)\n        with autocast():\n            out = text_model(**tok)  # last_hidden_state\n            sent = mean_pooling(out.last_hidden_state, tok['attention_mask'])     # (B, 768)\n            emb  = text_embedding_head(sent)                                      # (B, 512)\n            emb  = nn.functional.normalize(emb, dim=1)\n            logits = text_arcface_head(emb, y)\n            loss = text_criterion(logits, y)\n\n        scaler_txt.scale(loss).backward()\n        scaler_txt.step(text_optimizer)\n        scaler_txt.update()\n        text_scheduler.step()\n\n        bs = y.size(0)\n        running += loss.item() * bs\n        nseen += bs\n        pbar.set_postfix(loss=running / max(1, nseen))\n\ntext_model.eval(); text_embedding_head.eval(); text_arcface_head.eval()\n@torch.no_grad()\ndef build_text_embeddings_for_df_ft(df, batch_size=256, max_len=64):\n    titles = df['title'].fillna('').astype(str).tolist()\n    embs = []\n    for i in tqdm(range(0, len(titles), batch_size), desc=\"Embed/text(ft)\"):\n        batch = titles[i:i+batch_size]\n        tok = tokenize_titles(batch, max_len=max_len)\n        tok = {k: v.to(device, non_blocking=True) for k, v in tok.items()}\n        out = text_model(**tok)\n        sent = mean_pooling(out.last_hidden_state, tok['attention_mask'])  # (B,768)\n        e = text_embedding_head(sent)                                      # (B,512)\n        e = nn.functional.normalize(e, dim=1)\n        embs.append(e.cpu())\n    embs = torch.cat(embs, dim=0).numpy().astype('float32')\n    embs /= (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-8)\n    return embs.astype('float16')  # (N,512) float16\n\nmodel.eval(); embedding_head.eval(); arcface_head.eval()\n\n@torch.no_grad()\ndef build_val_embeddings(loader):\n    embs, ids, labels = [], [], []\n    for b in tqdm(loader, desc=\"Embed/val\"):\n        x = b['image'].to(device, non_blocking=True)\n        e = model(x)                         # (B, feat_dim)\n        e = embedding_head(e)                # (B, 512)\n        e = nn.functional.normalize(e, dim=1)\n        embs.append(e.cpu())\n        ids.extend(b['posting_id'])\n        # важно: eval_dataset должен возвращать label (class_id)\n        labels.extend(b['label'].cpu().numpy().tolist())\n    embs = torch.cat(embs, dim=0).numpy()    # (N, 512)\n    labels = np.array(labels)\n    return embs, ids, labels\n\ndef build_preds(embs, ids, K=50, tau=0.50, mutual=True, cap=50):\n    \"\"\"\n    embs: (N, D) L2-нормированные векторы\n    ids:  список posting_id в том же порядке\n    Возвращает dict: posting_id -> set(predicted_ids) (включая self), с ограничением cap.\n    \"\"\"\n    # Косинусная матрица: для L2-нормированных это просто e @ e^T\n    S = embs @ embs.T        # (N, N)\n    N = S.shape[0]\n\n    # Предвычислим top-K индексы для каждого i (быстро и экономно)\n    topk_idx = np.argsort(-S, axis=1)[:, :K]  # индексы соседей по убыванию сходства\n\n    preds = {}\n    for i in range(N):\n        cand = []\n        for j in topk_idx[i]:\n            if S[i, j] >= tau:\n                if not mutual or i in topk_idx[j]:   # взаимность (mutual-kNN) уменьшает false-merge\n                    cand.append(ids[j])\n        # обязательно self-match\n        if ids[i] not in cand:\n            cand = [ids[i]] + cand\n        # кап по условию соревна\n        preds[ids[i]] = set(cand[:cap])\n    return preds\n\ndef f1_matches(ids, labels, preds):\n    \"\"\"\n    Средний F1 по каждому посту:\n      - истина: все posting_id той же class_id\n      - предсказание: preds[posting_id]\n    \"\"\"\n    # сгруппируем истину: class_id -> set(posting_id)\n    truth = {}\n    for pid, g in zip(ids, labels):\n        truth.setdefault(g, set()).add(pid)\n\n    f1s = []\n    for pid, g in zip(ids, labels):\n        T = truth[g]\n        P = preds[pid]\n        inter = len(T & P)\n        denom = len(T) + len(P)\n        f1s.append( 2*inter/denom if denom > 0 else 0.0 )\n    return float(np.mean(f1s))\n\n# 1) эмбеддинги на валидации\nval_embs, val_ids, val_labels = build_val_embeddings(eval_dataloader)\n# === TEXT embeddings на валидации (в порядке eval_dataset.df) ===\nval_text_embs = build_text_embeddings_for_df_ft(eval_dataset.df, batch_size=256, max_len=64)  # (Nv,768) float16\n\n# === top-K для image и text (шире cap, потом обрежем) ===\nKQ = 100  # ширина кандидатов перед обрезкой до 50\nsims_img, idxs_img = topk_chunked_cos(val_embs.astype('float16'), K=KQ, qbs=128)     # (Nv,KQ)\nsims_txt, idxs_txt = topk_chunked_cos(val_text_embs,              K=KQ, qbs=256)     # (Nv,KQ)\n\n# === REPLACE this function with the one below ===\ndef build_preds_fused_mutual(ids, idxs_img, sims_img, idxs_txt, sims_txt,\n                             alpha=0.7, tau=0.50, K_cap=50):\n    \"\"\"\n    ids: список posting_id длины N\n    idxs_*: (N, KQ) индексы кандидатов\n    sims_*: (N, KQ) косинусы [-1,1]\n    alpha: вес image (0..1), (1-alpha) — вес text\n    tau: порог на fused-скор (после приведения в [0,1])\n    K_cap: ограничение размера группы\n    \"\"\"\n    N = len(ids)\n    # объединённые кандидаты для каждого i\n    cand_sets = [ set(idxs_img[i]).union(set(idxs_txt[i])) for i in range(N) ]\n\n    out = {}\n    for i in range(N):\n        # карты скорингов для быстрого доступа\n        map_img = {int(j): float(s) for j, s in zip(idxs_img[i], sims_img[i])}\n        map_txt = {int(j): float(s) for j, s in zip(idxs_txt[i], sims_txt[i])}\n\n        fused = []\n        for j in cand_sets[i]:\n            # приводим косинусы в [0,1] и смешиваем\n            si = (map_img.get(j, -1.0) + 1.0) / 2.0\n            st = (map_txt.get(j, -1.0) + 1.0) / 2.0\n            s  = alpha * si + (1.0 - alpha) * st\n            # взаимность на объединённых кандидатах\n            if s >= tau and (i in cand_sets[j]):\n                fused.append((j, s))\n\n        fused.sort(key=lambda x: -x[1])\n        keep = [ids[j] for j, _ in fused]\n        if ids[i] not in keep:\n            keep = [ids[i]] + keep\n        out[ids[i]] = set(keep[:K_cap])\n    return out\n\n\n# Поиск (alpha, tau) по сетке\n# --- grid search for fusion params ---\nalphas = np.linspace(0.4, 0.9, 6)     # 0.40..0.90\ntaus   = np.linspace(0.20, 0.80, 31)  # 0.20..0.80\n\nbest_fusion = {'f1': -1.0, 'alpha': None, 'tau': None}\nfor a in alphas:\n    for t in taus:\n        preds = build_preds_fused_mutual(\n            val_ids, idxs_img, sims_img, idxs_txt, sims_txt,\n            alpha=float(a), tau=float(t), K_cap=50\n        )\n        f1 = f1_matches(val_ids, val_labels, preds)\n        if f1 > best_fusion['f1']:\n            best_fusion = {'f1': float(f1), 'alpha': float(a), 'tau': float(t)}\n\nprint(f\"[VAL FUSION] Best F1={best_fusion['f1']:.4f} at alpha={best_fusion['alpha']:.2f}, tau={best_fusion['tau']:.2f}\")\n\n\n# (на всякий случай) L2-норм ещё раз, если вызывалась неявно\npreds_best_fused = build_preds_fused_mutual(\n    val_ids, idxs_img, sims_img, idxs_txt, sims_txt,\n    alpha=best_fusion['alpha'], tau=best_fusion['tau'], K_cap=50\n)\navg_group_size = np.mean([len(v) for v in preds_best_fused.values()])\nprint(f\"[VAL FUSION] Avg predicted group size: {avg_group_size:.2f}\")\n\n\n\n# (необязательно) Быстрый sanity-check: средний размер предсказанных групп\n# === Save checkpoint(s) ===\nSAVE_DIR = '/kaggle/working'\nos.makedirs(SAVE_DIR, exist_ok=True)\n\nckpt = {\n    'backbone_name': 'eca_nfnet_l1',          # FIX: было 'resnet50'\n    'feat_dim': model.num_features,\n    'emb_dim': 512,\n    'num_classes': NUM_CLASSES,\n    'arcface_cfg': {'s': 30.0, 'm': 0.5, 'easy_margin': False},\n    'state_dict': {\n        'backbone': model.state_dict(),\n        'embedding_head': embedding_head.state_dict(),\n        'arcface_head': arcface_head.state_dict(),\n    },\n    'label2id': label2id,\n    'fusion_alpha': float(best_fusion['alpha']),\n    'fusion_tau': float(best_fusion['tau']),\n    'val_f1_fused': float(best_fusion['f1']),\n    'epoch': EPOCHS,\n}\n\ntorch.save(ckpt, os.path.join(SAVE_DIR, 'arcface_eca_nfnet_l1_shopee_ckpt.pth'))\nprint('[SAVE] Full checkpoint ->', os.path.join(SAVE_DIR, 'arcface_eca_nfnet_l1_shopee_ckpt.pth'))\n\n# Лёгкий пакет для инференса (нужны веса и параметры фьюжна)\nembed_pkg = {\n    'backbone_name': 'eca_nfnet_l1',\n    'feat_dim': model.num_features,\n    'emb_dim': 512,\n    'state_dict': {\n        'backbone': model.state_dict(),\n        'embedding_head': embedding_head.state_dict(),\n    },\n    'fusion_alpha': float(best_fusion['alpha']),\n    'fusion_tau': float(best_fusion['tau']),\n}\ntorch.save(embed_pkg, os.path.join(SAVE_DIR, 'embedding_extractor.pth'))\nprint('[SAVE] Embedding extractor ->', os.path.join(SAVE_DIR, 'embedding_extractor.pth'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:26:37.235007Z","iopub.execute_input":"2025-10-10T15:26:37.235297Z","iopub.status.idle":"2025-10-10T15:32:47.996609Z","shell.execute_reply.started":"2025-10-10T15:26:37.235272Z","shell.execute_reply":"2025-10-10T15:32:47.995640Z"}},"outputs":[{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3844142818.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marcface_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- SAVE full ckpt (image + text) ---\nckpt = {\n    'backbone_name_img': 'eca_nfnet_l1',\n    'backbone_name_txt': TEXT_MODEL_NAME,\n    'img_feat_dim': model.num_features,\n    'txt_feat_dim': text_feat_dim,  # 768\n    'emb_dim': 512,\n    'num_classes': NUM_CLASSES,\n    'arcface_cfg': {'s': 30.0, 'm': 0.5, 'easy_margin': False},\n    'state_dict': {\n        'img_backbone': model.state_dict(),\n        'img_embed_head': embedding_head.state_dict(),\n        'img_arcface_head': arcface_head.state_dict(),\n        'txt_backbone': text_model.state_dict(),\n        'txt_embed_head': text_embedding_head.state_dict(),\n        'txt_arcface_head': text_arcface_head.state_dict(),\n    },\n    'label2id': label2id,\n    'fusion_alpha': float(best_fusion['alpha']),\n    'fusion_tau': float(best_fusion['tau']),\n    'val_f1_fused': float(best_fusion['f1']),\n    'epoch_img': EPOCHS,\n    'epoch_txt': EPOCHS_TEXT,\n}\ntorch.save(ckpt, os.path.join(SAVE_DIR, 'imgtxt_arcface_shopee_ckpt.pth'))\n\n# --- SAVE light embed extractor (для теста) ---\nembed_pkg = {\n    'backbone_name_img': 'eca_nfnet_l1',\n    'backbone_name_txt': TEXT_MODEL_NAME,\n    'emb_dim': 512,\n    'state_dict': {\n        'img_backbone': model.state_dict(),\n        'img_embed_head': embedding_head.state_dict(),\n        'txt_backbone': text_model.state_dict(),\n        'txt_embed_head': text_embedding_head.state_dict(),\n    },\n    'fusion_alpha': float(best_fusion['alpha']),\n    'fusion_tau': float(best_fusion['tau']),\n}\ntorch.save(embed_pkg, os.path.join(SAVE_DIR, 'embedding_extractor_mix.pth'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:32:47.997350Z","iopub.status.idle":"2025-10-10T15:32:47.997675Z","shell.execute_reply.started":"2025-10-10T15:32:47.997543Z","shell.execute_reply":"2025-10-10T15:32:47.997557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TOKENIZER_DIR = os.path.join(SAVE_DIR, \"xlmr_tokenizer\")\nos.makedirs(TOKENIZER_DIR, exist_ok=True)\n\ntext_tokenizer.save_pretrained(TOKENIZER_DIR)   # tokenizer.json, spm.model и т.п.\ntext_model.config.save_pretrained(TOKENIZER_DIR)  # config.json\nprint(\"Saved tokenizer+config ->\", TOKENIZER_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:32:48.782043Z","iopub.execute_input":"2025-10-10T15:32:48.782591Z","iopub.status.idle":"2025-10-10T15:32:48.804812Z","shell.execute_reply.started":"2025-10-10T15:32:48.782563Z","shell.execute_reply":"2025-10-10T15:32:48.803904Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/4029939670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTOKENIZER_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"xlmr_tokenizer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOKENIZER_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOKENIZER_DIR\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# tokenizer.json, spm.model и т.п.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOKENIZER_DIR\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# config.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'SAVE_DIR' is not defined"],"ename":"NameError","evalue":"name 'SAVE_DIR' is not defined","output_type":"error"}],"execution_count":30},{"cell_type":"code","source":"SAVE_DIR = '/kaggle/working'\nos.makedirs(SAVE_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:32:52.474275Z","iopub.execute_input":"2025-10-10T15:32:52.474605Z","iopub.status.idle":"2025-10-10T15:32:52.478182Z","shell.execute_reply.started":"2025-10-10T15:32:52.474581Z","shell.execute_reply":"2025-10-10T15:32:52.477598Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"TOKENIZER_DIR = os.path.join(SAVE_DIR, \"xlmr_tokenizer\")\nos.makedirs(TOKENIZER_DIR, exist_ok=True)\n\ntext_tokenizer.save_pretrained(TOKENIZER_DIR)   # tokenizer.json, spm.model и т.п.\ntext_model.config.save_pretrained(TOKENIZER_DIR)  # config.json\nprint(\"Saved tokenizer+config ->\", TOKENIZER_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:32:54.151650Z","iopub.execute_input":"2025-10-10T15:32:54.151917Z","iopub.status.idle":"2025-10-10T15:32:54.217540Z","shell.execute_reply.started":"2025-10-10T15:32:54.151896Z","shell.execute_reply":"2025-10-10T15:32:54.216925Z"}},"outputs":[{"name":"stdout","text":"Saved tokenizer+config -> /kaggle/working/xlmr_tokenizer\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"#need inference notebook","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T15:32:48.003054Z","iopub.status.idle":"2025-10-10T15:32:48.003255Z","shell.execute_reply.started":"2025-10-10T15:32:48.003158Z","shell.execute_reply":"2025-10-10T15:32:48.003166Z"}},"outputs":[],"execution_count":null}]}