{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13151379,"sourceType":"datasetVersion","datasetId":8331661}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Хочу попробовать потюнить ру клип сначала просто голову на кросс энтропию\nпотом потюнить немного сам ру клип \n\nВсе плохо надо катбуст на ординальных таргетах \n\nБрать наверное сначала не ру клип ввиду того что не запущу адекватно \n\n\nи будет ГООООООЛ ","metadata":{}},{"cell_type":"markdown","source":"# Pip install которые почему то работают с ру клипом \n\nСамая лучшая модель кста ","metadata":{}},{"cell_type":"code","source":"!pip install ruclip==0.0.2\n!pip install scikit-learn\n!pip install torch torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T16:25:58.769033Z","iopub.execute_input":"2025-10-09T16:25:58.769810Z","iopub.status.idle":"2025-10-09T16:27:41.598359Z","shell.execute_reply.started":"2025-10-09T16:25:58.769784Z","shell.execute_reply":"2025-10-09T16:27:41.597635Z"}},"outputs":[{"name":"stdout","text":"Collecting ruclip==0.0.2\n  Downloading ruclip-0.0.2-py3-none-any.whl.metadata (28 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from ruclip==0.0.2) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from ruclip==0.0.2) (0.21.0+cu124)\nCollecting huggingface-hub==0.2.1 (from ruclip==0.0.2)\n  Downloading huggingface_hub-0.2.1-py3-none-any.whl.metadata (6.3 kB)\nCollecting youtokentome~=1.0.6 (from ruclip==0.0.2)\n  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting more-itertools==8.12.0 (from ruclip==0.0.2)\n  Downloading more_itertools-8.12.0-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (4.67.1)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (4.14.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (25.0)\nRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.11/dist-packages (from youtokentome~=1.0.6->ruclip==0.0.2) (8.2.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->ruclip==0.0.2) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip==0.0.2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->ruclip==0.0.2) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->ruclip==0.0.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->ruclip==0.0.2)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->ruclip==0.0.2)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->ruclip==0.0.2)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->ruclip==0.0.2)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->ruclip==0.0.2)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->ruclip==0.0.2)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->ruclip==0.0.2)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->ruclip==0.0.2)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip==0.0.2) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip==0.0.2) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip==0.0.2) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->ruclip==0.0.2)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip==0.0.2) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip==0.0.2) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->ruclip==0.0.2) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->ruclip==0.0.2) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->ruclip==0.0.2) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->ruclip==0.0.2) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip==0.0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip==0.0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip==0.0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip==0.0.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip==0.0.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip==0.0.2) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->ruclip==0.0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->ruclip==0.0.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->ruclip==0.0.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->ruclip==0.0.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->ruclip==0.0.2) (2024.2.0)\nDownloading ruclip-0.0.2-py3-none-any.whl (14 kB)\nDownloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: youtokentome\n  Building wheel for youtokentome (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp311-cp311-linux_x86_64.whl size=1968569 sha256=822a9f26f6c451ca9fd4488feb2e95d1207b253c06bc038a7893022a862177b1\n  Stored in directory: /root/.cache/pip/wheels/1c/7c/e2/f8069c8e5ebb9f9a26963e906ffcae4977c6322af5ecaf25fc\nSuccessfully built youtokentome\nInstalling collected packages: youtokentome, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, more-itertools, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, nvidia-cusolver-cu12, ruclip\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: more-itertools\n    Found existing installation: more-itertools 10.7.0\n    Uninstalling more-itertools-10.7.0:\n      Successfully uninstalled more-itertools-10.7.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ndatasets 3.6.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.2.1 which is incompatible.\nsentence-transformers 4.1.0 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.2.1 which is incompatible.\ntokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 0.2.1 which is incompatible.\ndiffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.2.1 which is incompatible.\ngradio-client 1.10.1 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.2.1 which is incompatible.\naccelerate 1.8.1 requires huggingface_hub>=0.21.0, but you have huggingface-hub 0.2.1 which is incompatible.\ntransformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 0.2.1 which is incompatible.\ngradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.2.1 which is incompatible.\npeft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.2.1 more-itertools-8.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ruclip-0.0.2 youtokentome-1.0.6\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers\n!pip install torch torchvision\n!pip install scikit-learn\n!pip install ruclip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T16:27:41.600344Z","iopub.execute_input":"2025-10-09T16:27:41.600605Z","iopub.status.idle":"2025-10-09T16:27:57.694454Z","shell.execute_reply.started":"2025-10-09T16:27:41.600581Z","shell.execute_reply":"2025-10-09T16:27:57.693684Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nCollecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.2.1\n    Uninstalling huggingface-hub-0.2.1:\n      Successfully uninstalled huggingface-hub-0.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nruclip 0.0.2 requires huggingface-hub==0.2.1, but you have huggingface-hub 0.35.3 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.35.3\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: ruclip in /usr/local/lib/python3.11/dist-packages (0.0.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from ruclip) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from ruclip) (0.21.0+cu124)\nCollecting huggingface-hub==0.2.1 (from ruclip)\n  Using cached huggingface_hub-0.2.1-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: youtokentome~=1.0.6 in /usr/local/lib/python3.11/dist-packages (from ruclip) (1.0.6)\nRequirement already satisfied: more-itertools==8.12.0 in /usr/local/lib/python3.11/dist-packages (from ruclip) (8.12.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip) (4.67.1)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip) (4.14.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.2.1->ruclip) (25.0)\nRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.11/dist-packages (from youtokentome~=1.0.6->ruclip) (8.2.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->ruclip) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->ruclip) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->ruclip) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->ruclip) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->ruclip) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->ruclip) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.2.1->ruclip) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.2.1->ruclip) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.2.1->ruclip) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.2.1->ruclip) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->ruclip) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->ruclip) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->ruclip) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->ruclip) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->ruclip) (2024.2.0)\nUsing cached huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\nInstalling collected packages: huggingface-hub\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.35.3\n    Uninstalling huggingface-hub-0.35.3:\n      Successfully uninstalled huggingface-hub-0.35.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ndatasets 3.6.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.2.1 which is incompatible.\nsentence-transformers 4.1.0 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.2.1 which is incompatible.\ntokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 0.2.1 which is incompatible.\ndiffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.2.1 which is incompatible.\ngradio-client 1.10.1 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.2.1 which is incompatible.\naccelerate 1.8.1 requires huggingface_hub>=0.21.0, but you have huggingface-hub 0.2.1 which is incompatible.\ntransformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 0.2.1 which is incompatible.\ngradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.2.1 which is incompatible.\npeft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.2.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install huggingface-hub==0.23.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T16:27:57.695423Z","iopub.execute_input":"2025-10-09T16:27:57.695663Z","iopub.status.idle":"2025-10-09T16:28:02.239043Z","shell.execute_reply.started":"2025-10-09T16:27:57.695640Z","shell.execute_reply":"2025-10-09T16:28:02.238160Z"}},"outputs":[{"name":"stdout","text":"Collecting huggingface-hub==0.23.3\n  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (4.14.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.23.3) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.23.3) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.23.3) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.23.3) (2025.6.15)\nDownloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.2.1\n    Uninstalling huggingface-hub-0.2.1:\n      Successfully uninstalled huggingface-hub-0.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nruclip 0.0.2 requires huggingface-hub==0.2.1, but you have huggingface-hub 0.23.3 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ndatasets 3.6.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.3 which is incompatible.\ndiffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.3 which is incompatible.\ntransformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 0.23.3 which is incompatible.\ngradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.3 which is incompatible.\npeft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.23.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ================== Imports / Device ==================\n# ================== Imports / Device ==================\n# ================== Imports / Device ==================\n# ================== Imports / Device ==================\nimport os, io, re, subprocess, sys\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm as tqdm_notebook\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nif device == 'cuda':\n    try: torch.cuda.set_per_process_memory_fraction(0.65)\n    except: pass\n\n# ================== Data ==================\ntrain = pd.read_csv('/kaggle/input/image-text-matching-vseros-2024/train_df.tsv', sep='\\t')\ntest  = pd.read_csv('/kaggle/input/image-text-matching-vseros-2024/test_df.tsv',  sep='\\t')\n\ntrain_zip_path = '/kaggle/input/image-text-matching-vseros-2024/train.bin'\ntest_zip_path  = '/kaggle/input/image-text-matching-vseros-2024/test-001.bin'\n\n# ================== Text preprocessing (как на скрине) ==================\nfrom_mark_to_idx = {'Идеально': 2, 'Удовлетворительно': 1, 'Плохо': 0}\nidx_to_mark = {v:k for k,v in from_mark_to_idx.items()}\nif 'mark' in train.columns and train['mark'].dtype == object:\n    train['mark'] = train['mark'].map(from_mark_to_idx)\n\nregex_pat = re.compile(r\"[^ A-Яа-яЁёA-Za-z0-9]\", flags=re.UNICODE)\ndef clean_text(s: str) -> str:\n    s = re.sub(regex_pat, ' ', str(s))\n    s = \" \".join(s.split())\n    return s.lower()\n\n#train['text'] = train['text'].map(clean_text)\n#test['text']  = test['text'].map(clean_text)\ntrain['text'] = train['text'].fillna('').astype(str)\ntest['text']  = test['text'].fillna('').astype(str)\ndef norm_name(x: str) -> str:\n    return str(x).lstrip('/').replace('\\\\','/')\ntrain['filename'] = train['filename'].map(norm_name)\ntest['filename']  = test['filename'].map(norm_name)\n\n# ================== Train/Val split ==================\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(\n    train, test_size=0.33, random_state=42,\n    stratify=train['mark'] if 'mark' in train else None\n)\ntrain_df = train_df.reset_index(drop=True)\nval_df   = val_df.reset_index(drop=True)\n\n# ================== RuCLIP loader (как на скрине) ==================\nimport ruclip\n\nclass Params:\n    device = device\n    pretrained = 'ruclip-vit-base-patch32-224'\n\ndef get_ruclip_model(args):\n    model, processor = ruclip.load(args.pretrained, device=args.device)\n    model.to(args.device)\n    return model, processor\n\nargs = Params()\nmodel, processor = get_ruclip_model(args)\nmodel.eval()\n#args = Params()\n#model, tokenizer, preprocessor = get_ruclip_model(args)\n\n# ================== Zip streaming Dataset (в духе твоего примера) ==================\nclass ZipImageTextDS(Dataset):\n    def __init__(self, df, zip_path, image_col=\"filename\", text_col=\"text\", label_col=None):\n        self.df = df.reset_index(drop=True)\n        self.zip_path = zip_path\n        self.image_col, self.text_col, self.label_col = image_col, text_col, label_col\n\n        try:\n            out = subprocess.check_output(['unzip', '-Z1', zip_path], stderr=subprocess.DEVNULL)\n            members = out.decode('utf-8', errors='ignore').splitlines()\n        except Exception:\n            import zipfile\n            with zipfile.ZipFile(zip_path) as z:\n                members = [i.filename for i in z.infolist() if not i.is_dir()]\n\n        self._members = [m.lstrip('/').replace('\\\\','/') for m in members if not m.endswith('/')]\n        self._member_set = set(self._members)\n\n        from collections import defaultdict\n        self._by_base = defaultdict(list)\n        for m in self._members:\n            self._by_base[os.path.basename(m)].append(m)\n\n    def _resolve(self, name: str) -> str:\n        name = name.lstrip('/').replace('\\\\','/')\n        if name in self._member_set:\n            return name\n        cand = 'train/' + name if not name.startswith('train/') else name[len('train/'):]\n        if cand in self._member_set:\n            return cand\n        b = os.path.basename(name)\n        hits = self._by_base.get(b, [])\n        if len(hits) == 1:\n            return hits[0]\n        raise FileNotFoundError(f\"Ambiguous or missing: {name} in {self.zip_path} (candidates={len(hits)})\")\n\n    # >>> ЭТОТ МЕТОД НУЖЕН DataLoader\n    def __len__(self):\n        return len(self.df)\n\n    # >>> И ЭТО ТОЖЕ\n    def _read_image_bytes(self, member: str):\n        # 1) пробуем системный unzip (обычно устойчив к overlapped entries)\n        try:\n            return subprocess.check_output(\n                ['unzip', '-p', self.zip_path, member],\n                stderr=subprocess.DEVNULL\n            )\n        except Exception:\n            pass\n        # 2) python zipfile — может падать на CRC; ловим и возвращаем None\n        try:\n            import zipfile\n            with zipfile.ZipFile(self.zip_path, 'r') as z:\n                with z.open(member, 'r') as f:\n                    return f.read()\n        except Exception:\n            return None  # <<< ключевой фоллбек\n\n    def __getitem__(self, i):\n        row = self.df.iloc[i]\n        member = self._resolve(str(row[self.image_col]))\n        raw = self._read_image_bytes(member)\n\n        if not raw:\n            img = Image.new('RGB', (256, 256), 'white')  # пропускаем битую запись\n        else:\n            try:\n                img = Image.open(io.BytesIO(raw))\n                img.load()\n                img = img.convert('RGB')\n            except Exception:\n                img = Image.new('RGB', (256, 256), 'white')\n\n        item = {\"image\": img, \"text\": str(row[self.text_col])}\n        if self.label_col is not None:\n            item[\"label\"] = int(row[self.label_col])\n        return item\n\ndef keep_resolvable(df, zip_path, image_col=\"filename\"):\n    # оставим только те, что точно находятся (или уникальны по basename)\n    try:\n        out = subprocess.check_output(['unzip', '-Z1', zip_path], stderr=subprocess.DEVNULL)\n        members = out.decode('utf-8', errors='ignore').splitlines()\n    except Exception:\n        import zipfile\n        with zipfile.ZipFile(zip_path) as z:\n            members = [i.filename for i in z.infolist() if not i.is_dir()]\n    members = [m.lstrip('/').replace('\\\\','/') for m in members if not m.endswith('/')]\n    s = set(members)\n    from collections import defaultdict\n    by_base = defaultdict(list)\n    for m in members:\n        by_base[os.path.basename(m)].append(m)\n\n    def ok(p):\n        p = str(p).lstrip('/').replace('\\\\','/')\n        if p in s: return True\n        cand = 'train/' + p if not p.startswith('train/') else p[len('train/'):]\n        if cand in s: return True\n        hits = by_base.get(os.path.basename(p), [])\n        return len(hits) == 1\n\n    mask = df[image_col].astype(str).map(ok)\n    return df[mask].reset_index(drop=True)\n\ntrain_df = keep_resolvable(train_df, train_zip_path, 'filename')\nval_df   = keep_resolvable(val_df,   train_zip_path, 'filename')\n#test     = keep_resolvable(test,     test_zip_path,  'filename')\n\n\n# ================== Datasets & Loaders ==================\ntrain_dataset = ZipImageTextDS(train_df, train_zip_path, label_col='mark')\nval_dataset   = ZipImageTextDS(val_df,   train_zip_path, label_col='mark')\ntest_dataset  = ZipImageTextDS(test,     test_zip_path)\n\n# как на скрине: прокидываем препроцессоры прямо в __getitem__ через collate в DataLoader не требуется\ndef collate_fn(batch):\n    imgs = [b['image'] for b in batch]\n    txts = [b['text']  for b in batch]\n    enc = processor(\n        text=txts, images=imgs,\n        return_tensors='pt',\n        padding='max_length', truncation=True, max_length=77\n    )\n    # Fallback: если processor не вернул attention_mask\n    if 'attention_mask' in enc:\n        attn = enc['attention_mask']\n    else:\n        pad_id = 0\n        try:\n            pad_id = getattr(processor.tokenizer, 'pad_token_id', 0)\n        except Exception:\n            pass\n        attn = (enc['input_ids'] != pad_id).long()\n\n    return {\n        'image': enc['pixel_values'],\n        'input_ids': enc['input_ids'],\n        'attention_mask': attn,\n    }\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=False,  num_workers=4, collate_fn=collate_fn, pin_memory=False)\nvalid_loader = DataLoader(val_dataset,   batch_size=64, shuffle=False, num_workers=4, collate_fn=collate_fn, pin_memory=False)\ntest_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False, num_workers=4, collate_fn=collate_fn, pin_memory=False)\n\n# ================== Cosine scores ==================\ndef get_scores(loader):\n    scores=[]\n    for batch in tqdm_notebook(loader):\n        imgs = batch['image'].to(device)\n        ids  = batch['input_ids'].to(device)\n        mask = batch['attention_mask'].to(device)\n\n        with torch.no_grad():\n            img_emb = F.normalize(model.encode_image(imgs), dim=-1)\n            try:\n                txt_emb = F.normalize(model.encode_text(ids, attention_mask=mask), dim=-1)\n            except TypeError:\n                txt_emb = F.normalize(model.encode_text(ids), dim=-1)\n            #img_emb = F.normalize(model.encode_image(imgs), dim=-1)\n            #txt_emb = F.normalize(model.encode_text(ids, attention_mask=mask), dim=-1)\n        scores.append(torch.diagonal(img_emb @ txt_emb.T).cpu().numpy())\n    return np.hstack(scores)\n\ntrain_scores = get_scores(train_loader)\nvalid_scores = get_scores(valid_loader)\ntest_scores  = get_scores(test_loader)\n\ntrain_df['scores'] = train_scores\nval_df['scores']   = valid_scores\ntest['scores']     = test_scores\n\n# ================== Поиск двойного порога (как на скринах) ==================\ndef put_vals(df, best, good, bad):\n    preds = np.zeros(df.shape[0], dtype=int)\n    for i in best: preds[i] = 2\n    for i in good: preds[i] = 1\n    for i in bad:  preds[i] = 0\n    return preds\n\nbest_acc = -1.0\nbest_left, best_right = 0.0, 1.0\n#grid = np.linspace(0.0, 1.0, 51)\ngrid = np.linspace(-1.0, 1.0, 101)\nfor left in tqdm_notebook(grid):\n    for right in grid:\n        best_idx = list(train_df[train_df['scores'] >= right].index)\n        good_idx = list(train_df[(train_df['scores'] < right) & (train_df['scores'] > left)].index)\n        bad_idx  = list(train_df[train_df['scores'] <= left].index)\n        preds = put_vals(train_df, best_idx, good_idx, bad_idx)\n        acc = (train_df['mark'].values == preds).mean()\n        if acc > best_acc:\n            best_acc, best_left, best_right = acc, left, right\n\nprint(f\"Best train acc: {best_acc:.4f} | borders: left={best_left:.4f}, right={best_right:.4f}\")\n\n# ================== Валидация и тест ==================\ndef apply_thresholds(df, left_b, right_b):\n    best_idx = list(df[df['scores'] >= right_b].index)\n    good_idx = list(df[(df['scores'] < right_b) & (df['scores'] > left_b)].index)\n    bad_idx  = list(df[df['scores'] <= left_b].index)\n    return put_vals(df, best_idx, good_idx, bad_idx)\n\nval_pred_idx = apply_thresholds(val_df, best_left, best_right)\nval_acc = (val_df['mark'].values == val_pred_idx).mean()\nprint(f\"Valid accuracy: {val_acc:.4f}\")\n\ntest_pred_idx = apply_thresholds(test, best_left, best_right)\ntest['mark_idx'] = test_pred_idx\ntest['mark'] = test['mark_idx'].map({0:'Плохо', 1:'Удовлетворительно', 2:'Идеально'})\n\n# ================== Сабмит ==================\nsub = pd.DataFrame({'id': test['id'], 'mark': test['mark']}) if 'id' in test.columns \\\n      else pd.DataFrame({'filename': test['filename'], 'mark': test['mark']})\n# sub.to_csv('submission.csv', index=False)\nsub.head()\n\n\n# Для сохранения: sub.to_csv('submission.csv', index=False)\nout_cb = \"/kaggle/working/submission.tsv\"\nsub.to_csv(out_cb, sep=\"\\t\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:19:29.115255Z","iopub.execute_input":"2025-10-09T17:19:29.116266Z","iopub.status.idle":"2025-10-09T17:33:12.306824Z","shell.execute_reply.started":"2025-10-09T17:19:29.116225Z","shell.execute_reply":"2025-10-09T17:33:12.305748Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:671: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'\n  warnings.warn(\nException ignored in: <function tqdm.__del__ at 0x7fbde1e8f6a0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1148, in __del__\n    self.close()\n  File \"/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\", line 282, in close\n    self.disp(bar_style='success', check_delay=False)\n    ^^^^^^^^^\nAttributeError: 'tqdm' object has no attribute 'disp'\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n    self._close()\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n    reader_close()\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n    self._close()\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n    self.run()\n  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n    reader_close()\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n    self.run()\n  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n    self._close()\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n    self.run()\n  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/272 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0f245b3c2cc4aa5b527432d95c27ac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/134 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d16f007390ad499aa6a8ad24e9199d11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"963b0d9182c640f993af5ecdfde7f08d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/101 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f16e91e8c004e3c84358b09a51c570d"}},"metadata":{}},{"name":"stdout","text":"Best train acc: 0.5134 | borders: left=0.0800, right=0.3200\nValid accuracy: 0.5212\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"best_acc = -1.0\nbest_left, best_right = 0.0, 1.0\n#grid = np.linspace(0.0, 1.0, 51)\ngrid = np.linspace(-1.0, 1.0, 101)\nfor left in tqdm_notebook(grid):\n    for right in grid:\n        best_idx = list(train_df[train_df['scores'] >= right].index)\n        good_idx = list(train_df[(train_df['scores'] < right) & (train_df['scores'] > left)].index)\n        bad_idx  = list(train_df[train_df['scores'] <= left].index)\n        preds = put_vals(train_df, best_idx, good_idx, bad_idx)\n        acc = (train_df['mark'].values == preds).mean()\n        if acc > best_acc:\n            best_acc, best_left, best_right = acc, left, right\n\nprint(f\"Best train acc: {best_acc:.4f} | borders: left={best_left:.4f}, right={best_right:.4f}\")\n\n# ================== Валидация и тест ==================\ndef apply_thresholds(df, left_b, right_b):\n    best_idx = list(df[df['scores'] >= right_b].index)\n    good_idx = list(df[(df['scores'] < right_b) & (df['scores'] > left_b)].index)\n    bad_idx  = list(df[df['scores'] <= left_b].index)\n    return put_vals(df, best_idx, good_idx, bad_idx)\n\nval_pred_idx = apply_thresholds(val_df, best_left, best_right)\nval_acc = (val_df['mark'].values == val_pred_idx).mean()\nprint(f\"Valid accuracy: {val_acc:.4f}\")\n\ntest_pred_idx = apply_thresholds(test, best_left, best_right)\ntest['mark_idx'] = test_pred_idx\ntest['mark'] = test['mark_idx'].map({0:'Плохо', 1:'Удовлетворительно', 2:'Идеально'})\n\n# ================== Сабмит ==================\nsub = pd.DataFrame({'id': test['id'], 'mark': test['mark']}) if 'id' in test.columns \\\n      else pd.DataFrame({'filename': test['filename'], 'mark': test['mark']})\n# sub.to_csv('submission.csv', index=False)\nsub.head()\n\n\n# Для сохранения: sub.to_csv('submission.csv', index=False)\nout_cb = \"/kaggle/working/submission.tsv\"\nsub.to_csv(out_cb, sep=\"\\t\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"left_b, right_b = 0.296, 0.338\nval_pred_idx = apply_thresholds(val_df, left_b, right_b)\nval_acc = (val_df['mark'].values == val_pred_idx).mean()\nprint(val_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:45:25.753300Z","iopub.execute_input":"2025-10-09T17:45:25.753985Z","iopub.status.idle":"2025-10-09T17:45:25.766930Z","shell.execute_reply.started":"2025-10-09T17:45:25.753961Z","shell.execute_reply":"2025-10-09T17:45:25.766195Z"}},"outputs":[{"name":"stdout","text":"0.3888694434721736\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"base_left, base_right = 0.296, 0.338\ngrid_left  = np.linspace(base_left-0.05,  base_left+0.05, 101)\ngrid_right = np.linspace(base_right-0.05, base_right+0.05, 101)\n\nbest = (-1, None, None)\nfor L in grid_left:\n    for R in grid_right:\n        if R <= L: \n            continue\n        pred = apply_thresholds(val_df, L, R)\n        acc  = (val_df['mark'].values == pred).mean()\n        if acc > best[0]:\n            best = (acc, L, R)\n\nval_acc, best_left, best_right = best\nprint(f'Best VAL acc: {val_acc:.4f} | left={best_left:.4f} right={best_right:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:45:34.126223Z","iopub.execute_input":"2025-10-09T17:45:34.126501Z","iopub.status.idle":"2025-10-09T17:45:57.754289Z","shell.execute_reply.started":"2025-10-09T17:45:34.126482Z","shell.execute_reply":"2025-10-09T17:45:57.753646Z"}},"outputs":[{"name":"stdout","text":"Best VAL acc: 0.4518 | left=0.2460 right=0.3140\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def get_clip_feats(loader):\n    pos_list, margin_list, prob_list = [], [], []\n    with torch.no_grad():\n        try:\n            T = float(model.logit_scale.exp().item())\n        except Exception:\n            T = 20.0  # разумный дефолт для CLIP\n        for batch in tqdm_notebook(loader, total=len(loader)):\n            imgs = batch['image'].to(device)\n            ids  = batch['input_ids'].to(device)\n            mask = batch['attention_mask'].to(device)\n\n            img = F.normalize(model.encode_image(imgs), dim=-1)\n            try:\n                txt = F.normalize(model.encode_text(ids, attention_mask=mask), dim=-1)\n            except TypeError:\n                txt = F.normalize(model.encode_text(ids), dim=-1)\n\n            S   = img @ txt.T              # [B,B]\n            pos = S.diag()                 # s_pos\n            Snd = S - torch.diag_embed(pos)\n            top1_neg, _ = Snd.max(dim=1)\n            margin = pos - top1_neg\n            prob   = torch.softmax(S * T, dim=1).diag()\n\n            pos_list.append(pos.cpu().numpy())\n            margin_list.append(margin.cpu().numpy())\n            prob_list.append(prob.cpu().numpy())\n    return (np.hstack(pos_list), np.hstack(margin_list), np.hstack(prob_list))\n\ntr_s,tr_m,tr_p = get_clip_feats(train_loader)\nva_s,va_m,va_p = get_clip_feats(valid_loader)\nte_s,te_m,te_p = get_clip_feats(test_loader)\n\nfor df, s, m, p in [(train_df,tr_s,tr_m,tr_p),(val_df,va_s,va_m,va_p),(test,te_s,te_m,te_p)]:\n    df['score']  = s\n    df['margin'] = m\n    df['prob']   = p\n    df['text_len'] = df['text'].fillna('').astype(str).str.len().clip(0,1024).astype(np.float32)  # простая текстовая фича\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:49:19.144773Z","iopub.execute_input":"2025-10-09T17:49:19.145466Z","iopub.status.idle":"2025-10-09T18:01:38.752186Z","shell.execute_reply.started":"2025-10-09T17:49:19.145440Z","shell.execute_reply":"2025-10-09T18:01:38.751109Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/272 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c9a4d3545bf485fbac2dcc15fb843c2"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/134 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1922a3972084fb0a9d9b65197294ff9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a85ef62b3c6148968f289f2f6e72e7d1"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nException ignored in: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>    \nTraceback (most recent call last):\nself._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n        if w.is_alive():self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n       if w.is_alive():  \n      ^ ^  ^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^^  \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process'\n             ^  ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAssertionError: AssertionErrorcan only test a child process: \ncan only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"p = train_df['prob'].values\ny = train_df['mark'].astype(int).values\n\nbest = (0, None, None)\nfor L in np.linspace(0.2, 0.9, 141):\n    for R in np.linspace(0.3, 0.99, 141):\n        if R <= L: continue\n        pred = np.where(p >= R, 2, np.where(p > L, 1, 0))\n        acc  = (pred == y).mean()\n        if acc > best[0]:\n            best = (acc, L, R)\nprint(f'Best VAL acc on prob: {best[0]:.4f} | L={best[1]:.3f} R={best[2]:.3f}')\n\nL,R = best[1], best[2]\ntest_pred = np.where(test['prob'].values >= R, 2, np.where(test['prob'].values > L, 1, 0))\ntest['mark_idx'] = test_pred\ntest['mark'] = test['mark_idx'].map({0:'Плохо',1:'Удовлетворительно',2:'Идеально'})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:15:09.863199Z","iopub.execute_input":"2025-10-09T18:15:09.863579Z","iopub.status.idle":"2025-10-09T18:15:12.236720Z","shell.execute_reply.started":"2025-10-09T18:15:09.863553Z","shell.execute_reply":"2025-10-09T18:15:12.235911Z"}},"outputs":[{"name":"stdout","text":"Best VAL acc on prob: 0.4696 | L=0.200 R=0.975\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nfeats = ['score','margin','prob','text_len']\nXtr, ytr = train_df[feats], train_df['mark'].astype(int)\nXva, yva = val_df[feats],   val_df['mark'].astype(int)\n\nclasses = np.array(sorted(ytr.unique()))\ncw = compute_class_weight('balanced', classes=classes, y=ytr.values).tolist()\n\ncb = CatBoostClassifier(\n    loss_function='MultiClass', eval_metric='Accuracy',\n    iterations=3000, learning_rate=0.03, depth=5, l2_leaf_reg=4.0,\n    class_weights=cw, random_seed=42, verbose=200\n)\ncb.fit(Pool(Xtr,ytr), eval_set=Pool(Xva,yva))\nva_pred = cb.predict(Xva).ravel().astype(int)\nprint('CatBoost VAL acc:', accuracy_score(yva, va_pred))\n\ntest_pred = cb.predict(test[feats]).ravel().astype(int)\ntest['mark_idx'] = test_pred\ntest['mark'] = test['mark_idx'].map({0:'Плохо',1:'Удовлетворительно',2:'Идеально'})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:13:34.051396Z","iopub.execute_input":"2025-10-09T18:13:34.052114Z","iopub.status.idle":"2025-10-09T18:13:48.255197Z","shell.execute_reply.started":"2025-10-09T18:13:34.052091Z","shell.execute_reply":"2025-10-09T18:13:48.254203Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.4693941\ttest: 0.4618749\tbest: 0.4618749 (0)\ttotal: 6.76ms\tremaining: 20.3s\n200:\tlearn: 0.5020606\ttest: 0.4809298\tbest: 0.4846344 (18)\ttotal: 908ms\tremaining: 12.6s\n400:\tlearn: 0.5135490\ttest: 0.4859828\tbest: 0.4860677 (391)\ttotal: 1.82s\tremaining: 11.8s\n600:\tlearn: 0.5300608\ttest: 0.4822005\tbest: 0.4860677 (391)\ttotal: 2.72s\tremaining: 10.9s\n800:\tlearn: 0.5411403\ttest: 0.4803547\tbest: 0.4860677 (391)\ttotal: 3.62s\tremaining: 9.94s\n1000:\tlearn: 0.5518441\ttest: 0.4768218\tbest: 0.4860677 (391)\ttotal: 4.58s\tremaining: 9.14s\n1200:\tlearn: 0.5619250\ttest: 0.4801059\tbest: 0.4860677 (391)\ttotal: 5.49s\tremaining: 8.23s\n1400:\tlearn: 0.5726279\ttest: 0.4769100\tbest: 0.4860677 (391)\ttotal: 6.42s\tremaining: 7.32s\n1600:\tlearn: 0.5843694\ttest: 0.4731231\tbest: 0.4860677 (391)\ttotal: 7.33s\tremaining: 6.4s\n1800:\tlearn: 0.5916319\ttest: 0.4741374\tbest: 0.4860677 (391)\ttotal: 8.23s\tremaining: 5.48s\n2000:\tlearn: 0.5983544\ttest: 0.4721200\tbest: 0.4860677 (391)\ttotal: 9.15s\tremaining: 4.57s\n2200:\tlearn: 0.6048272\ttest: 0.4669031\tbest: 0.4860677 (391)\ttotal: 10.1s\tremaining: 3.65s\n2400:\tlearn: 0.6104694\ttest: 0.4694311\tbest: 0.4860677 (391)\ttotal: 11s\tremaining: 2.75s\n2600:\tlearn: 0.6169824\ttest: 0.4667401\tbest: 0.4860677 (391)\ttotal: 11.9s\tremaining: 1.83s\n2800:\tlearn: 0.6244504\ttest: 0.4649741\tbest: 0.4860677 (391)\ttotal: 12.8s\tremaining: 913ms\n2999:\tlearn: 0.6292227\ttest: 0.4649739\tbest: 0.4860677 (391)\ttotal: 13.8s\tremaining: 0us\n\nbestTest = 0.4860677335\nbestIteration = 391\n\nShrink model to first 392 iterations.\nCatBoost VAL acc: 0.4411387236028468\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"@torch.no_grad()\ndef encode_all(loader):\n    E_img, E_txt = [], []\n    for b in tqdm_notebook(loader, total=len(loader)):\n        imgs = b['image'].to(device)\n        ids  = b['input_ids'].to(device)\n        mask = b['attention_mask'].to(device)\n        e_img = F.normalize(model.encode_image(imgs), dim=-1)\n        try:\n            e_txt = F.normalize(model.encode_text(ids, attention_mask=mask), dim=-1)\n        except TypeError:\n            e_txt = F.normalize(model.encode_text(ids), dim=-1)\n        E_img.append(e_img.cpu()); E_txt.append(e_txt.cpu())\n    return torch.cat(E_img), torch.cat(E_txt)\n\nimg_tr, txt_tr = encode_all(train_loader)\nimg_va, txt_va = encode_all(valid_loader)\nimg_te, txt_te = encode_all(test_loader)\n\ndef global_feats(img, txt, T=20.0, chunk=2048):\n    n = img.size(0)\n    pos_all, mrg_all, prob_all = [], [], []\n    for i0 in tqdm_notebook(range(0, n, chunk)):\n        i1 = min(n, i0+chunk)\n        I = img[i0:i1]                      # [b,d]\n        S = I @ txt.T                       # [b,n]\n        # диагональные «правильные» сходства:\n        pos = S[:, i0:i1].diagonal()        # [b]\n        # лучший негатив по всей строке:\n        S_ = S.clone()\n        S_[:, i0:i1] -= torch.diag_embed(pos)\n        top1_neg, _ = S_.max(dim=1)\n        mrg = pos - top1_neg\n        # «глобальная вероятность» правильной пары:\n        P = torch.softmax((I @ txt.T) * T, dim=1)\n        pr = P[:, i0:i1].diagonal()\n        pos_all.append(pos.numpy()); mrg_all.append(mrg.numpy()); prob_all.append(pr.numpy())\n    return np.hstack(pos_all), np.hstack(mrg_all), np.hstack(prob_all)\n\ntry:\n    T = float(model.logit_scale.exp().item())\nexcept Exception:\n    T = 20.0\n\ntr_s, tr_m, tr_p = global_feats(img_tr, txt_tr, T)\nva_s, va_m, va_p = global_feats(img_va, txt_va, T)\nte_s, te_m, te_p = global_feats(img_te, txt_te, T)\n\nfor df, s, m, p in [(train_df,tr_s,tr_m,tr_p),(val_df,va_s,va_m,va_p),(test,te_s,te_m,te_p)]:\n    df['score']   = s\n    df['margin']  = m\n    df['prob']    = p\n    df['text_len']= df['text'].str.len().clip(0,1024).astype(np.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:23:24.975856Z","iopub.execute_input":"2025-10-09T18:23:24.976173Z","iopub.status.idle":"2025-10-09T18:30:18.488401Z","shell.execute_reply.started":"2025-10-09T18:23:24.976148Z","shell.execute_reply":"2025-10-09T18:30:18.474482Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/272 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"489dbcf060f948ecacbdeab17e11b0bb"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/134 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41815dc02a8436191676cb344bcfbad"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nException ignored in:     if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\n\n   Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n       self._shutdown_workers() ^^^\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    ^if w.is_alive():^\n^ ^ ^ ^   ^ ^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^^ ^^ ^ ^^ ^  \n    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n ^^ ^^  ^ ^ ^^ ^ ^^^^  ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^^can only test a child process^\n^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>^\n^Traceback (most recent call last):\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    ^self._shutdown_workers()\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^if w.is_alive():^\n ^^  ^^ \n AssertionError :  can only test a child process^\n^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>^^\n^^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^    self._shutdown_workers()^\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n\n             ^^^^^  ^ ^ ^ ^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^^ ^  ^ ^ ^ ^ ^ ^^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError^^: ^can only test a child process^\n^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\n^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    self._shutdown_workers()^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^if w.is_alive():\n^  ^^ ^ ^   ^^^\n^AssertionError^^^^^^: ^^can only test a child process^\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nException ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540> \nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n     self._shutdown_workers()    \n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n     if w.is_alive(): \n  ^^  ^ ^   ^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^^ ^^ ^^ ^^ ^ ^ ^^ ^ ^ \n AssertionError: can only test a child process \n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2196924609.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mimg_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mimg_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mimg_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2196924609.py\u001b[0m in \u001b[0;36mencode_all\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mE_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mids\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":29},{"cell_type":"code","source":"mask_va = (val_df['ok']==1) if 'ok' in val_df else np.ones(len(val_df), bool)\np = val_df.loc[mask_va, 'prob'].values\ny = val_df.loc[mask_va, 'mark'].astype(int).values\n\nbest = (0, None, None)\nfor L in np.linspace(0.2, 0.9, 141):\n    for R in np.linspace(0.3, 0.99, 141):\n        if R <= L: continue\n        pred = np.where(p >= R, 2, np.where(p > L, 1, 0))\n        acc  = (pred == y).mean()\n        if acc > best[0]:\n            best = (acc, L, R)\n\nprint(f'Best VAL acc (global prob): {best[0]:.4f} | L={best[1]:.3f} R={best[2]:.3f}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# гистограммы скоров по классам\nfor k,v in {0:'Плохо',1:'Удовлетворительно',2:'Идеально'}.items():\n    s = val_df.loc[val_df['mark']==k, 'scores'].values\n    print(v, 'n=', s.size, 'mean=', float(np.mean(s)), 'std=', float(np.std(s)))\n\n# грубый retrieval@1 на батче валидации (ожидаем >> 0.33)\ndef retrieval_at_1(loader, n_batches=20):\n    ok, total = 0, 0\n    with torch.no_grad():\n        for bi, batch in enumerate(loader):\n            if bi>=n_batches: break\n            imgs = batch['image'].to(device)\n            ids  = batch['input_ids'].to(device)\n            try:\n                txt = model.encode_text(ids)\n            except TypeError:\n                txt = model.encode_text(ids)\n            img = model.encode_image(imgs)\n            img = F.normalize(img, dim=-1)\n            txt = F.normalize(txt, dim=-1)\n            sims = img @ txt.T                       # [B,B]\n            ok += int((sims.argmax(1) == torch.arange(sims.size(0), device=sims.device)).sum())\n            total += sims.size(0)\n    return ok/total if total else 0.0\n\nprint('Val R@1 ≈', retrieval_at_1(valid_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:34:35.439828Z","iopub.execute_input":"2025-10-09T17:34:35.440804Z","iopub.status.idle":"2025-10-09T17:35:07.621358Z","shell.execute_reply.started":"2025-10-09T17:34:35.440760Z","shell.execute_reply":"2025-10-09T17:35:07.620290Z"}},"outputs":[{"name":"stdout","text":"Плохо n= 660 mean= 0.2682957947254181 std= 0.10285823047161102\nУдовлетворительно n= 3955 mean= 0.32398521900177 std= 0.09490367025136948\nИдеально n= 3956 mean= 0.35247066617012024 std= 0.0946582779288292\nVal R@1 ≈ 0.7796875\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ================== CatBoost на scores ==================\n# !pip install -q catboost  # если не установлено\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Пулы\nX_tr = train_df[['scores']]\ny_tr = train_df['mark'].astype(int)\n\nX_va = val_df[['scores']]\ny_va = val_df['mark'].astype(int)\n\ntrain_pool = Pool(X_tr, label=y_tr)\nvalid_pool = Pool(X_va, label=y_va)\n\n# Модель (с запасом итераций + ранняя остановка)\ncb = CatBoostClassifier(\n    loss_function='MultiClass',\n    eval_metric='Accuracy',\n    iterations=2000,\n    learning_rate=0.05,\n    depth=4,\n    l2_leaf_reg=3.0,\n    random_seed=42,\n    #od_type='Iter',\n    #od_wait=100,\n    verbose=200\n)\n\ncb.fit(train_pool, eval_set=valid_pool)\n\n# Оценка на валидации\nva_pred = cb.predict(valid_pool)\n# CatBoost может вернуть shape (n,1); приведём к плоскому int-вектору\nva_pred = np.array(va_pred).reshape(-1).astype(int)\n\nval_acc_cb = accuracy_score(y_va, va_pred)\nprint(f'CatBoost valid accuracy: {val_acc_cb:.4f}')\nprint('Confusion matrix:\\n', confusion_matrix(y_va, va_pred))\nprint('Classification report:\\n', classification_report(y_va, va_pred, digits=4))\n\n# ================== Предсказания на тест ==================\ntest_pool = Pool(test[['scores']])\ntest_pred_idx = np.array(cb.predict(test_pool)).reshape(-1).astype(int)\n\n# Маппим к строковым меткам\nidx_to_mark = {0:'Плохо', 1:'Удовлетворительно', 2:'Идеально'}\ntest['mark_idx_cb'] = test_pred_idx\ntest['mark_cb'] = test['mark_idx_cb'].map(idx_to_mark)\n\n# Сабмит CatBoost\nsub_cb = (pd.DataFrame({'id': test['id'], 'mark': test['mark_cb']})\n          if 'id' in test.columns\n          else pd.DataFrame({'filename': test['filename'], 'mark': test['mark_cb']}))\n\nsub_cb_path = \"/kaggle/working/submission_catboost.tsv\"\nsub_cb.to_csv(sub_cb_path, sep=\"\\t\", index=False)\nprint('Saved:', sub_cb_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:39:43.170032Z","iopub.execute_input":"2025-10-09T17:39:43.170858Z","iopub.status.idle":"2025-10-09T17:39:51.380050Z","shell.execute_reply.started":"2025-10-09T17:39:43.170828Z","shell.execute_reply":"2025-10-09T17:39:51.379260Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.5087064\ttest: 0.5141757\tbest: 0.5141757 (0)\ttotal: 5.36ms\tremaining: 10.7s\n200:\tlearn: 0.5161772\ttest: 0.5233928\tbest: 0.5233928 (185)\ttotal: 789ms\tremaining: 7.06s\n400:\tlearn: 0.5191081\ttest: 0.5243262\tbest: 0.5254929 (260)\ttotal: 1.58s\tremaining: 6.29s\n600:\tlearn: 0.5208321\ttest: 0.5221094\tbest: 0.5254929 (260)\ttotal: 2.38s\tremaining: 5.54s\n800:\tlearn: 0.5233033\ttest: 0.5204760\tbest: 0.5254929 (260)\ttotal: 3.15s\tremaining: 4.72s\n1000:\tlearn: 0.5250848\ttest: 0.5194260\tbest: 0.5254929 (260)\ttotal: 3.94s\tremaining: 3.93s\n1200:\tlearn: 0.5254296\ttest: 0.5197760\tbest: 0.5254929 (260)\ttotal: 4.72s\tremaining: 3.14s\n1400:\tlearn: 0.5254296\ttest: 0.5197760\tbest: 0.5254929 (260)\ttotal: 5.56s\tremaining: 2.38s\n1600:\tlearn: 0.5260617\ttest: 0.5173259\tbest: 0.5254929 (260)\ttotal: 6.34s\tremaining: 1.58s\n1800:\tlearn: 0.5263491\ttest: 0.5168592\tbest: 0.5254929 (260)\ttotal: 7.12s\tremaining: 786ms\n1999:\tlearn: 0.5262341\ttest: 0.5174425\tbest: 0.5254929 (260)\ttotal: 7.9s\tremaining: 0us\n\nbestTest = 0.5254929413\nbestIteration = 260\n\nShrink model to first 261 iterations.\nCatBoost valid accuracy: 0.5255\nConfusion matrix:\n [[   0  437  223]\n [   0 1871 2084]\n [   0 1323 2633]]\nClassification report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000       660\n           1     0.5153    0.4731    0.4933      3955\n           2     0.5330    0.6656    0.5920      3956\n\n    accuracy                         0.5255      8571\n   macro avg     0.3494    0.3795    0.3617      8571\nweighted avg     0.4838    0.5255    0.5008      8571\n\nSaved: /kaggle/working/submission_catboost.tsv\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"sub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.476082Z","iopub.execute_input":"2025-10-09T17:02:07.476322Z","iopub.status.idle":"2025-10-09T17:02:07.495037Z","shell.execute_reply.started":"2025-10-09T17:02:07.476304Z","shell.execute_reply":"2025-10-09T17:02:07.494393Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                          filename               mark\n0       competition_data:46008.png           Идеально\n1      competition_data:354303.png           Идеально\n2       competition_data:98673.png  Удовлетворительно\n3      competition_data:208734.png           Идеально\n4      competition_data:260487.png           Идеально\n...                            ...                ...\n11995   competition_data:85036.png           Идеально\n11996  competition_data:333914.png  Удовлетворительно\n11997   competition_data:97622.png           Идеально\n11998  competition_data:237715.png  Удовлетворительно\n11999  competition_data:325273.png  Удовлетворительно\n\n[12000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>mark</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>competition_data:46008.png</td>\n      <td>Идеально</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>competition_data:354303.png</td>\n      <td>Идеально</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>competition_data:98673.png</td>\n      <td>Удовлетворительно</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>competition_data:208734.png</td>\n      <td>Идеально</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>competition_data:260487.png</td>\n      <td>Идеально</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11995</th>\n      <td>competition_data:85036.png</td>\n      <td>Идеально</td>\n    </tr>\n    <tr>\n      <th>11996</th>\n      <td>competition_data:333914.png</td>\n      <td>Удовлетворительно</td>\n    </tr>\n    <tr>\n      <th>11997</th>\n      <td>competition_data:97622.png</td>\n      <td>Идеально</td>\n    </tr>\n    <tr>\n      <th>11998</th>\n      <td>competition_data:237715.png</td>\n      <td>Удовлетворительно</td>\n    </tr>\n    <tr>\n      <th>11999</th>\n      <td>competition_data:325273.png</td>\n      <td>Удовлетворительно</td>\n    </tr>\n  </tbody>\n</table>\n<p>12000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"gol=pd.DataFrame({\n    'filename': sub['filename'],\n    'text': test['text'],\n    'mark': test['mark'],\n})\n\nout_cb = \"/kaggle/working/submission2345678.tsv\"\ngol.to_csv(out_cb, sep=\"\\t\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:15:22.954684Z","iopub.execute_input":"2025-10-09T18:15:22.954976Z","iopub.status.idle":"2025-10-09T18:15:22.994412Z","shell.execute_reply.started":"2025-10-09T18:15:22.954953Z","shell.execute_reply":"2025-10-09T18:15:22.993816Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"fgftrefr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.536904Z","iopub.execute_input":"2025-10-09T17:02:07.537806Z","iopub.status.idle":"2025-10-09T17:02:07.568341Z","shell.execute_reply.started":"2025-10-09T17:02:07.537778Z","shell.execute_reply":"2025-10-09T17:02:07.564836Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/924549552.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfgftrefr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'fgftrefr' is not defined"],"ename":"NameError","evalue":"name 'fgftrefr' is not defined","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================== PIP (совместимо с ruclip 0.0.2) ==================\n!pip -q install ruclip==0.0.2 transformers huggingface-hub==0.23.3\n!pip -q install torch torchvision scikit-learn catboost\n\n# ================== Imports / Device ==================\nimport os, io, re, subprocess, sys, gc, math\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nfrom tqdm.auto import tqdm as tqdm_notebook\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nif device == 'cuda':\n    try: torch.cuda.set_per_process_memory_fraction(0.65)\n    except: pass\n\n# ================== Data ==================\ntrain = pd.read_csv('/kaggle/input/image-text-matching-vseros-2024/train_df.tsv', sep='\\t')\ntest  = pd.read_csv('/kaggle/input/image-text-matching-vseros-2024/test_df.tsv',  sep='\\t')\n\ntrain_zip_path = '/kaggle/input/image-text-matching-vseros-2024/train.bin'\ntest_zip_path  = '/kaggle/input/image-text-matching-vseros-2024/test-001.bin'\n\n# ================== Labels & Text ==================\nfrom_mark_to_idx = {'Идеально': 2, 'Удовлетворительно': 1, 'Плохо': 0}\nidx_to_mark = {v:k for k,v in from_mark_to_idx.items()}\n\nif 'mark' in train.columns and train['mark'].dtype == object:\n    train['mark'] = train['mark'].map(from_mark_to_idx)\n\n# ВАЖНО: не «чистим» текст — CLIP любит оригинал\ntrain['text'] = train['text'].fillna('').astype(str)\ntest['text']  = test['text'].fillna('').astype(str)\n\ndef norm_name(x: str) -> str:\n    return str(x).lstrip('/').replace('\\\\','/')\ntrain['filename'] = train['filename'].map(norm_name)\ntest['filename']  = test['filename'].map(norm_name)\n\n# ================== Split ==================\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(\n    train, test_size=0.33, random_state=SEED,\n    stratify=train['mark'] if 'mark' in train else None\n)\ntrain_df = train_df.reset_index(drop=True)\nval_df   = val_df.reset_index(drop=True)\n\n# ================== RuCLIP ==================\nimport ruclip\n\nclass Params:\n    device = device\n    pretrained = 'ruclip-vit-large-patch14-224'  # можно попробовать vit-large-p14-224\n\ndef get_ruclip_model(args):\n    model, processor = ruclip.load(args.pretrained, device=args.device)\n    model.to(args.device)\n    model.eval()\n    return model, processor\n\nmodel, processor = get_ruclip_model(Params())\n\n# ================== Dataset: ZIP streaming (устойчивый) ==================\nclass ZipImageTextDS(Dataset):\n    \"\"\"\n    Читает картинки из zip/.bin без распаковки.\n    Для \"проблемных\" архивов сначала пробуем системный unzip -p,\n    потом fallback на zipfile. Битые записи -> белый placeholder + ok=0.\n    \"\"\"\n    def __init__(self, df, zip_path, image_col=\"filename\", text_col=\"text\", label_col=None):\n        self.df = df.reset_index(drop=True)\n        self.zip_path = zip_path\n        self.image_col, self.text_col, self.label_col = image_col, text_col, label_col\n\n        # Список членов архива\n        try:\n            out = subprocess.check_output(['unzip', '-Z1', zip_path], stderr=subprocess.DEVNULL)\n            members = out.decode('utf-8', errors='ignore').splitlines()\n        except Exception:\n            import zipfile\n            with zipfile.ZipFile(zip_path) as z:\n                members = [i.filename for i in z.infolist() if not i.is_dir()]\n\n        self._members = [m.lstrip('/').replace('\\\\','/') for m in members if not m.endswith('/')]\n        self._member_set = set(self._members)\n\n        from collections import defaultdict\n        self._by_base = defaultdict(list)\n        for m in self._members:\n            self._by_base[os.path.basename(m)].append(m)\n\n    def _resolve(self, name: str) -> str:\n        name = name.lstrip('/').replace('\\\\','/')\n        if name in self._member_set:\n            return name\n        cand = 'train/' + name if not name.startswith('train/') else name[len('train/'):]\n        if cand in self._member_set:\n            return cand\n        b = os.path.basename(name)\n        hits = self._by_base.get(b, [])\n        if len(hits) == 1:\n            return hits[0]\n        # неоднозначно — лучше вернуть «не найдено»\n        raise FileNotFoundError(f\"Ambiguous or missing: {name} in {self.zip_path} (candidates={len(hits)})\")\n\n    def _read_image_bytes(self, member: str):\n        # 1) системный unzip\n        try:\n            return subprocess.check_output(['unzip', '-p', self.zip_path, member], stderr=subprocess.DEVNULL)\n        except Exception:\n            pass\n        # 2) python zipfile\n        try:\n            import zipfile\n            with zipfile.ZipFile(self.zip_path, 'r') as z:\n                with z.open(member, 'r') as f:\n                    return f.read()\n        except Exception:\n            return None\n\n    def __len__(self): \n        return len(self.df)\n\n    def __getitem__(self, i):\n        row = self.df.iloc[i]\n        # resolve может кидать FileNotFoundError -> подставим placeholder\n        try:\n            member = self._resolve(str(row[self.image_col]))\n            raw = self._read_image_bytes(member)\n        except Exception:\n            raw = None\n\n        ok = 1 if raw else 0\n        if not raw:\n            img = Image.new('RGB', (256, 256), 'white')\n        else:\n            try:\n                img = Image.open(io.BytesIO(raw))\n                img.load()\n                img = img.convert('RGB')\n            except Exception:\n                ok = 0\n                img = Image.new('RGB', (256, 256), 'white')\n\n        item = {\"image\": img, \"text\": str(row[self.text_col]), \"ok\": ok}\n        if self.label_col is not None:\n            item[\"label\"] = int(row[self.label_col])\n        return item\n\n# (опц.) заранее фильтруем «плохие пути» на train/val (test не трогаем)\ndef keep_resolvable(df, zip_path, image_col=\"filename\"):\n    try:\n        out = subprocess.check_output(['unzip', '-Z1', zip_path], stderr=subprocess.DEVNULL)\n        members = out.decode('utf-8', errors='ignore').splitlines()\n    except Exception:\n        import zipfile\n        with zipfile.ZipFile(zip_path) as z:\n            members = [i.filename for i in z.infolist() if not i.is_dir()]\n    members = [m.lstrip('/').replace('\\\\','/') for m in members if not m.endswith('/')]\n    s = set(members)\n    from collections import defaultdict\n    by_base = defaultdict(list)\n    for m in members:\n        by_base[os.path.basename(m)].append(m)\n    def ok(p):\n        p = str(p).lstrip('/').replace('\\\\','/')\n        if p in s: return True\n        cand = 'train/' + p if not p.startswith('train/') else p[len('train/'):]\n        if cand in s: return True\n        hits = by_base.get(os.path.basename(p), [])\n        return len(hits) == 1\n    mask = df[image_col].astype(str).map(ok)\n    return df[mask].reset_index(drop=True)\n\ntrain_df = keep_resolvable(train_df, train_zip_path, 'filename')\nval_df   = keep_resolvable(val_df,   train_zip_path, 'filename')\n# test мы не фильтруем, чтобы ничего не потерять\n\n# ================== Loaders (однопоточные!) ==================\ndef collate_fn(batch):\n    imgs = [b['image'] for b in batch]\n    txts = [b['text']  for b in batch]\n    enc = processor(\n        text=txts, images=imgs,\n        return_tensors='pt',\n        padding='max_length', truncation=True, max_length=77\n    )\n    # attention_mask может отсутствовать у старых процессоров\n    if 'attention_mask' in enc:\n        attn = enc['attention_mask']\n    else:\n        pad_id = 0\n        try:\n            pad_id = getattr(processor.tokenizer, 'pad_token_id', 0)\n        except Exception:\n            pass\n        attn = (enc['input_ids'] != pad_id).long()\n\n    ok = torch.tensor([b.get('ok', 1) for b in batch], dtype=torch.long)\n\n    return {\n        'image': enc['pixel_values'],\n        'input_ids': enc['input_ids'],\n        'attention_mask': attn,\n        'ok': ok,\n    }\n\nNUM_WORKERS = 4  # критично для стабильности\nBS = 64\n\ntrain_dataset = ZipImageTextDS(train_df, train_zip_path, label_col='mark')\nval_dataset   = ZipImageTextDS(val_df,   train_zip_path, label_col='mark')\ntest_dataset  = ZipImageTextDS(test,     test_zip_path)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BS, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_fn, pin_memory=False)\nvalid_loader = DataLoader(val_dataset,   batch_size=BS, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_fn, pin_memory=False)\ntest_loader  = DataLoader(test_dataset,  batch_size=BS, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_fn, pin_memory=False)\n\n# ================== Эмбеддинги и глобальные фичи ==================\n@torch.no_grad()\ndef encode_all(loader):\n    imgs_all, txts_all, ok_all = [], [], []\n    for b in tqdm_notebook(loader, total=len(loader)):\n        imgs = b['image'].to(device)\n        ids  = b['input_ids'].to(device)\n        mask = b['attention_mask'].to(device)\n\n        img = F.normalize(model.encode_image(imgs), dim=-1)\n        try:\n            txt = F.normalize(model.encode_text(ids, attention_mask=mask), dim=-1)\n        except TypeError:\n            txt = F.normalize(model.encode_text(ids), dim=-1)\n\n        imgs_all.append(img.cpu()); txts_all.append(txt.cpu()); ok_all.append(b['ok'].cpu())\n    return torch.cat(imgs_all), torch.cat(txts_all), torch.cat(ok_all)\n\nimg_tr, txt_tr, ok_tr = encode_all(train_loader)\nimg_va, txt_va, ok_va = encode_all(valid_loader)\nimg_te, txt_te, ok_te = encode_all(test_loader)\n\ndef global_feats(img, txt, T=20.0, chunk=2048):\n    \"\"\"\n    Считает:\n      - score: диагональ (сходство правильной пары)\n      - margin: отрыв от лучшего негатива по всей строке\n      - prob: softmax(T*S) на диагонали (глобальная «вероятность»)\n    Счёт идёт чанками, чтобы не упасть по памяти.\n    \"\"\"\n    n = img.size(0)\n    pos_all, mrg_all, prob_all = [], [], []\n    for i0 in tqdm_notebook(range(0, n, chunk)):\n        i1 = min(n, i0+chunk)\n        I = img[i0:i1]                 # [b,d]\n        S = I @ txt.T                  # [b,n]\n\n        # prob — до модификаций S:\n        Pr = torch.softmax(S * T, dim=1)\n        pr = Pr[:, i0:i1].diagonal()\n\n        pos = S[:, i0:i1].diagonal()\n        S_ = S.clone()\n        S_[:, i0:i1] -= torch.diag_embed(pos)   # обнуляем локальную диагональ\n        top1_neg, _ = S_.max(dim=1)\n        mrg = pos - top1_neg\n\n        pos_all.append(pos.cpu().numpy())\n        mrg_all.append(mrg.cpu().numpy())\n        prob_all.append(pr.cpu().numpy())\n    return np.hstack(pos_all), np.hstack(mrg_all), np.hstack(prob_all)\n\ntry:\n    T = float(model.logit_scale.exp().item())\nexcept Exception:\n    T = 20.0\n\ntr_s, tr_m, tr_p = global_feats(img_tr, txt_tr, T)\nva_s, va_m, va_p = global_feats(img_va, txt_va, T)\nte_s, te_m, te_p = global_feats(img_te, txt_te, T)\n\n# Записываем фичи и ok-флаг\nfor df, s, m, p, ok in [\n    (train_df, tr_s, tr_m, tr_p, ok_tr.numpy()),\n    (val_df,   va_s, va_m, va_p, ok_va.numpy()),\n    (test,     te_s, te_m, te_p, ok_te.numpy()),\n]:\n    df['score']    = s\n    df['margin']   = m\n    df['prob']     = p\n    df['ok']       = ok.astype(int)\n    df['text_len'] = df['text'].str.len().clip(0,1024).astype(np.float32)\n\n# Быстрая проверка ретривала (должно быть >> 0.33)\n@torch.no_grad()\ndef retrieval_at_1(img, txt, batch=1024):\n    ok, total = 0, 0\n    n = img.size(0)\n    for i0 in range(0, n, batch):\n        i1 = min(n, i0+batch)\n        I = img[i0:i1]\n        S = I @ txt.T\n        ok += int((S.argmax(1) == torch.arange(i0, i1)).sum())\n        total += (i1 - i0)\n    return ok / total\n\nprint('Val R@1 ≈', retrieval_at_1(img_va, txt_va))\n\n# ================== Классификация (CatBoost на глобальных фичах) ==================\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfeats = ['score','margin','prob','text_len']\n\nmask_tr = (train_df['ok']==1)\nmask_va = (val_df['ok']==1)\n\nXtr, ytr = train_df.loc[mask_tr, feats], train_df.loc[mask_tr, 'mark'].astype(int)\nXva, yva = val_df.loc[mask_va, feats],   val_df.loc[mask_va, 'mark'].astype(int)\n\nclasses = np.array(sorted(ytr.unique()))\ncw = compute_class_weight('balanced', classes=classes, y=ytr.values).tolist()\n\ncb = CatBoostClassifier(\n    loss_function='MultiClass',\n    eval_metric='Accuracy',\n    iterations=4000,\n    learning_rate=0.03,\n    depth=5,\n    l2_leaf_reg=3.0,\n    class_weights=cw,\n    #od_type='Iter', od_wait=300,  # ранняя остановка\n    random_seed=SEED,\n    verbose=200\n)\n\ncb.fit(Pool(Xtr, ytr), eval_set=Pool(Xva, yva))\nva_pred = cb.predict(Xva).ravel().astype(int)\nval_acc_cb = accuracy_score(yva, va_pred)\nprint(f'CatBoost VAL acc: {val_acc_cb:.4f}')\nprint('Confusion matrix:\\n', confusion_matrix(yva, va_pred))\nprint('Classification report:\\n', classification_report(yva, va_pred, digits=4))\n\n# ================== Инференс на тест ==================\nXte = test[feats]\ntest_pred_idx = cb.predict(Xte).ravel().astype(int)\n\ntest['mark_idx'] = test_pred_idx\ntest['mark'] = test['mark_idx'].map(idx_to_mark)\n\n# ================== Сабмит ==================\nsub = (pd.DataFrame({'id': test['id'], 'mark': test['mark']})\n       if 'id' in test.columns\n       else pd.DataFrame({'filename': test['filename'], 'mark': test['mark']}))\n\nout_path = \"/kaggle/working/submission.tsv\"\nsub.to_csv(out_path, sep=\"\\t\", index=False)\nprint('Saved:', out_path)\n\n# (опц.) быстрые sanity-checks\nfor k,v in {0:'Плохо',1:'Удовлетворительно',2:'Идеально'}.items():\n    s = val_df.loc[val_df['mark']==k, 'score'].values\n    print(v, 'n=', s.size, 'mean=', float(np.mean(s)), 'std=', float(np.std(s)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T19:31:49.907206Z","iopub.execute_input":"2025-10-09T19:31:49.908042Z","iopub.status.idle":"2025-10-09T19:52:58.911633Z","shell.execute_reply.started":"2025-10-09T19:31:49.908017Z","shell.execute_reply":"2025-10-09T19:52:58.910676Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Cannot install huggingface-hub==0.23.3 and ruclip==0.0.2 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:671: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"bpe.model:   0%|          | 0.00/748k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4a6d9fee13442ab46e53b113d05cfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"441c923471074b77995582d6931bb876"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ff6546c1a4c4dbcaaa59289d907bdb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/272 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3d567194e0047078823fef766704f16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/134 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d87d2530a7740d38fd733386eabaa53"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc5bac8916904ac587bd675d35ff4def"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a07f658fcb64176b1d7722c2a1446f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6c76c26d6214b9199dfe6bd9da6d419"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d7015e1efc44952a2717185aa7afcdb"}},"metadata":{}},{"name":"stdout","text":"Val R@1 ≈ 0.3052152607630382\n0:\tlearn: 0.4713707\ttest: 0.4651369\tbest: 0.4651369 (0)\ttotal: 9.56ms\tremaining: 38.2s\n200:\tlearn: 0.5111404\ttest: 0.5002904\tbest: 0.5033165 (90)\ttotal: 906ms\tremaining: 17.1s\n400:\tlearn: 0.5227998\ttest: 0.5035811\tbest: 0.5045038 (315)\ttotal: 1.83s\tremaining: 16.4s\n600:\tlearn: 0.5329279\ttest: 0.5010664\tbest: 0.5049340 (490)\ttotal: 2.73s\tremaining: 15.4s\n800:\tlearn: 0.5456258\ttest: 0.4977057\tbest: 0.5049340 (490)\ttotal: 3.63s\tremaining: 14.5s\n1000:\tlearn: 0.5560000\ttest: 0.4925780\tbest: 0.5049340 (490)\ttotal: 4.53s\tremaining: 13.6s\n1200:\tlearn: 0.5691523\ttest: 0.4941855\tbest: 0.5049340 (490)\ttotal: 5.44s\tremaining: 12.7s\n1400:\tlearn: 0.5796933\ttest: 0.4897292\tbest: 0.5049340 (490)\ttotal: 6.34s\tremaining: 11.8s\n1600:\tlearn: 0.5901499\ttest: 0.4856945\tbest: 0.5049340 (490)\ttotal: 7.26s\tremaining: 10.9s\n1800:\tlearn: 0.5963334\ttest: 0.4844380\tbest: 0.5049340 (490)\ttotal: 8.21s\tremaining: 10s\n2000:\tlearn: 0.6036374\ttest: 0.4846088\tbest: 0.5049340 (490)\ttotal: 9.1s\tremaining: 9.1s\n2200:\tlearn: 0.6101106\ttest: 0.4814974\tbest: 0.5049340 (490)\ttotal: 10s\tremaining: 8.17s\n2400:\tlearn: 0.6177881\ttest: 0.4804062\tbest: 0.5049340 (490)\ttotal: 10.9s\tremaining: 7.26s\n2600:\tlearn: 0.6273313\ttest: 0.4778827\tbest: 0.5049340 (490)\ttotal: 11.8s\tremaining: 6.35s\n2800:\tlearn: 0.6343421\ttest: 0.4790633\tbest: 0.5049340 (490)\ttotal: 12.7s\tremaining: 5.44s\n3000:\tlearn: 0.6426822\ttest: 0.4769599\tbest: 0.5049340 (490)\ttotal: 13.6s\tremaining: 4.53s\n3200:\tlearn: 0.6497763\ttest: 0.4757847\tbest: 0.5049340 (490)\ttotal: 14.5s\tremaining: 3.62s\n3400:\tlearn: 0.6558756\ttest: 0.4735138\tbest: 0.5049340 (490)\ttotal: 15.4s\tremaining: 2.71s\n3600:\tlearn: 0.6611880\ttest: 0.4720832\tbest: 0.5049340 (490)\ttotal: 16.3s\tremaining: 1.81s\n3800:\tlearn: 0.6671234\ttest: 0.4733492\tbest: 0.5049340 (490)\ttotal: 17.2s\tremaining: 900ms\n3999:\tlearn: 0.6710650\ttest: 0.4730142\tbest: 0.5049340 (490)\ttotal: 18.1s\tremaining: 0us\n\nbestTest = 0.5049340018\nbestIteration = 490\n\nShrink model to first 491 iterations.\nCatBoost VAL acc: 0.4638\nConfusion matrix:\n [[ 404  154  102]\n [1223 1320 1412]\n [ 660 1045 2251]]\nClassification report:\n               precision    recall  f1-score   support\n\n           0     0.1767    0.6121    0.2742       660\n           1     0.5240    0.3338    0.4078      3955\n           2     0.5979    0.5690    0.5831      3956\n\n    accuracy                         0.4638      8571\n   macro avg     0.4328    0.5050    0.4217      8571\nweighted avg     0.5314    0.4638    0.4784      8571\n\nSaved: /kaggle/working/submission.tsv\nПлохо n= 660 mean= 0.39957597851753235 std= 0.17652729153633118\nУдовлетворительно n= 3955 mean= 0.5072545409202576 std= 0.14646586775779724\nИдеально n= 3956 mean= 0.5493189692497253 std= 0.1390133798122406\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cb = CatBoostClassifier(\n    loss_function='MultiClass',\n    eval_metric='Accuracy',\n    iterations=4000,\n    learning_rate=0.03,\n    depth=5,\n    l2_leaf_reg=3.0,\n    class_weights=cw,\n    #od_type='Iter', od_wait=300,  # ранняя остановка\n    random_seed=SEED,\n    verbose=200\n)\n\ncb.fit(Pool(Xtr, ytr), eval_set=Pool(Xva, yva))\nva_pred = cb.predict(Xva).ravel().astype(int)\nval_acc_cb = accuracy_score(yva, va_pred)\nprint(f'CatBoost VAL acc: {val_acc_cb:.4f}')\nprint('Confusion matrix:\\n', confusion_matrix(yva, va_pred))\nprint('Classification report:\\n', classification_report(yva, va_pred, digits=4))\n\n# ================== Инференс на тест ==================\nXte = test[feats]\ntest_pred_idx = cb.predict(Xte).ravel().astype(int)\n\ntest['mark_idx'] = test_pred_idx\ntest['mark'] = test['mark_idx'].map(idx_to_mark)\n\n# ================== Сабмит ==================\nsub = (pd.DataFrame({'id': test['id'], 'mark': test['mark']})\n       if 'id' in test.columns\n       else pd.DataFrame({'filename': test['filename'], 'mark': test['mark']}))\n\nout_path = \"/kaggle/working/submission.tsv\"\nsub.to_csv(out_path, sep=\"\\t\", index=False)\nprint('Saved:', out_path)\n\n# (опц.) быстрые sanity-checks\nfor k,v in {0:'Плохо',1:'Удовлетворительно',2:'Идеально'}.items():\n    s = val_df.loc[val_df['mark']==k, 'score'].values\n    print(v, 'n=', s.size, 'mean=', float(np.mean(s)), 'std=', float(np.std(s)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:49:43.744524Z","iopub.execute_input":"2025-10-09T18:49:43.744814Z","iopub.status.idle":"2025-10-09T18:49:58.623601Z","shell.execute_reply.started":"2025-10-09T18:49:43.744792Z","shell.execute_reply":"2025-10-09T18:49:58.622773Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 1.0939026\ttotal: 4.62ms\tremaining: 18.5s\n200:\tlearn: 0.9785380\ttotal: 713ms\tremaining: 13.5s\n400:\tlearn: 0.9636115\ttotal: 1.45s\tremaining: 13s\n600:\tlearn: 0.9469974\ttotal: 2.15s\tremaining: 12.2s\n800:\tlearn: 0.9329615\ttotal: 2.87s\tremaining: 11.5s\n1000:\tlearn: 0.9203617\ttotal: 3.57s\tremaining: 10.7s\n1200:\tlearn: 0.9083829\ttotal: 4.28s\tremaining: 9.98s\n1400:\tlearn: 0.8971745\ttotal: 5.05s\tremaining: 9.36s\n1600:\tlearn: 0.8865750\ttotal: 5.77s\tremaining: 8.64s\n1800:\tlearn: 0.8770924\ttotal: 6.46s\tremaining: 7.89s\n2000:\tlearn: 0.8674665\ttotal: 7.16s\tremaining: 7.16s\n2200:\tlearn: 0.8585447\ttotal: 7.88s\tremaining: 6.44s\n2400:\tlearn: 0.8500681\ttotal: 8.59s\tremaining: 5.72s\n2600:\tlearn: 0.8417296\ttotal: 9.32s\tremaining: 5.01s\n2800:\tlearn: 0.8335473\ttotal: 10s\tremaining: 4.29s\n3000:\tlearn: 0.8261321\ttotal: 10.7s\tremaining: 3.57s\n3200:\tlearn: 0.8186765\ttotal: 11.4s\tremaining: 2.85s\n3400:\tlearn: 0.8114024\ttotal: 12.1s\tremaining: 2.14s\n3600:\tlearn: 0.8042171\ttotal: 12.9s\tremaining: 1.42s\n3800:\tlearn: 0.7972798\ttotal: 13.6s\tremaining: 711ms\n3999:\tlearn: 0.7911501\ttotal: 14.3s\tremaining: 0us\nCatBoost VAL acc: 0.4917\nConfusion matrix:\n [[ 269  257  134]\n [ 816 1646 1493]\n [ 455 1202 2299]]\nClassification report:\n               precision    recall  f1-score   support\n\n           0     0.1747    0.4076    0.2445       660\n           1     0.5301    0.4162    0.4663      3955\n           2     0.5856    0.5811    0.5834      3956\n\n    accuracy                         0.4917      8571\n   macro avg     0.4301    0.4683    0.4314      8571\nweighted avg     0.5283    0.4917    0.5032      8571\n\nSaved: /kaggle/working/submission.tsv\nПлохо n= 660 mean= 0.2682957947254181 std= 0.10285823047161102\nУдовлетворительно n= 3955 mean= 0.32399052381515503 std= 0.09489366412162781\nИдеально n= 3956 mean= 0.3524739742279053 std= 0.09465833008289337\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"gol=pd.DataFrame({\n    'filename': test['filename'],\n    'text': test['text'],\n    'mark': test['mark'],\n})\n\nout_cb = \"/kaggle/working/sub_meh23.tsv\"\ngol.to_csv(out_cb, sep=\"\\t\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T19:52:58.914797Z","iopub.execute_input":"2025-10-09T19:52:58.915061Z","iopub.status.idle":"2025-10-09T19:52:58.953944Z","shell.execute_reply.started":"2025-10-09T19:52:58.915032Z","shell.execute_reply":"2025-10-09T19:52:58.953380Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"@torch.no_grad()\ndef encode_all(loader):\n    E_img, E_txt = [], []\n    for b in tqdm_notebook(loader, total=len(loader)):\n        imgs = b['image'].to(device)\n        ids  = b['input_ids'].to(device)\n        mask = b['attention_mask'].to(device)\n        e_img = F.normalize(model.encode_image(imgs), dim=-1)\n        try:\n            e_txt = F.normalize(model.encode_text(ids, attention_mask=mask), dim=-1)\n        except TypeError:\n            e_txt = F.normalize(model.encode_text(ids), dim=-1)\n        E_img.append(e_img.cpu()); E_txt.append(e_txt.cpu())\n    return torch.cat(E_img), torch.cat(E_txt)\n\nimg_tr, txt_tr = encode_all(train_loader)\nimg_va, txt_va = encode_all(valid_loader)\nimg_te, txt_te = encode_all(test_loader)\n\ndef global_feats_extended(img, txt, T=20.0, chunk=2048):\n    n = img.size(0)\n    scores, margins, probs, ranks, zscores = [], [], [], [], []\n    for i0 in tqdm_notebook(range(0, n, chunk)):\n        i1 = min(n, i0+chunk)\n        I = img[i0:i1]               # [b,d]\n        S = I @ txt.T                # [b,n]\n\n        # диагональ (правильные пары)\n        pos = S[:, i0:i1].diagonal()           # [b]\n\n        # top-1 негатив и margin\n        S_ = S.clone()\n        S_[:, i0:i1] -= torch.diag_embed(pos)\n        top1_neg = S_.max(dim=1).values\n        margin = pos - top1_neg\n\n        # глобальная \"вероятность\" правильной пары\n        prob = torch.softmax(S * T, dim=1)[:, i0:i1].diagonal()\n\n        # ранк правильного текста среди всех (1 = лучший)\n        greater = (S > pos.unsqueeze(1)).sum(dim=1)\n        rank = (greater + 1).float()\n\n        # z-score диагонали относительно строки\n        row_mean = S.mean(dim=1)\n        row_std  = S.std(dim=1)\n        z = (pos - row_mean) / (row_std + 1e-6)\n\n        scores.append(pos.numpy()); margins.append(margin.numpy())\n        probs.append(prob.numpy()); ranks.append(rank.numpy()); zscores.append(z.numpy())\n    return (np.hstack(scores), np.hstack(margins), np.hstack(probs),\n            np.hstack(ranks),  np.hstack(zscores))\n\ntry:\n    T = float(model.logit_scale.exp().item())\nexcept Exception:\n    T = 20.0\n\ntr_s, tr_m, tr_p, tr_r, tr_z = global_feats_extended(img_tr, txt_tr, T)\nva_s, va_m, va_p, va_r, va_z = global_feats_extended(img_va, txt_va, T)\nte_s, te_m, te_p, te_r, te_z = global_feats_extended(img_te, txt_te, T)\n\nfor df, s, m, p, r, z in [\n    (train_df, tr_s, tr_m, tr_p, tr_r, tr_z),\n    (val_df,   va_s, va_m, va_p, va_r, va_z),\n    (test,     te_s, te_m, te_p, te_r, te_z),\n]:\n    df['score']    = s\n    df['margin']   = m\n    df['prob']     = p\n    df['rank']     = r.astype(np.float32)            # 1..N\n    df['rr']       = (1.0 / df['rank']).astype(np.float32)  # reciprocal rank\n    df['zscore']   = z.astype(np.float32)\n    df['text_len'] = df['text'].str.len().clip(0,1024).astype(np.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:50:28.151409Z","iopub.execute_input":"2025-10-09T18:50:28.152029Z","iopub.status.idle":"2025-10-09T19:02:32.908515Z","shell.execute_reply.started":"2025-10-09T18:50:28.152007Z","shell.execute_reply":"2025-10-09T19:02:32.907382Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/272 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58cd9509833c4830b661349a0c17d3ce"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/134 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e05449588ff4405c8ede94739e91c2a2"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive(): \n      ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0520d2a9884007a86d7253ed8a43ae"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7663dec8ade44c35ac40a3aea61f626b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2cf371892824373bf6ec13f05553a5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66f171d12b2a4f86b6abadcc65736d98"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"from catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfeats = ['score','margin','prob','zscore','rr','text_len']  # добавили zscore и rr\n\nXtr, ytr = train_df[feats], train_df['mark'].astype(int)\nXva, yva = val_df[feats],   val_df['mark'].astype(int)\n\nclasses = np.array(sorted(ytr.unique()))\ncw = compute_class_weight('balanced', classes=classes, y=ytr.values).tolist()\n\ncb = CatBoostClassifier(\n    loss_function='MultiClass',\n    eval_metric='Accuracy',\n    iterations=5000,\n    learning_rate=0.03,\n    depth=5,\n    l2_leaf_reg=3.0,\n    class_weights=cw,\n    od_type='Iter', od_wait=300,\n    random_seed=42,\n    verbose=200\n)\ncb.fit(Pool(Xtr, ytr), eval_set=Pool(Xva, yva), use_best_model=True)\nva_pred = cb.predict(Xva).ravel().astype(int)\nprint('CatBoost VAL acc:', accuracy_score(yva, va_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T19:02:32.910860Z","iopub.execute_input":"2025-10-09T19:02:32.911104Z","iopub.status.idle":"2025-10-09T19:02:35.629779Z","shell.execute_reply.started":"2025-10-09T19:02:32.911078Z","shell.execute_reply":"2025-10-09T19:02:35.629039Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.4798998\ttest: 0.4718729\tbest: 0.4718729 (0)\ttotal: 10.8ms\tremaining: 54s\n200:\tlearn: 0.5081153\ttest: 0.4902145\tbest: 0.4937511 (182)\ttotal: 1.07s\tremaining: 25.6s\n400:\tlearn: 0.5237136\ttest: 0.4904784\tbest: 0.4937511 (182)\ttotal: 2.13s\tremaining: 24.4s\nStopped by overfitting detector  (300 iterations wait)\n\nbestTest = 0.4937511458\nbestIteration = 182\n\nShrink model to first 183 iterations.\nCatBoost VAL acc: 0.46633998366584994\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"@torch.no_grad()\ndef encode_all(loader, tta_flip=True):\n    E_img, E_txt = [], []\n    for b in tqdm_notebook(loader, total=len(loader)):\n        imgs = b['image'].to(device)\n        ids  = b['input_ids'].to(device)\n        mask = b['attention_mask'].to(device)\n\n        # image TTA: оригинал (+ горизонтальный флип)\n        img1 = model.encode_image(imgs)\n        if tta_flip:\n            imgs_flip = torch.flip(imgs, dims=[-1])\n            img2 = model.encode_image(imgs_flip)\n            img = F.normalize((img1 + img2) / 2.0, dim=-1)\n        else:\n            img = F.normalize(img1, dim=-1)\n\n        try:\n            txt = F.normalize(model.encode_text(ids, attention_mask=mask), dim=-1)\n        except TypeError:\n            txt = F.normalize(model.encode_text(ids), dim=-1)\n\n        E_img.append(img.cpu()); E_txt.append(txt.cpu())\n    return torch.cat(E_img), torch.cat(E_txt)\n\nimg_tr, txt_tr = encode_all(train_loader, tta_flip=True)\nimg_va, txt_va = encode_all(valid_loader, tta_flip=True)\nimg_te, txt_te = encode_all(test_loader,  tta_flip=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T19:11:22.124130Z","iopub.execute_input":"2025-10-09T19:11:22.124489Z","iopub.status.idle":"2025-10-09T19:23:33.533947Z","shell.execute_reply.started":"2025-10-09T19:11:22.124464Z","shell.execute_reply":"2025-10-09T19:23:33.532925Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/272 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87ca6a98aa174221ad31cb113fddea26"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/134 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cada1dddc8d14c59bf64824ed8510d9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae29105045d421da67a669d1e1d8921"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n: AssertionErrorcan only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    \nif w.is_alive():       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"def _row_feats(S, i0, i1, T, topk=5):\n    # S: [b, n] = img_chunk @ txt^T  (или наоборот, если считаем «по колонке»)\n    b = i1 - i0\n    pos = S[:, i0:i1].diagonal()                  # [b]\n    # top-1/ top-k негативы в строке\n    S_ = S.clone()\n    S_[:, i0:i1] -= torch.diag_embed(pos)\n    top1_neg = S_.max(dim=1).values\n    topk_neg = torch.topk(S_, k=min(topk, S_.size(1)-1), dim=1).values\n    gapk = pos - topk_neg.mean(dim=1)\n\n    # softmax probs и энтропия\n    P = torch.softmax(S * T, dim=1)\n    prob = P[:, i0:i1].diagonal()\n    entropy = -(P * (P.clamp_min(1e-12).log())).sum(dim=1)\n\n    # ранк и reciprocal rank\n    greater = (S > pos.unsqueeze(1)).sum(dim=1)\n    rank = (greater + 1).float()\n    rr = 1.0 / rank\n\n    # zscore\n    row_mean = S.mean(dim=1)\n    row_std  = S.std(dim=1)\n    z = (pos - row_mean) / (row_std + 1e-6)\n\n    return pos, (pos - top1_neg), gapk, prob, entropy, rank, rr, z\n\n@torch.no_grad()\ndef global_rowwise(A, B, T=20.0, topk=5, chunk=2048):\n    n = A.size(0)\n    acc = {k: [] for k in ['score','margin','gapk','prob','entropy','rank','rr','zscore']}\n    for i0 in tqdm_notebook(range(0, n, chunk)):\n        i1 = min(n, i0+chunk)\n        S = A[i0:i1] @ B.T                     # [b, n]\n        pos, mrg, gapk, prob, H, rank, rr, z = _row_feats(S, i0, i1, T, topk)\n        acc['score'].append(pos.cpu().numpy())\n        acc['margin'].append(mrg.cpu().numpy())\n        acc['gapk'].append(gapk.cpu().numpy())\n        acc['prob'].append(prob.cpu().numpy())\n        acc['entropy'].append(H.cpu().numpy())\n        acc['rank'].append(rank.cpu().numpy())\n        acc['rr'].append(rr.cpu().numpy())\n        acc['zscore'].append(z.cpu().numpy())\n    return {k: np.hstack(v) for k, v in acc.items()}\n\n# вытаскиваем T у модели (температура)\ntry:\n    T = float(model.logit_scale.exp().item())\nexcept Exception:\n    T = 20.0\n\n# IMG->TXT (строчные признаки)\ntr_row = global_rowwise(img_tr, txt_tr, T=T)\nva_row = global_rowwise(img_va, txt_va, T=T)\nte_row = global_rowwise(img_te, txt_te, T=T)\n\n# TXT->IMG (колоночные признаки): просто меняем местами эмбединги\ntr_col = global_rowwise(txt_tr, img_tr, T=T)\nva_col = global_rowwise(txt_va, img_va, T=T)\nte_col = global_rowwise(txt_te, img_te, T=T)\n\n# складываем всё в датафреймы (score одинаковый в обеих, берём row)\ndef add_feats(df, row, col):\n    df['score']      = row['score']\n    df['row_margin'] = row['margin'];  df['col_margin'] = col['margin']\n    df['row_gapk']   = row['gapk'];    df['col_gapk']   = col['gapk']\n    df['row_prob']   = row['prob'];    df['col_prob']   = col['prob']\n    df['row_entropy']= row['entropy']; df['col_entropy']= col['entropy']\n    df['row_rank']   = row['rank'];    df['col_rank']   = col['rank']\n    df['row_rr']     = row['rr'];      df['col_rr']     = col['rr']\n    df['row_z']      = row['zscore'];  df['col_z']      = col['zscore']\n    df['text_len']   = df['text'].str.len().clip(0,1024).astype(np.float32)\n\nadd_feats(train_df, tr_row, tr_col)\nadd_feats(val_df,   va_row, va_col)\nadd_feats(test,     te_row, te_col)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T19:54:53.196613Z","iopub.execute_input":"2025-10-09T19:54:53.196935Z","iopub.status.idle":"2025-10-09T19:55:46.554163Z","shell.execute_reply.started":"2025-10-09T19:54:53.196905Z","shell.execute_reply":"2025-10-09T19:55:46.553328Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cdaea2fcd6548b9934e4530e6b54c04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e52e0182c6084b138ecc5bc7dc9ffcb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70ab3a9d04434f8db0b15b4e48fa020d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15af6b7303594b15b64b70d7d63d9d27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd2db82537fd4488ba34a520c4a0aed6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4efb5afbdfe1420a9c3a5c8e9817fc68"}},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"from catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nfeats = [\n    'score',\n    'row_margin','col_margin',\n    'row_gapk','col_gapk',\n    'row_prob','col_prob',\n    'row_entropy','col_entropy',\n    'row_rr','col_rr',\n    'row_z','col_z',\n    'text_len'\n]\n\nXtr, ytr = train_df[feats], train_df['mark'].astype(int)\nXva, yva = val_df[feats],   val_df['mark'].astype(int)\n\nclasses = np.array(sorted(ytr.unique()))\ncw = compute_class_weight('balanced', classes=classes, y=ytr.values).tolist()\n\ncb = CatBoostClassifier(\n    loss_function='MultiClass',\n    eval_metric='Accuracy',\n    iterations=6000,\n    learning_rate=0.03,\n    depth=6,\n    l2_leaf_reg=3.0,\n    class_weights=cw,\n    od_type='Iter', od_wait=400,\n    random_seed=42,\n    verbose=200\n)\ncb.fit(Pool(Xtr,ytr), eval_set=Pool(Xva,yva), use_best_model=True)\nva_pred = cb.predict(Xva).ravel().astype(int)\nprint('CatBoost VAL acc:', accuracy_score(yva, va_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T19:58:34.518391Z","iopub.execute_input":"2025-10-09T19:58:34.518702Z","iopub.status.idle":"2025-10-09T19:59:28.544602Z","shell.execute_reply.started":"2025-10-09T19:58:34.518685Z","shell.execute_reply":"2025-10-09T19:59:28.543864Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.4951780\ttest: 0.4831054\tbest: 0.4831054 (0)\ttotal: 13.6ms\tremaining: 1m 21s\n200:\tlearn: 0.5398817\ttest: 0.5045216\tbest: 0.5055315 (194)\ttotal: 1.76s\tremaining: 50.9s\n400:\tlearn: 0.5680114\ttest: 0.4996534\tbest: 0.5059533 (203)\ttotal: 3.53s\tremaining: 49.3s\n600:\tlearn: 0.6003338\ttest: 0.4914192\tbest: 0.5059533 (203)\ttotal: 5.31s\tremaining: 47.7s\n800:\tlearn: 0.6262270\ttest: 0.4903356\tbest: 0.5059533 (203)\ttotal: 7.05s\tremaining: 45.7s\n1000:\tlearn: 0.6487563\ttest: 0.4917758\tbest: 0.5059533 (203)\ttotal: 8.79s\tremaining: 43.9s\n1200:\tlearn: 0.6680925\ttest: 0.4923706\tbest: 0.5059533 (203)\ttotal: 10.6s\tremaining: 42.2s\n1400:\tlearn: 0.6882161\ttest: 0.4920420\tbest: 0.5059533 (203)\ttotal: 12.3s\tremaining: 40.5s\n1600:\tlearn: 0.7048137\ttest: 0.4889339\tbest: 0.5059533 (203)\ttotal: 14.2s\tremaining: 39s\n1800:\tlearn: 0.7205390\ttest: 0.4872563\tbest: 0.5059533 (203)\ttotal: 15.9s\tremaining: 37.1s\n2000:\tlearn: 0.7340659\ttest: 0.4849903\tbest: 0.5059533 (203)\ttotal: 17.7s\tremaining: 35.4s\n2200:\tlearn: 0.7484239\ttest: 0.4826378\tbest: 0.5059533 (203)\ttotal: 19.5s\tremaining: 33.6s\n2400:\tlearn: 0.7605423\ttest: 0.4773356\tbest: 0.5059533 (203)\ttotal: 21.2s\tremaining: 31.8s\n2600:\tlearn: 0.7708353\ttest: 0.4764960\tbest: 0.5059533 (203)\ttotal: 23s\tremaining: 30.1s\n2800:\tlearn: 0.7795515\ttest: 0.4727946\tbest: 0.5059533 (203)\ttotal: 24.9s\tremaining: 28.4s\n3000:\tlearn: 0.7901759\ttest: 0.4740617\tbest: 0.5059533 (203)\ttotal: 26.6s\tremaining: 26.6s\n3200:\tlearn: 0.7991822\ttest: 0.4726344\tbest: 0.5059533 (203)\ttotal: 28.3s\tremaining: 24.8s\n3400:\tlearn: 0.8060722\ttest: 0.4720470\tbest: 0.5059533 (203)\ttotal: 30.1s\tremaining: 23s\n3600:\tlearn: 0.8127130\ttest: 0.4710387\tbest: 0.5059533 (203)\ttotal: 31.9s\tremaining: 21.2s\n3800:\tlearn: 0.8205978\ttest: 0.4683450\tbest: 0.5059533 (203)\ttotal: 33.6s\tremaining: 19.5s\n4000:\tlearn: 0.8270726\ttest: 0.4644736\tbest: 0.5059533 (203)\ttotal: 35.4s\tremaining: 17.7s\n4200:\tlearn: 0.8334231\ttest: 0.4615285\tbest: 0.5059533 (203)\ttotal: 37.2s\tremaining: 15.9s\n4400:\tlearn: 0.8384458\ttest: 0.4611098\tbest: 0.5059533 (203)\ttotal: 38.9s\tremaining: 14.1s\n4600:\tlearn: 0.8437173\ttest: 0.4602683\tbest: 0.5059533 (203)\ttotal: 40.6s\tremaining: 12.4s\n4800:\tlearn: 0.8501929\ttest: 0.4602711\tbest: 0.5059533 (203)\ttotal: 42.4s\tremaining: 10.6s\n5000:\tlearn: 0.8553816\ttest: 0.4580825\tbest: 0.5059533 (203)\ttotal: 44.2s\tremaining: 8.84s\n5200:\tlearn: 0.8599887\ttest: 0.4584217\tbest: 0.5059533 (203)\ttotal: 46s\tremaining: 7.07s\n5400:\tlearn: 0.8654264\ttest: 0.4570754\tbest: 0.5059533 (203)\ttotal: 47.8s\tremaining: 5.3s\n5600:\tlearn: 0.8693701\ttest: 0.4553073\tbest: 0.5059533 (203)\ttotal: 49.6s\tremaining: 3.53s\n5800:\tlearn: 0.8743515\ttest: 0.4539615\tbest: 0.5059533 (203)\ttotal: 51.3s\tremaining: 1.76s\n5999:\tlearn: 0.8787929\ttest: 0.4531206\tbest: 0.5059533 (203)\ttotal: 53.1s\tremaining: 0us\n\nbestTest = 0.5059532616\nbestIteration = 203\n\nCatBoost VAL acc: 0.5265429938163575\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# матричка похожести для VAL (img_va @ txt_va^T уже есть в памяти?)\n@torch.no_grad()\ndef full_S(img, txt, chunk=2048):\n    n = img.size(0)\n    rows = []\n    for i0 in range(0, n, chunk):\n        i1 = min(n, i0+chunk)\n        rows.append((img[i0:i1] @ txt.T).cpu())\n    return torch.cat(rows, dim=0)  # [n, n]\n\nS_val = full_S(img_va, txt_va)  # косинусы (нормированные эмбеды)\n\n# оптимизируем T по валидации\ny_val = val_df['mark'].astype(int).values\nbest = (0.0, None)\nfor T in np.linspace(5, 80, 76):  # широкий свип\n    P = torch.softmax(S_val * T, dim=1)\n    prob = P.diag().numpy()\n    # простое двухпороговое правило по prob\n    best_local = (0, None, None)\n    for L in np.linspace(0.2, 0.9, 71):\n        for R in np.linspace(0.3, 0.99, 71):\n            if R <= L: continue\n            pred = np.where(prob >= R, 2, np.where(prob > L, 1, 0))\n            acc  = (pred == y_val).mean()\n            if acc > best_local[0]:\n                best_local = (acc, L, R)\n    if best_local[0] > best[0]:\n        best = (best_local[0], (T, best_local[1], best_local[2]))\n\nbest_acc_T, (T_star, L_star, R_star) = best\nprint(f'Best VAL acc by prob@T: {best_acc_T:.4f} | T*={T_star:.1f}, L={L_star:.3f}, R={R_star:.3f}')\n\n# Пересчитаем ГЛОБАЛЬНЫЕ prob-фичи для train/val/test с T_star\n@torch.no_grad()\ndef global_prob_with_T(img, txt, T, chunk=2048):\n    n = img.size(0)\n    out = np.zeros(n, dtype=np.float32)\n    idx = 0\n    for i0 in range(0, n, chunk):\n        i1 = min(n, i0+chunk)\n        I = img[i0:i1]\n        P = torch.softmax((I @ txt.T) * T, dim=1)\n        out[i0:i1] = P[:, i0:i1].diagonal().cpu().numpy()\n    return out\n\ntrain_df['row_prob_T'] = global_prob_with_T(img_tr, txt_tr, T_star)\nval_df['row_prob_T']   = global_prob_with_T(img_va, txt_va, T_star)\ntest['row_prob_T']     = global_prob_with_T(img_te, txt_te, T_star)\n\n# (по желанию) такой же расчёт для «колонн»:\n@torch.no_grad()\ndef global_col_prob_with_T(txt, img, T, chunk=2048):\n    n = txt.size(0)\n    out = np.zeros(n, dtype=np.float32)\n    for i0 in range(0, n, chunk):\n        i1 = min(n, i0+chunk)\n        S = txt[i0:i1] @ img.T\n        P = torch.softmax(S * T, dim=1)\n        out[i0:i1] = P[:, i0:i1].diagonal().cpu().numpy()\n    return out\n\ntrain_df['col_prob_T'] = global_col_prob_with_T(txt_tr, img_tr, T_star)\nval_df['col_prob_T']   = global_col_prob_with_T(txt_va, img_va, T_star)\ntest['col_prob_T']     = global_col_prob_with_T(txt_te, img_te, T_star)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T20:02:19.650025Z","iopub.execute_input":"2025-10-09T20:02:19.650343Z","iopub.status.idle":"2025-10-09T20:03:20.235447Z","shell.execute_reply.started":"2025-10-09T20:02:19.650323Z","shell.execute_reply":"2025-10-09T20:03:20.234574Z"}},"outputs":[{"name":"stdout","text":"Best VAL acc by prob@T: 0.2776 | T*=50.0, L=0.200, R=0.300\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score\n\n# кодируем НЕнормированные эмбеды (сырые) — отдельная функция\n@torch.no_grad()\ndef encode_raw_all(loader, tta_flip=True):\n    EI, ET = [], []\n    for b in tqdm_notebook(loader, total=len(loader)):\n        imgs = b['image'].to(device)\n        ids  = b['input_ids'].to(device)\n        mask = b['attention_mask'].to(device)\n\n        img1 = model.encode_image(imgs)\n        if tta_flip:\n            imgs_f = torch.flip(imgs, dims=[-1])\n            img2 = model.encode_image(imgs_f)\n            img_raw = (img1 + img2) / 2.0\n        else:\n            img_raw = img1\n\n        try:\n            txt_raw = model.encode_text(ids, attention_mask=mask)\n        except TypeError:\n            txt_raw = model.encode_text(ids)\n\n        EI.append(img_raw.cpu()); ET.append(txt_raw.cpu())\n    return torch.cat(EI), torch.cat(ET)\n\nimg_tr_raw, txt_tr_raw = encode_raw_all(train_loader, tta_flip=True)\nimg_va_raw, txt_va_raw = encode_raw_all(valid_loader, tta_flip=True)\nimg_te_raw, txt_te_raw = encode_raw_all(test_loader,  tta_flip=True)\n\ndef build_pair_feats(I, T):\n    # I,T: [N, D] (сырые эмбеды, не нормированные)\n    had  = (I * T).numpy()                          # поэлементное произведение\n    diff = torch.abs(I - T).numpy()                 # поэлементная |разность|\n    dot  = (I * T).sum(dim=1, keepdim=True).numpy() # сырое скалярное\n    i_n  = I.norm(dim=1, keepdim=True).numpy()      # ||img||\n    t_n  = T.norm(dim=1, keepdim=True).numpy()      # ||txt||\n    # финальные признаки: 2*D + 3 скаляра\n    return np.hstack([had, diff, dot, i_n, t_n]).astype(np.float32)\n\nXtr_pair = build_pair_feats(img_tr_raw, txt_tr_raw)\nXva_pair = build_pair_feats(img_va_raw, txt_va_raw)\nXte_pair = build_pair_feats(img_te_raw, txt_te_raw)\n\nytr = train_df['mark'].astype(int).values\nyva = val_df['mark'].astype(int).values\n\n# Линейная мультиклассовая логрегрессия (сбалансированные веса)\nlogit = make_pipeline(\n    StandardScaler(with_mean=True, with_std=True),\n    LogisticRegression(\n        max_iter=3000, solver='saga', n_jobs=-1,\n        multi_class='multinomial', class_weight='balanced', C=2.0\n    )\n)\nlogit.fit(Xtr_pair, ytr)\nva_pred = logit.predict(Xva_pair)\nprint('LogReg (pair feats) VAL acc:', accuracy_score(yva, va_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T20:03:20.236781Z","iopub.execute_input":"2025-10-09T20:03:20.237020Z","iopub.status.idle":"2025-10-09T20:46:30.796629Z","shell.execute_reply.started":"2025-10-09T20:03:20.237001Z","shell.execute_reply":"2025-10-09T20:46:30.792041Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/272 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9f599b225f248ebb997f231cb206e3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/134 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28acc3329488450cb54cde08c3f52793"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1c7a95060cb4ed1b069b8282076cad1"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbd220b4540>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/891909116.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mva_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXva_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LogReg (pair feats) VAL acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1292\u001b[0m             path_func(\n\u001b[1;32m   1293\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1-й уровень: CatBoost по твоим глобальным фичам (добавь row_prob_T/col_prob_T в список)\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfeats = [\n    'score',\n    'row_margin','col_margin',\n    'row_gapk','col_gapk',\n    'row_prob','col_prob','row_prob_T','col_prob_T',\n    'row_entropy','col_entropy',\n    'row_rr','col_rr',\n    'row_z','col_z',\n    'text_len'\n]\nXtr_cb, Xva_cb, Xte_cb = train_df[feats], val_df[feats], test[feats]\nytr, yva = train_df['mark'].astype(int).values, val_df['mark'].astype(int).values\n\nclasses = np.array(sorted(np.unique(ytr)))\ncw = compute_class_weight('balanced', classes=classes, y=ytr).tolist()\n\ncb = CatBoostClassifier(\n    loss_function='MultiClass', eval_metric='Accuracy',\n    iterations=6000, learning_rate=0.03, depth=6, l2_leaf_reg=3.0,\n    class_weights=cw, od_type='Iter', od_wait=400,\n    random_seed=42, verbose=200\n)\ncb.fit(Pool(Xtr_cb, ytr), eval_set=Pool(Xva_cb, yva), use_best_model=True)\n\nP_cb_tr = cb.predict_proba(Xtr_cb)\nP_cb_va = cb.predict_proba(Xva_cb)\nP_cb_te = cb.predict_proba(Xte_cb)\n\n# 2-й уровень: берём [P_cb, P_logreg] и учим лёгкий логистический мета-классификатор\nP_lr_tr = logit.predict_proba(Xtr_pair)\nP_lr_va = logit.predict_proba(Xva_pair)\nP_lr_te = logit.predict_proba(Xte_pair)\n\nZtr = np.hstack([P_cb_tr, P_lr_tr])  # [N, 6]\nZva = np.hstack([P_cb_va, P_lr_va])\nZte = np.hstack([P_cb_te, P_lr_te])\n\nmeta = LogisticRegression(max_iter=2000, solver='lbfgs', multi_class='multinomial', class_weight='balanced')\nmeta.fit(Ztr, ytr)\nva_pred = meta.predict(Zva)\nprint('STACK VAL acc:', accuracy_score(yva, va_pred))\n\n# инференс\ntest_pred_idx = meta.predict(Zte)\ntest['mark_idx'] = test_pred_idx\ntest['mark'] = test['mark_idx'].map({0:'Плохо',1:'Удовлетворительно',2:'Идеально'})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T20:46:31.154678Z","iopub.execute_input":"2025-10-09T20:46:31.155202Z","iopub.status.idle":"2025-10-09T20:46:38.378883Z","shell.execute_reply.started":"2025-10-09T20:46:31.155170Z","shell.execute_reply":"2025-10-09T20:46:38.377801Z"}},"outputs":[{"name":"stdout","text":"0:\tlearn: 0.4898741\ttest: 0.4882909\tbest: 0.4882909 (0)\ttotal: 16.7ms\tremaining: 1m 40s\n200:\tlearn: 0.5361486\ttest: 0.5028389\tbest: 0.5054434 (165)\ttotal: 2.4s\tremaining: 1m 9s\n400:\tlearn: 0.5683445\ttest: 0.4987303\tbest: 0.5054434 (165)\ttotal: 4.78s\tremaining: 1m 6s\nStopped by overfitting detector  (400 iterations wait)\n\nbestTest = 0.5054434345\nbestIteration = 165\n\nShrink model to first 166 iterations.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3553566419.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# 2-й уровень: берём [P_cb, P_logreg] и учим лёгкий логистический мета-классификатор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mP_lr_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mP_lr_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXva_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mP_lr_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXte_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, **predict_proba_params)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_proba_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_final_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decision_function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m             \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 \u001b[0;31m# Workaround for multi_class=\"multinomial\" and binary outcomes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"],"ename":"AttributeError","evalue":"'LogisticRegression' object has no attribute 'coef_'","output_type":"error"}],"execution_count":58},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Xte = test[feats]\ntest_pred_idx = cb.predict(Xte).ravel().astype(int)\n\ntest['mark_idx'] = test_pred_idx\ntest['mark'] = test['mark_idx'].map(idx_to_mark)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T20:46:56.586286Z","iopub.execute_input":"2025-10-09T20:46:56.587061Z","iopub.status.idle":"2025-10-09T20:46:56.610672Z","shell.execute_reply.started":"2025-10-09T20:46:56.587034Z","shell.execute_reply":"2025-10-09T20:46:56.610027Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"gol=pd.DataFrame({\n    'filename': test['filename'],\n    'text': test['text'],\n    'mark': test['mark'],\n})\n\nout_cb = \"/kaggle/working/idk.tsv\"\ngol.to_csv(out_cb, sep=\"\\t\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T20:47:05.434765Z","iopub.execute_input":"2025-10-09T20:47:05.435485Z","iopub.status.idle":"2025-10-09T20:47:05.476692Z","shell.execute_reply.started":"2025-10-09T20:47:05.435454Z","shell.execute_reply":"2025-10-09T20:47:05.475932Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"# Сиды","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch \nimport os \nimport random \n\nseed=42\n\nos.environ['PYTHONHASHSEED']=str(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.568872Z","iopub.status.idle":"2025-10-09T17:02:07.569134Z","shell.execute_reply.started":"2025-10-09T17:02:07.569005Z","shell.execute_reply":"2025-10-09T17:02:07.569017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.570896Z","iopub.status.idle":"2025-10-09T17:02:07.571295Z","shell.execute_reply.started":"2025-10-09T17:02:07.571101Z","shell.execute_reply":"2025-10-09T17:02:07.571118Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TEST MODE","metadata":{}},{"cell_type":"code","source":"TEST_MODE=False ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.572891Z","iopub.status.idle":"2025-10-09T17:02:07.573180Z","shell.execute_reply.started":"2025-10-09T17:02:07.573048Z","shell.execute_reply":"2025-10-09T17:02:07.573062Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Импорты","metadata":{}},{"cell_type":"code","source":"#!pip install ruclip #--no-deps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.574681Z","iopub.status.idle":"2025-10-09T17:02:07.575066Z","shell.execute_reply.started":"2025-10-09T17:02:07.574936Z","shell.execute_reply":"2025-10-09T17:02:07.574952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms as v2\nfrom torch.utils.data import Dataset, DataLoader\n#from transformers import Trainer, TrainingArguments, CLIPModel, CLIPProcessor\n# CLIPModel, CLIPProcessor\nimport PIL \nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n#import ruclip\nfrom torch import nn \nfrom tqdm.auto import tqdm\nimport os, random, io, zipfile, warnings\nimport torch.nn.functional as F\nfrom catboost import CatBoostRegressor, CatBoostClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.575969Z","iopub.status.idle":"2025-10-09T17:02:07.576305Z","shell.execute_reply.started":"2025-10-09T17:02:07.576134Z","shell.execute_reply":"2025-10-09T17:02:07.576148Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/image-text-matching-vseros-2024/train_df.tsv', sep='\\t')\ntest=pd.read_csv('/kaggle/input/image-text-matching-vseros-2024/test_df.tsv', sep='\\t')\n\ntrain_zip_path='/kaggle/input/image-text-matching-vseros-2024/train.bin'\ntest_zip_path='/kaggle/input/image-text-matching-vseros-2024/test-001.bin'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.577518Z","iopub.status.idle":"2025-10-09T17:02:07.577774Z","shell.execute_reply.started":"2025-10-09T17:02:07.577668Z","shell.execute_reply":"2025-10-09T17:02:07.577679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.578667Z","iopub.status.idle":"2025-10-09T17:02:07.578926Z","shell.execute_reply.started":"2025-10-09T17:02:07.578795Z","shell.execute_reply":"2025-10-09T17:02:07.578806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_gol=pd.read_csv('/kaggle/input/image-text-matching-vseros-2024/train_df.tsv', sep='\\t')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.579826Z","iopub.status.idle":"2025-10-09T17:02:07.580113Z","shell.execute_reply.started":"2025-10-09T17:02:07.579952Z","shell.execute_reply":"2025-10-09T17:02:07.579962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_gol.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.582081Z","iopub.status.idle":"2025-10-09T17:02:07.582411Z","shell.execute_reply.started":"2025-10-09T17:02:07.582229Z","shell.execute_reply":"2025-10-09T17:02:07.582243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# If TEST MODE","metadata":{}},{"cell_type":"code","source":"# If TEST MODE — берём сбалансированную подвыборку по классам\nif TEST_MODE:\n    # хотим всего ~100 строк, делим поровну между классами\n    n_classes = train[\"mark\"].nunique()\n    per_class_target = max(1, 24000 // n_classes)\n\n    # на всякий случай ограничимся минимальным доступным числом в классе\n    vc = train[\"mark\"].value_counts()\n    per_class = int(min(vc.min(), per_class_target))\n\n    train = (\n        train.groupby(\"mark\", group_keys=False)\n             .apply(lambda x: x.sample(n=per_class, random_state=seed))\n             .sample(frac=1.0, random_state=seed)           # перемешаем\n             .reset_index(drop=True)\n    )\n    \n    # тест можно просто усечь до 100, как у тебя было\n    #test = test.sample(n=min(len(test), 100), random_state=seed).reset_index(drop=True)\nelse:\n    train = train\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.583272Z","iopub.status.idle":"2025-10-09T17:02:07.583587Z","shell.execute_reply.started":"2025-10-09T17:02:07.583437Z","shell.execute_reply":"2025-10-09T17:02:07.583451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#if TEST_MODE:\n#    train=train[:100]\n#    test=test[:100]\n#else:\n#    train=train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.584624Z","iopub.status.idle":"2025-10-09T17:02:07.584817Z","shell.execute_reply.started":"2025-10-09T17:02:07.584725Z","shell.execute_reply":"2025-10-09T17:02:07.584734Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Mapping","metadata":{}},{"cell_type":"code","source":"LABEL2ID = {\"Плохо\":0, \"Удовлетворительно\":1, \"Идеально\":2}\nif train[\"mark\"].dtype == object:\n    train[\"label_id\"] = train[\"mark\"].map(LABEL2ID)\nelse:\n    train[\"label_id\"] = train[\"mark\"].astype(int)\n\nID2LABEL = {v:k for k,v in LABEL2ID.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.585581Z","iopub.status.idle":"2025-10-09T17:02:07.585913Z","shell.execute_reply.started":"2025-10-09T17:02:07.585743Z","shell.execute_reply":"2025-10-09T17:02:07.585759Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split","metadata":{}},{"cell_type":"code","source":"train_data, eval_data =train_test_split(train, test_size=0.2, random_state=seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.587021Z","iopub.status.idle":"2025-10-09T17:02:07.587365Z","shell.execute_reply.started":"2025-10-09T17:02:07.587176Z","shell.execute_reply":"2025-10-09T17:02:07.587192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class ZipImageTextDS(Dataset):\n    def __init__(self, df, zip_path, image_col=\"filename\", text_col=\"text\", label_col=None):\n        self.df = df.reset_index(drop=True)\n        self.zip_path = zip_path\n        self.image_col, self.text_col, self.label_col = image_col, text_col, label_col\n        with zipfile.ZipFile(self.zip_path) as z:\n            self._members = [i.filename for i in z.infolist() if not i.is_dir()]\n        # basename -> full path\n        self._by_base = {}\n        for m in self._members:\n            b = os.path.basename(m)\n            if b not in self._by_base:\n                self._by_base[b] = m\n        self._zip = None\n\n    def _get_zip(self):\n        if self._zip is None:\n            self._zip = zipfile.ZipFile(self.zip_path, \"r\")\n        return self._zip\n\n    def _resolve(self, name):\n        if name in self._members:\n            return name\n        b = os.path.basename(name)\n        if b in self._by_base:\n            return self._by_base[b]\n        raise FileNotFoundError(f\"{name} not found in {self.zip_path}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, i):\n        row = self.df.iloc[i]\n        name = self._resolve(str(row[self.image_col]))\n        z = self._get_zip()\n        try:\n            with z.open(name, \"r\") as f:\n                img = Image.open(io.BytesIO(f.read()))\n                img.load()\n                img = img.convert(\"RGB\")\n        except Exception:\n            img = Image.new(\"RGB\", (256, 256), \"white\")  # fallback\n\n        item = {\"image\": img, \"text\": str(row[self.text_col])}\n        if self.label_col is not None:\n            item[\"label\"] = int(row[self.label_col])\n        return item\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.588414Z","iopub.status.idle":"2025-10-09T17:02:07.588623Z","shell.execute_reply.started":"2025-10-09T17:02:07.588526Z","shell.execute_reply":"2025-10-09T17:02:07.588535Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creation of datasets ","metadata":{}},{"cell_type":"code","source":"train_ds = ZipImageTextDS(train, train_zip_path, label_col=\"label_id\")\ntest_ds  = ZipImageTextDS(test,  test_zip_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.590194Z","iopub.status.idle":"2025-10-09T17:02:07.590506Z","shell.execute_reply.started":"2025-10-09T17:02:07.590355Z","shell.execute_reply":"2025-10-09T17:02:07.590369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def simple_collate(batch):\n    images = [b[\"image\"] for b in batch]\n    texts  = [b[\"text\"] for b in batch]\n    out = {\"images\": images, \"texts\": texts}\n    if \"label\" in batch[0]:\n        out[\"labels\"] = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    return out\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=False, num_workers=0, collate_fn=simple_collate)\ntest_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=0, collate_fn=simple_collate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.591167Z","iopub.status.idle":"2025-10-09T17:02:07.591432Z","shell.execute_reply.started":"2025-10-09T17:02:07.591281Z","shell.execute_reply":"2025-10-09T17:02:07.591291Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EPOCHS","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"EPOCHS=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.592743Z","iopub.status.idle":"2025-10-09T17:02:07.593010Z","shell.execute_reply.started":"2025-10-09T17:02:07.592880Z","shell.execute_reply":"2025-10-09T17:02:07.592893Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model clip","metadata":{}},{"cell_type":"code","source":"#import ruclip\n\n# Load the CLIP model and processor\n#BACKBONE = \"ruclip-vit-base-patch32-224\"\n#clip_model, preprocess = ruclip.load(BACKBONE, device=device)\n#clip_model.eval()\n#for p in clip_model.parameters():\n #   p.requires_grad = False#","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.594389Z","iopub.status.idle":"2025-10-09T17:02:07.594623Z","shell.execute_reply.started":"2025-10-09T17:02:07.594508Z","shell.execute_reply":"2025-10-09T17:02:07.594520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#from transformers import AutoProcessor, SiglipModel\n#BACKBONE = \"google/siglip-base-patch16-256-multilingual\"\n#proc = AutoProcessor.from_pretrained(BACKBONE)\n#hf_model = SiglipModel.from_pretrained(BACKBONE).to(device).eval()\n#for p in hf_model.parameters():\n#    p.requires_grad = False\n'''\n@torch.no_grad()\ndef encode(images, texts):\n    pv_list, bad = [], 0\n    for im in images:\n        pim = sanitize_to_pil_rgb(im)\n        try:\n            tens = processor(images=pim)     # <-- ключ images=\n            if tens.ndim == 3:\n                tens = tens.unsqueeze(0)     # [1,3,H,W]\n        except Exception:\n            bad += 1\n            tens = processor(images=PLACEHOLDER).unsqueeze(0)\n        pv_list.append(tens)\n    if bad:\n        print(f\"[encode] replaced {bad} bad images with placeholders\")\n\n    pixel_values = torch.cat(pv_list, dim=0).to(device)      # [B,3,H,W]\n    input_ids    = ruclip.tokenize(texts).to(device)         # [B, L]\n\n    img = clip_model.encode_image(pixel_values)              # [B,D]\n    txt = clip_model.encode_text(input_ids)                  # [B,D]\n\n    img = F.normalize(img, dim=-1)\n    txt = F.normalize(txt, dim=-1)\n    return img, txt\n\n# Узнаём размер проекции (proj_dim) на лету\nfrom PIL import Image as _Image\n\nwith torch.no_grad():\n    pv = preprocess(images=PLACEHOLDER)      # <-- ключевым аргументом\n    if pv.ndim == 3:                         # [3,H,W] -> добавим batch dim\n        pv = pv.unsqueeze(0)                 # [1,3,H,W]\n    d_img = clip_model.encode_image(pv.to(device)).shape[-1]\nprint(\"ruCLIP proj dim:\", d_img)\n\n\n\nencode_pair, PROJ_DIM = encode, d_img\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.595848Z","iopub.status.idle":"2025-10-09T17:02:07.596093Z","shell.execute_reply.started":"2025-10-09T17:02:07.595971Z","shell.execute_reply":"2025-10-09T17:02:07.595987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- add once (рядом с SigLIP fallback) ---\nfrom PIL import Image\nimport numpy as np\nimport torch, torch.nn.functional as F\n\nPLACEHOLDER = Image.new(\"RGB\", (224, 224), \"white\")\n\ndef sanitize_to_pil_rgb(im):\n    try:\n        if isinstance(im, Image.Image):\n            im.load()\n            return im.convert(\"RGB\")\n        if isinstance(im, torch.Tensor):\n            t = im.detach().cpu()\n            if t.ndim == 3 and t.shape[0] in (1, 3):  # CHW->HWC\n                t = t.permute(1, 2, 0)\n            if t.ndim == 2:\n                t = t.unsqueeze(-1)\n            if t.dtype.is_floating_point:\n                t = (t.clamp(0, 1) * 255).to(torch.uint8)\n            arr = t.numpy()\n        elif isinstance(im, np.ndarray):\n            arr = im\n            if arr.ndim == 3 and arr.shape[0] in (1, 3) and arr.shape[-1] not in (1, 3):\n                arr = np.transpose(arr, (1, 2, 0))  # CHW->HWC\n            if arr.ndim == 2:\n                arr = arr[..., None]\n            if arr.dtype.kind in \"fc\":\n                arr = (arr.clip(0, 1) * 255).astype(np.uint8)\n            else:\n                arr = arr.astype(np.uint8, copy=False)\n        else:\n            return PLACEHOLDER\n\n        if arr.ndim != 3:\n            return PLACEHOLDER\n        if arr.shape[-1] == 1:\n            arr = np.repeat(arr, 3, axis=-1)\n        if arr.shape[-1] != 3:\n            arr = np.repeat(arr[..., :1], 3, axis=-1)\n\n        pil = Image.fromarray(arr, \"RGB\")\n        w, h = pil.size\n        return pil if (w > 1 and h > 1) else PLACEHOLDER\n    except Exception:\n        return PLACEHOLDER","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.597495Z","iopub.status.idle":"2025-10-09T17:02:07.597767Z","shell.execute_reply.started":"2025-10-09T17:02:07.597611Z","shell.execute_reply":"2025-10-09T17:02:07.597625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ruclip\nfrom PIL import Image\nimport torch.nn.functional as F\n\n# load ruCLIP\nBACKBONE = \"ruclip-vit-base-patch32-224\"   # или 224 — на твой выбор\nclip_model, preprocess = ruclip.load(BACKBONE, device=device)\nclip_model.eval()\nfor p in clip_model.parameters():\n    p.requires_grad = False\n\nPLACEHOLDER = Image.new(\"RGB\", (224, 224), \"white\")  # размер не критичен: preprocess сам ресайзит\n\n@torch.no_grad()\ndef encode(images, texts):\n    pv_list, bad = [], 0\n    for im in images:\n        pim = sanitize_to_pil_rgb(im)\n        try:\n            pv = preprocess(images=[pim])['pixel_values']           # <-- тензор\n        except Exception:\n            bad += 1\n            pv = preprocess(images=[PLACEHOLDER])['pixel_values']\n        pv_list.append(pv)\n\n    if bad:\n        print(f\"[encode] replaced {bad} bad images with placeholders\")\n\n    pixel_values = torch.cat(pv_list, dim=0).to(device)             # [B,3,H,W]\n    input_ids    = preprocess(text=texts)['input_ids'].to(device)   # <-- вот так, НЕ ruclip.tokenize\n\n    img = clip_model.encode_image(pixel_values)\n    txt = clip_model.encode_text(input_ids)\n    img = F.normalize(img, dim=-1)\n    txt = F.normalize(txt, dim=-1)\n    return img, txt\n\n# (опционально) узнать размер эмбеддинга\nwith torch.no_grad():\n    pv = preprocess(images=[PLACEHOLDER])['pixel_values'].to(device)  # <—\n    d_img = clip_model.encode_image(pv).shape[-1]\nprint(\"ruCLIP proj dim:\", d_img)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.598729Z","iopub.status.idle":"2025-10-09T17:02:07.599094Z","shell.execute_reply.started":"2025-10-09T17:02:07.598967Z","shell.execute_reply":"2025-10-09T17:02:07.598981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef encode(images, texts):\n    pil = [sanitize_to_pil_rgb(im) for im in images]\n    batch = preprocess(text=texts, images=pil, return_tensors=\"pt\", padding=True)\n    pixel_values = batch[\"pixel_values\"].to(device)\n    input_ids    = batch[\"input_ids\"].to(device)\n    img = F.normalize(clip_model.encode_image(pixel_values), dim=-1)\n    txt = F.normalize(clip_model.encode_text(input_ids),    dim=-1)\n    return img, txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.600443Z","iopub.status.idle":"2025-10-09T17:02:07.600644Z","shell.execute_reply.started":"2025-10-09T17:02:07.600549Z","shell.execute_reply":"2025-10-09T17:02:07.600558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encode_pair = encode\nD=d_img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.601766Z","iopub.status.idle":"2025-10-09T17:02:07.602016Z","shell.execute_reply.started":"2025-10-09T17:02:07.601915Z","shell.execute_reply":"2025-10-09T17:02:07.601925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Get embedding features \n","metadata":{}},{"cell_type":"code","source":"\n\n@torch.no_grad()\ndef extract_embeddings(dataloader):\n    img_all, txt_all, y_all = [], [], []\n    pbar = tqdm(total=len(dataloader.dataset), desc=\"Extracting embeddings\", unit=\"img\")\n    for batch in dataloader:\n        img, txt = encode_pair(batch[\"images\"], batch[\"texts\"])\n        img_all.append(img.cpu()); txt_all.append(txt.cpu())\n        if \"labels\" in batch: y_all.append(batch[\"labels\"].cpu())\n        pbar.update(img.size(0))\n    pbar.close()\n    img = torch.cat(img_all, 0).numpy()\n    txt = torch.cat(txt_all, 0).numpy()\n    y   = None if not y_all else torch.cat(y_all, 0).numpy()\n    return img, txt, y\n\nimg_tr, txt_tr, y_tr = extract_embeddings(train_loader)\nimg_te, txt_te, _    = extract_embeddings(test_loader)\n\nprint(\"Embeddings:\", img_tr.shape, txt_tr.shape, \"| test:\", img_te.shape, txt_te.shape)\n\n# =========================\n# 5) Pairwise features\n# =========================\ndef build_features(img, txt):\n    absdiff = np.abs(img - txt)\n    hadam   = img * txt\n    cos     = np.sum(hadam, axis=1, keepdims=True)  # L2-normalized → скалярное произведение = cos\n    X = np.concatenate([img, txt, absdiff, hadam, cos], axis=1)  # (N, 4D+1)\n    return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.603125Z","iopub.status.idle":"2025-10-09T17:02:07.603388Z","shell.execute_reply.started":"2025-10-09T17:02:07.603242Z","shell.execute_reply":"2025-10-09T17:02:07.603254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np, json, torch, ruclip\n\n# --- cast to compact dtypes before saving ---\nimg_tr32 = img_tr.astype(\"float32\")\ntxt_tr32 = txt_tr.astype(\"float32\")\nimg_te32 = img_te.astype(\"float32\")\ntxt_te32 = txt_te.astype(\"float32\")\ny_tr64   = None if y_tr is None else y_tr.astype(\"int64\")\n\n# paths (Kaggle-safe)\ntrain_npz_path = \"/kaggle/working/embeds_train.npz\"\ntest_npz_path  = \"/kaggle/working/embeds_test.npz\"\nmeta_path      = \"/kaggle/working/embeds_meta.json\"\n\n# --- save arrays + basic row mapping (so you can join back to dataframes) ---\nnp.savez_compressed(\n    train_npz_path,\n    img=img_tr32,\n    txt=txt_tr32,\n    y=(y_tr64 if y_tr64 is not None else np.array([], dtype=\"int64\")),\n    idx=train.index.values.astype(\"int64\"),\n    filename=train[\"filename\"].astype(str).values,\n    text=train[\"text\"].astype(str).values,\n)\n\nnp.savez_compressed(\n    test_npz_path,\n    img=img_te32,\n    txt=txt_te32,\n    idx=np.arange(len(txt_te32), dtype=\"int64\"),\n    filename=test[\"filename\"].astype(str).values,\n    text=test[\"text\"].astype(str).values,\n)\n\n# --- save minimal metadata for reproducibility ---\nmeta = {\n    \"backbone\": \"ruclip-vit-base-patch32-224\",\n    \"proj_dim\": int(D),                 # your embedding dim\n    \"normalized\": True,                 # you called F.normalize\n    \"seed\": int(seed),\n    \"ruclip_version\": getattr(ruclip, \"__version__\", \"unknown\"),\n    \"torch_version\": torch.__version__,\n}\nwith open(meta_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(meta, f, ensure_ascii=False, indent=2)\n\nprint(\"Saved:\", train_npz_path, test_npz_path, meta_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.604835Z","iopub.status.idle":"2025-10-09T17:02:07.605144Z","shell.execute_reply.started":"2025-10-09T17:02:07.604990Z","shell.execute_reply":"2025-10-09T17:02:07.605003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    all_img, all_txt = [], []\n    for b in DataLoader(train_ds, batch_size=128, shuffle=False, collate_fn=simple_collate):\n        i, t = encode(b[\"images\"], b[\"texts\"])\n        all_img.append(i.cpu()); all_txt.append(t.cpu())\nI = torch.cat(all_img, 0).numpy()\nT = torch.cat(all_txt, 0).numpy()\n\ncos = (I*T).sum(axis=1)\ndf = pd.DataFrame({\"cos\": cos, \"y\": train[\"label_id\"].values})\nprint(df.groupby(\"y\")[\"cos\"].describe())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.607699Z","iopub.status.idle":"2025-10-09T17:02:07.607905Z","shell.execute_reply.started":"2025-10-09T17:02:07.607812Z","shell.execute_reply":"2025-10-09T17:02:07.607821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cos_train, y_train, cos_val, y_val — косинусы и метки на train/val\nfrom sklearn.model_selection import train_test_split\n\ncos_train = (img_tr * txt_tr).sum(1)\ny_train   = y_tr.astype(int)\n\nc_tr, c_val, y_tr_s, y_val_s = train_test_split(\n    cos_train, y_train, test_size=0.2, stratify=y_train, random_state=seed\n)\n\ndef acc_for_tau(c, y, t1, t2):\n    y_hat = (c > t1).astype(int) + (c > t2).astype(int)\n    return (y_hat == y).mean()\n\n# стартовые пороги — середины между средними валидац. классов\nmu = [c_val[y_val_s==k].mean() for k in (0,1,2)]\nt1_0 = 0.5*(mu[0]+mu[1]); t2_0 = 0.5*(mu[1]+mu[2])\n\ngrid = np.linspace(t1_0-0.10, t2_0+0.10, 201)\nbest = (0.0, t1_0, t2_0)\nfor t1 in grid:\n    for t2 in grid:\n        if t2 <= t1: \n            continue\n        a = acc_for_tau(c_val, y_val_s, t1, t2)\n        if a > best[0]:\n            best = (a, float(t1), float(t2))\nval_acc_cos2, T1, T2 = best\nprint(f\"[cos-2thr] tuned on val: acc={val_acc_cos2:.4f} | T1={T1:.4f} T2={T2:.4f}\")\n\n# прогноз на тесте\ncos_test = (img_te * txt_te).sum(1)\npred_ids_cos2 = (cos_test > T1).astype(int) + (cos_test > T2).astype(int)\npred_str_cos2 = [ID2LABEL[int(i)] for i in pred_ids_cos2]\n\nsub_cos2 = pd.DataFrame({\n    \"filename\": test[\"filename\"].astype(str).values,\n    \"text\":     test[\"text\"].astype(str).values,\n    \"mark\":     pred_str_cos2\n})\nout_cos2 = \"/kaggle/working/submission_cos2.tsv\"\nsub_cos2.to_csv(out_cos2, sep=\"\\t\", index=False)\nprint(\"Saved:\", out_cos2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.609027Z","iopub.status.idle":"2025-10-09T17:02:07.609288Z","shell.execute_reply.started":"2025-10-09T17:02:07.609173Z","shell.execute_reply":"2025-10-09T17:02:07.609186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from catboost import CatBoostClassifier\n\nrng = np.random.default_rng(seed)\nN, K = len(img_tr), 64  # K негативов на каждый объект\n\n# TRAIN: случайные индексы негативов (исключаем self-match)\nneg_idx_tr = rng.integers(0, N, size=(N, K))\nrow = np.arange(N)[:, None]\nneg_idx_tr = np.where(neg_idx_tr == row, (neg_idx_tr + 1) % N, neg_idx_tr)\n\nneg_sim_tr = (img_tr[:, None, :] * txt_tr[neg_idx_tr]).sum(-1)   # [N,K]\npos_sim_tr = (img_tr * txt_tr).sum(-1)                           # [N]\n\nrank_gap_tr = pos_sim_tr - neg_sim_tr.max(axis=1)                # [N]\nz_score_tr  = (pos_sim_tr - neg_sim_tr.mean(axis=1)) / (neg_sim_tr.std(axis=1)+1e-6)\nX_small_tr  = np.c_[pos_sim_tr, rank_gap_tr, z_score_tr]         # (N,3)\ny_small_tr  = y_train\n\n# TEST: как «галерею» негативов используем все тексты теста\nM = len(img_te)\nneg_idx_te = rng.integers(0, len(txt_te), size=(M, K))\nneg_sim_te = (img_te[:, None, :] * txt_te[neg_idx_te]).sum(-1)\npos_sim_te = (img_te * txt_te).sum(-1)\n\nrank_gap_te = pos_sim_te - neg_sim_te.max(axis=1)\nz_score_te  = (pos_sim_te - neg_sim_te.mean(axis=1)) / (neg_sim_te.std(axis=1)+1e-6)\nX_small_te  = np.c_[pos_sim_te, rank_gap_te, z_score_te]\n\n# holdout для настройки catboost\nXs_tr, Xs_val, ys_tr, ys_val = train_test_split(\n    X_small_tr, y_small_tr, test_size=0.2, stratify=y_small_tr, random_state=seed\n)\n\nclf = CatBoostClassifier(\n    iterations=2000, learning_rate=0.05, depth=6,\n    loss_function=\"MultiClass\", eval_metric=\"Accuracy\",\n    od_type=\"Iter\", od_wait=200, random_seed=seed,\n    task_type=\"GPU\" if torch.cuda.is_available() else \"CPU\",\n    verbose=200\n)\nclf.fit(Xs_tr, ys_tr, eval_set=(Xs_val, ys_val), use_best_model=True)\n\nval_acc_cb = (clf.predict(Xs_val).astype(int).ravel() == ys_val).mean()\nprint(f\"[CatBoost rank-gap/z] val_acc={val_acc_cb:.4f}\")\n\npred_ids_cb  = clf.predict(X_small_te).ravel().astype(int)\npred_str_cb  = [ID2LABEL[int(i)] for i in pred_ids_cb]\n\nsub_cb = pd.DataFrame({\n    \"filename\": test[\"filename\"].astype(str).values,\n    \"text\":     test[\"text\"].astype(str).values,\n    \"mark\":     pred_str_cb\n})\nout_cb = \"/kaggle/working/submission_catboost_rel.tsv\"\nsub_cb.to_csv(out_cb, sep=\"\\t\", index=False)\nprint(\"Saved:\", out_cb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.610493Z","iopub.status.idle":"2025-10-09T17:02:07.610760Z","shell.execute_reply.started":"2025-10-09T17:02:07.610605Z","shell.execute_reply":"2025-10-09T17:02:07.610619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    all_img, all_txt = [], []\n    for b in DataLoader(train_ds, batch_size=256, shuffle=False, collate_fn=simple_collate):\n        i, t = encode(b[\"images\"], b[\"texts\"])\n        all_img.append(i.cpu()); all_txt.append(t.cpu())\nI = torch.cat(all_img, 0).numpy()\nT = torch.cat(all_txt, 0).numpy()\n\ncos_pos = (I*T).sum(1)                              # true pairs\nperm    = np.random.permutation(len(T))\ncos_neg = (I*T[perm]).sum(1)                        # random negatives\n\ndf = pd.DataFrame({\"cos\": cos_pos, \"y\": train[\"label_id\"].to_numpy()})\nprint(df.groupby(\"y\")[\"cos\"].describe())            # должно быть: y=0 << y=1~2\nprint(\"mean cos pos / neg:\", cos_pos.mean(), cos_neg.mean())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.612343Z","iopub.status.idle":"2025-10-09T17:02:07.612648Z","shell.execute_reply.started":"2025-10-09T17:02:07.612497Z","shell.execute_reply":"2025-10-09T17:02:07.612510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cosine как единственная фича\n#cos_tr = (img_tr * txt_tr).sum(axis=1)\n#cos_val = (img_val * txt_val).sum(axis=1)\n\n# 1) простая логистика\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(multi_class='ovr', C=2.0, max_iter=1000)\nclf.fit(cos_tr.reshape(-1,1), y_tr)\nval_acc = (clf.predict(cos_val.reshape(-1,1)) == y_val).mean()\nprint(\"LogReg(cos) val_acc:\", val_acc)\n\n# 2) изотоника (как регрессия 0..2) + округление\nfrom sklearn.isotonic import IsotonicRegression\nir = IsotonicRegression(out_of_bounds='clip')\nir.fit(cos_tr, y_tr.astype(float))\ny_val_pred = np.clip(np.rint(ir.predict(cos_val)), 0, 2).astype(int)\nprint(\"Isotonic(cos) val_acc:\", (y_val_pred == y_val).mean())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.613768Z","iopub.status.idle":"2025-10-09T17:02:07.613978Z","shell.execute_reply.started":"2025-10-09T17:02:07.613883Z","shell.execute_reply":"2025-10-09T17:02:07.613891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#X_tr = build_features(img_tr, txt_tr)\n#X_te = build_features(img_te, txt_te)\n\n#print(\"Features:\", X_tr.shape, X_te.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.614798Z","iopub.status.idle":"2025-10-09T17:02:07.615094Z","shell.execute_reply.started":"2025-10-09T17:02:07.614935Z","shell.execute_reply":"2025-10-09T17:02:07.614949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_features_small(img, txt):\n    # предполагаем, что img/txt уже L2-нормированы\n    cos = np.einsum('nd,nd->n', img, txt)\n    l2  = np.sqrt(np.clip(2 - 2*cos, 0, None))\n    abs_mean = np.mean(np.abs(img - txt), axis=1)\n    had_mean = np.mean(img * txt, axis=1)\n    abs_max  = np.max(np.abs(img - txt), axis=1)\n    return np.c_[cos, l2, abs_mean, had_mean, abs_max]  # (N, 5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.616191Z","iopub.status.idle":"2025-10-09T17:02:07.616463Z","shell.execute_reply.started":"2025-10-09T17:02:07.616329Z","shell.execute_reply":"2025-10-09T17:02:07.616344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\nsvd_img = TruncatedSVD(n_components=128, random_state=seed).fit(img_tr)\nsvd_txt = TruncatedSVD(n_components=128, random_state=seed).fit(txt_tr)\n\nimg_tr_red = svd_img.transform(img_tr); img_te_red = svd_img.transform(img_te)\ntxt_tr_red = svd_txt.transform(txt_tr); txt_te_red = svd_txt.transform(txt_te)\n\n# добавим компактные агрегаты\ndef build_features_red(img_red, txt_red, img, txt):\n    cos = np.einsum('nd,nd->n', img, txt)\n    l2  = np.sqrt(np.clip(2 - 2*cos, 0, None))\n    return np.c_[img_red, txt_red, cos, l2]\n\nX_tr = build_features_red(img_tr_red, txt_tr_red, img_tr, txt_tr)\nX_te = build_features_red(img_te_red, txt_te_red, img_te, txt_te)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.617766Z","iopub.status.idle":"2025-10-09T17:02:07.618013Z","shell.execute_reply.started":"2025-10-09T17:02:07.617896Z","shell.execute_reply":"2025-10-09T17:02:07.617914Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# skf catboost ","metadata":{}},{"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\nparams = dict(\n   iterations=3000, learning_rate=0.03, depth=6,\n    loss_function='MultiClass', eval_metric='Accuracy',\n    random_seed=seed, od_type='Iter', od_wait=400,\n    task_type='GPU' if torch.cuda.is_available() else 'CPU',\n    auto_class_weights='Balanced',\n    \n    verbose=200\n)\nif use_gpu:\n    params.update(dict(task_type='GPU', devices='0'))\n\n# Simple holdout from the end (можно сделать GroupKFold по text — будет честнее)\nfrom sklearn.model_selection import train_test_split\nX_trn, X_val, y_trn, y_val = train_test_split(X_tr, y_tr, test_size=0.2, random_state=seed, stratify=y_tr)\n\nreg = CatBoostClassifier(**params)\nreg.fit(X_trn, y_trn, eval_set=(X_val, y_val), use_best_model=True)\n\n# Validation accuracy via rounding\ndef reg2class(y_pred):\n    y_hat = np.rint(y_pred).astype(int)\n    return np.clip(y_hat, 0, 2)\n\ny_val_pred = reg.predict(X_val)\nval_acc = (y_val_pred == y_val).mean()\nprint(f\"Validation accuracy (rounded): {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.619585Z","iopub.status.idle":"2025-10-09T17:02:07.619825Z","shell.execute_reply.started":"2025-10-09T17:02:07.619711Z","shell.execute_reply":"2025-10-09T17:02:07.619722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"def reg2class(y_pred, K=3):\n    y = np.asarray(y_pred).reshape(-1)        # <- делаем 1-D\n    y_hat = np.rint(y).astype(np.int64)\n    return np.clip(y_hat, 0, K-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.620530Z","iopub.status.idle":"2025-10-09T17:02:07.620849Z","shell.execute_reply.started":"2025-10-09T17:02:07.620662Z","shell.execute_reply":"2025-10-09T17:02:07.620678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_pred_ids = reg.predict(X_te)\ntest_pred_str = [ID2LABEL[i] for i in test_pred_ids]\n\nsub = pd.DataFrame({\n    \"filename\": test[\"filename\"].astype(str).values,\n    \"text\":     test[\"text\"].astype(str).values,\n    \"mark\":     test_pred_str\n})\nsave_path = \"/kaggle/working/submission22.tsv\"\nsub.to_csv(save_path, sep=\"\\t\", index=False)\nprint(\"Saved:\", save_path)\nprint(sub.head(5).to_csv(sep=\"\\t\", index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.622898Z","iopub.status.idle":"2025-10-09T17:02:07.623216Z","shell.execute_reply.started":"2025-10-09T17:02:07.623063Z","shell.execute_reply":"2025-10-09T17:02:07.623076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MLP ","metadata":{}},{"cell_type":"code","source":"# =========================\n# MLP head on top of CLIP features (replace CatBoost block with this)\n# =========================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\n\n# 1) split as before (keep stratify for balanced val)\nX_trn, X_val, y_trn, y_val = train_test_split(\n    X_tr, y_tr, test_size=0.2, random_state=seed, stratify=y_tr\n)\n\nclass NumpyDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.X = torch.from_numpy(X).float()\n        self.y = None if y is None else torch.from_numpy(y).long()\n    def __len__(self): return self.X.shape[0]\n    def __getitem__(self, i):\n        if self.y is None:\n            return self.X[i]\n        return self.X[i], self.y[i]\n\ntrain_ds_feat = NumpyDataset(X_trn, y_trn)\nval_ds_feat   = NumpyDataset(X_val, y_val)\ntest_ds_feat  = NumpyDataset(X_te,  None)\n\ntrain_loader_feat = DataLoader(train_ds_feat, batch_size=1024, shuffle=True,  num_workers=0, pin_memory=True)\nval_loader_feat   = DataLoader(val_ds_feat,   batch_size=2048, shuffle=False, num_workers=0, pin_memory=True)\ntest_loader_feat  = DataLoader(test_ds_feat,  batch_size=2048, shuffle=False, num_workers=0, pin_memory=True)\n\n# 2) simple MLP classifier\nclass MLPHead(nn.Module):\n    def __init__(self, in_dim, num_classes=3, hidden=(1024, 512), p=0.2):\n        super().__init__()\n        layers = []\n        prev = in_dim\n        for h in hidden:\n            layers += [nn.Linear(prev, h), nn.BatchNorm1d(h), nn.ReLU(inplace=True), nn.Dropout(p)]\n            prev = h\n        layers += [nn.Linear(prev, num_classes)]\n        self.net = nn.Sequential(*layers)\n    def forward(self, x): return self.net(x)\n\nin_dim = X_trn.shape[1]\nmlp = MLPHead(in_dim, num_classes=3, hidden=(1024, 512), p=0.25).to(device)\n\noptimizer = torch.optim.AdamW(mlp.parameters(), lr=3e-3, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)  # epochs\ncriterion = nn.CrossEntropyLoss()\n\nbest_acc, best_state, patience, bad = 0.0, None, 5, 0\nEPOCHS = 20\n\ndef eval_acc(loader):\n    mlp.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for xb, yb in loader:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n            logits = mlp(xb)\n            pred = logits.argmax(dim=1)\n            correct += (pred == yb).sum().item()\n            total   += yb.numel()\n    return correct / max(1, total)\n\nfor epoch in range(1, EPOCHS+1):\n    mlp.train()\n    running = 0.0\n    for xb, yb in train_loader_feat:\n        xb = xb.to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n        logits = mlp(xb)\n        loss = criterion(logits, yb)\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * xb.size(0)\n    scheduler.step()\n\n    val_acc = eval_acc(val_loader_feat)\n    train_loss = running / len(train_ds_feat)\n    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_acc={val_acc:.4f}\")\n\n    if val_acc > best_acc + 1e-4:\n        best_acc = val_acc\n        best_state = {k: v.detach().cpu() for k, v in mlp.state_dict().items()}\n        bad = 0\n    else:\n        bad += 1\n        if bad >= patience:\n            print(f\"Early stopping (patience={patience}). Best val_acc={best_acc:.4f}\")\n            break\n\n# load best\nif best_state is not None:\n    mlp.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n\n# 3) predict on test\nmlp.eval()\nall_preds = []\nwith torch.no_grad():\n    for xb in test_loader_feat:\n        xb = xb.to(device, non_blocking=True)\n        logits = mlp(xb)\n        all_preds.append(logits.argmax(dim=1).cpu().numpy())\ntest_pred_ids = np.concatenate(all_preds, axis=0)\n\n# 4) submission\ntest_pred_str = [ID2LABEL[int(i)] for i in test_pred_ids]\nsub = pd.DataFrame({\n    \"filename\": test[\"filename\"].astype(str).values,\n    \"text\":     test[\"text\"].astype(str).values,\n    \"mark\":     test_pred_str\n})\nout_path = \"/kaggle/working/submission_mlp.tsv\"\nsub.to_csv(out_path, sep=\"\\t\", index=False)\nprint(\"Saved:\", out_path)\nprint(sub.head(5).to_csv(sep=\"\\t\", index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.624519Z","iopub.status.idle":"2025-10-09T17:02:07.624824Z","shell.execute_reply.started":"2025-10-09T17:02:07.624673Z","shell.execute_reply":"2025-10-09T17:02:07.624688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ordinal","metadata":{}},{"cell_type":"code","source":"# =========================\n# Ordinal MLP head (replace CatBoost block with this)\n# =========================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\n\nK = 3  # 3 ordered classes\n\n# 1) split features\nX_trn, X_val, y_trn, y_val = train_test_split(\n    X_tr, y_tr, test_size=0.2, random_state=seed, stratify=y_tr\n)\n\nclass NumpyDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.X = torch.from_numpy(X).float()\n        self.y = None if y is None else torch.from_numpy(y).long()\n    def __len__(self): return self.X.shape[0]\n    def __getitem__(self, i):\n        if self.y is None: return self.X[i]\n        return self.X[i], self.y[i]\n\ntrain_ds_feat = NumpyDataset(X_trn, y_trn)\nval_ds_feat   = NumpyDataset(X_val, y_val)\ntest_ds_feat  = NumpyDataset(X_te,  None)\n\ntrain_loader_feat = DataLoader(train_ds_feat, batch_size=1024, shuffle=True,  num_workers=0, pin_memory=True)\nval_loader_feat   = DataLoader(val_ds_feat,   batch_size=2048, shuffle=False, num_workers=0, pin_memory=True)\ntest_loader_feat  = DataLoader(test_ds_feat,  batch_size=2048, shuffle=False, num_workers=0, pin_memory=True)\n\n# 2) ordinal utilities\ndef ordinal_targets(y, num_classes=K):\n    # y: (B,) int in [0..K-1] -> targets: (B, K-1), t[:,k-1] = 1 if y>=k else 0\n    y = y.view(-1, 1)\n    ks = torch.arange(1, num_classes, device=y.device).view(1, -1)\n    return (y >= ks).float()\n\ndef ordinal_loss(logits, y):\n    # logits: (B, K-1), y: (B,)\n    t = ordinal_targets(y, num_classes=logits.size(1)+1)\n    return F.binary_cross_entropy_with_logits(logits, t)\n\n@torch.no_grad()\ndef ordinal_predict_from_logits(logits, tau=(0.5, 0.5)):\n    # logits: (B, K-1) -> class in [0..K-1]\n    probs = torch.sigmoid(logits)\n    thresholds = torch.tensor(tau, device=probs.device).view(1, -1)  # (1, K-1)\n    passed = (probs > thresholds).sum(dim=1)  # count thresholds passed\n    return passed  # int labels\n\n# 3) MLP with (K-1) outputs\nclass OrdinalMLP(nn.Module):\n    def __init__(self, in_dim, hidden=(1024, 512), p=0.25, num_classes=K):\n        super().__init__()\n        layers, prev = [], in_dim\n        for h in hidden:\n            layers += [nn.Linear(prev, h), nn.BatchNorm1d(h), nn.ReLU(inplace=True), nn.Dropout(p)]\n            prev = h\n        layers += [nn.Linear(prev, num_classes - 1)]  # K-1 logits (thresholds)\n        self.net = nn.Sequential(*layers)\n    def forward(self, x): return self.net(x)\n\nin_dim = X_trn.shape[1]\nmodel = OrdinalMLP(in_dim, hidden=(1024, 512), p=0.25, num_classes=K).to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)  # epochs\nEPOCHS, patience = 30, 10\n\ndef eval_acc(loader, tau=(0.5, 0.5)):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for xb, yb in loader:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n            logits = model(xb)\n            pred = ordinal_predict_from_logits(logits, tau=tau)\n            correct += (pred == yb).sum().item()\n            total   += yb.numel()\n    return correct / max(1, total)\n\nbest_acc, best_state, bad = 0.0, None, 0\nbest_tau = (0.5, 0.5)\n\nfor epoch in range(1, EPOCHS+1):\n    # --- train ---\n    model.train()\n    run_loss = 0.0\n    for xb, yb in train_loader_feat:\n        xb = xb.to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n        logits = model(xb)\n        loss = ordinal_loss(logits, yb)\n        loss.backward()\n        optimizer.step()\n        run_loss += loss.item() * xb.size(0)\n    scheduler.step()\n    train_loss = run_loss / len(train_ds_feat)\n\n    # --- quick val acc at default tau ---\n    val_acc_default = eval_acc(val_loader_feat, tau=(0.5, 0.5))\n\n    # --- small grid to tune thresholds on val ---\n    model.eval()\n    with torch.no_grad():\n        all_logits, all_labels = [], []\n        for xb, yb in val_loader_feat:\n            xb = xb.to(device, non_blocking=True)\n            logits = model(xb).cpu()\n            all_logits.append(logits)\n            all_labels.append(yb)\n        L = torch.cat(all_logits, 0).numpy()   # (N, K-1)\n        Y = torch.cat(all_labels, 0).numpy()   # (N,)\n\n    def acc_for_tau(t1, t2):\n        probs = 1/(1+np.exp(-L))\n        pred  = (probs > np.array([t1, t2])[None, :]).sum(axis=1)\n        return (pred == Y).mean()\n\n    grid = np.linspace(0.35, 0.65, 13)\n    best_local_acc, local_tau = 0.0, (0.5, 0.5)\n    for t1 in grid:\n        for t2 in grid:\n            if t2 >= t1:  # monotone thresholds (optional)\n                a = acc_for_tau(t1, t2)\n                if a > best_local_acc:\n                    best_local_acc, local_tau = a, (float(t1), float(t2))\n\n    # choose tuned tau for checkpointing\n    val_acc = best_local_acc\n    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | \"\n          f\"val_acc@0.5={val_acc_default:.4f} | val_acc@tuned={val_acc:.4f} | tau={local_tau}\")\n\n    if val_acc > best_acc + 1e-4:\n        best_acc  = val_acc\n        best_tau  = local_tau\n        best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n        bad = 0\n    else:\n        bad += 1\n        if bad >= patience:\n            print(f\"Early stopping (patience={patience}). Best val_acc={best_acc:.4f}, tau={best_tau}\")\n            break\n\n# load best\nif best_state is not None:\n    model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n\n# 4) predict on test with tuned thresholds\nmodel.eval()\nall_preds = []\nwith torch.no_grad():\n    for xb in test_loader_feat:\n        xb = xb.to(device, non_blocking=True)\n        logits = model(xb)\n        preds = ordinal_predict_from_logits(logits, tau=best_tau)\n        all_preds.append(preds.cpu().numpy())\ntest_pred_ids = np.concatenate(all_preds, axis=0)\n\n# 5) submission\ntest_pred_str = [ID2LABEL[int(i)] for i in test_pred_ids]\nsub = pd.DataFrame({\n    \"filename\": test[\"filename\"].astype(str).values,\n    \"text\":     test[\"text\"].astype(str).values,\n    \"mark\":     test_pred_str\n})\nout_path = \"/kaggle/working/submission_mlp_ordinal2.tsv\"\nsub.to_csv(out_path, sep=\"\\t\", index=False)\nprint(\"Saved:\", out_path)\nprint(sub.head(5).to_csv(sep=\"\\t\", index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T17:02:07.625923Z","iopub.status.idle":"2025-10-09T17:02:07.626233Z","shell.execute_reply.started":"2025-10-09T17:02:07.626066Z","shell.execute_reply":"2025-10-09T17:02:07.626079Z"}},"outputs":[],"execution_count":null}]}